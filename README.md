# Graduation log

in-memory)auto        - [Uitwerking JDBC](#uitwerking-jdbc)auto            - [Secrets encrypted opslaan](#secrets-encrypted-opslaan)auto    - [Dag 41, 30-10-2018](#dag-41-30-10-2018)auto    - [Dag 42, 31-10-2018](#dag-42-31-10-2018)auto        - [Gesprek met Ilse](#gesprek-met-ilse-1)auto    - [Dag 43, 1-11-2018](#dag-43-1-11-2018)auto        - [Terugkomdag op school](#terugkomdag-op-school)auto            - [Intervisie](#intervisie)auto            - [Portfolio](#portfolio)auto    - [Dag 44, 5-11-2018](#dag-44-5-11-2018)auto    - [Dag 45, 6-11-2018](#dag-45-6-11-2018)auto        - [Leeswijzer](#leeswijzer)auto        - [Universiteit van Nederland, 6 nov 2018](#universiteit-van-nederland-6-nov-2018)auto            - [Wat gebeurt er als de golfstroom stilvalt?](#wat-gebeurt-er-als-de-golfstroom-stilvalt)auto            - [Waarom gaan we uiteindelijk ten onder aan plastic soep?](#waarom-gaan-we-uiteindelijk-ten-onder-aan-plastic-soep)auto            - [Zijn wij wel goed voorbereid op de volgende pandemie?](#zijn-wij-wel-goed-voorbereid-op-de-volgende-pandemie)auto            - [Hoe ziet een wereld zonder insecten eruit?](#hoe-ziet-een-wereld-zonder-insecten-eruit)auto            - [Hoe kan een cyberaanval het internet platleggen?](#hoe-kan-een-cyberaanval-het-internet-platleggen)auto        - [Conclusie](#conclusie)auto    - [Dag 46, 7-11-2018](#dag-46-7-11-2018)auto        - [Overdag](#overdag)auto        - [Iska GIF](#iska-gif)auto    - [Dag 47, 8-11-2018](#dag-47-8-11-2018)auto    - [Dag 48, 9-11-2018](#dag-48-9-11-2018)auto        - [Interviewen!](#interviewen)auto    - [11-11-2018](#11-11-2018)auto        - [Reactie van Bartosz](#reactie-van-bartosz)auto    - [Dag 49, 12-11-2018](#dag-49-12-11-2018)auto    - [Dag 50, 13-11-2018](#dag-50-13-11-2018)auto        - [Gesprek Tim Mahy](#gesprek-tim-mahy)auto        - [De dag verder](#de-dag-verder)auto    - [Dag 51, 14-11-2018](#dag-51-14-11-2018)auto        - [CROQUE MIDDAG!](#croque-middag)auto        - [Gesprek met Ilse](#gesprek-met-ilse-2)auto    - [Dag 52, 15-11-2018](#dag-52-15-11-2018)auto        - [After lunch talk van collega](#after-lunch-talk-van-collega)auto    - [Dag 53, 16-11-2018](#dag-53-16-11-2018)auto    - [Dag 54, 19-11-2018](#dag-54-19-11-2018)auto        - [Mappen structuur react app](#mappen-structuur-react-app)auto            - [Smart component](#smart-component)auto            - [Dumb component](#dumb-component)autoauto<!-- /TOC -->

## Dag 1, 3-9-2018

### Stage kickoff dag

Deze dag is begonnen in Veenendaal, hier moest ik om 9u aanwezig zijn. Gelukkig zaten de files mee en kwam ik precies op tijd. Eenmaal aangekomen ontmoette ik 2 mede stagiaires die ook gaan afstuderen maar dan in Veenendaal. Na opgehaald te worden door _Bart Bijl_ kwamen we in de kantine terecht. Hier was het merendeel van de andere stagiaires al aanwezig. We moesten nog eventjes wachten op een vijftal laatkomers (dit kwam door het verkeer).

We zijn toen als complete groep naar de Seminar ruimte begeleid en mochten daar plaats nemen. Hier werd een PowerPoint gehouden met informatie over het afstuderen. Na deze algemene PowerPoint kwam er een collega langs om door het plan van aanpak (PvA) te lopen. Dit heeft enige tijd geduurd omdat het template vanuit Info Support zelf zeer uitgebreid is en er veel vragen waren.

Na de presentatie was er een lunch, hier hebben we met zijn alle gebruik van gemaakt en heerlijk van genoten. Na een half uur pauze was het tijd voor een ontmoeting met de systeembeheerders voor de pasjes en laptops die in bruikleen worden uitgegeven. Toen we klaar waren bij de systeem beheerders mocht ik al naar huis; dit kwam omdat ik afstudeerde in Mechelen i.p.v. in Veenendaal.

## Dag 2, 4-9-2018

### Laptop en werkplek inrichten

Mijn eerste dag bij Info Support in BelgiÃ«. Hier ben ik om 8:30uur aangekomen en een rondleiding gekregen van Christen en Ilse. Na de rondleiding heb ik werkplek toegewezen gekregen bij 4 andere collega's op de kamer. Na kennis te maken ben ik begonnen met mijn laptop in te richten.

De volgende software heb ik als eerste geÃ¯nstalleerd

- Visual Studio code
  - Markdownlint
  - vscode-icons
- Git
- GitKraken (Git UI)
- iTunes (Muziek)

Na deze installaties ben ik mijn afstudeeropdracht nog eens gaan lezen om mijzelf voor te bereiden op het gesprek met mijn begeleider. Ik heb ook een snelle Google search gedaan naar vergelijkbare producten en kwam al snel kandidaten tegen.

- [peoplecart](https://peoplecart.com)
- [Bonusly](https://bonus.ly/)
- [PeopleStreme](https://peoplestreme.com)

Na gesprek gehad te hebben met Benny is de opdracht een stuk duidelijker. De software die ze hier gebruiken is bonus.ly, die ik reeds al had gevonden. De opdracht is eigenlijk een blockchain versie van deze software. Nu ik een richtlijn heb kan ik de opdracht beter uitwerken en heb ik een uitgangspunt.

### Bronnen gelezen

Ik heb de volgende bronnen gelezen om al vast een feel te krijgen voor de blockchain/ethereum/smartcontracts.

- [How Do Ethereum Smart Contracts Work?](https://www.coindesk.com/information/ethereum-smart-contracts-work/)
- [The Hitchhikerâ€™s Guide to Smart Contracts in Ethereum](https://blog.zeppelin.solutions/the-hitchhikers-guide-to-smart-contracts-in-ethereum-848f08001f05)

Na deze gelezen te hebben ben ik begonnen aan mijn PvA (Plan van Aanpak) en zal hier nog enige dagen mee bezig zijn. Ik heb concreet met Benny afgesproken vrijdag een concept versie in te leveren en deze dinsdag te bespreken met desbetreffende feedback zodat in week 2 (hopelijk) een definitieve versie verschijnt.

## Dag 3, 5-9-2018

### Start + Plan van Aanpak

Deze dag startte rustig. Ik heb mijn werkplek de dag ervoor al toegewezen dus vandaag kon ik normaal doorlopen en beginnen. Ik ben verder gegaan aan mijn Plan van Aanpak en heb een eerste versie opgezet. Deze heb ik zelf ook nogmaals doorgelezen.

### Test & Lunch

Toen we pauze hadden was er een test van een applicatie die gemaakt was voor een klant. De applicatie kon je op je telefoon openen en het was een soort quiz. Er werd gebruik gemaakt van je camera om QR codes te scannen zodat de "zoektocht" gevalideerd kon worden echter was er nu een master QR code. Toen de test klaar was en de feedback verzameld was bleek het een geslaagde test te zijn geweest.

### Kikkeren!?

> Marvin, weet je wat kikkeren is?

Ik ben toen uitgenodigd door een 3-tal collega's om te gaan _kikkeren_, dit is natuurlijk gewoon tafelvoetbal. Ik heb hier zelf niet veel ervaring mee en ik denk dat daarom ook mijn team verloren had..

### Procesbegeleidster

Ik heb ook met mijn procesbegeleidster afspraken gemaakt over hoe vaak we elkaar gaan spreken. We zijn akkoord gegaan met een ontmoeting om de 2 weken ingaande vanaf week 3 op woensdag.

### Begin van blockchain kennis..

Ik ben altijd heel erg van de handen vies maken i.p.v. alleen maar artikelen lezen. Ik begin meestal met YouTube video's. De video's die ik vandaag heb bekeken met betrekking tot blockchain techniek

- [What is a Smart Contract? A Beginnerâ€™s Guide - Ameer Rosic](https://www.youtube.com/watch?v=qdoUpGg_DpQ)
- [Ethereum Explained - Siraj Raval](https://www.youtube.com/watch?v=-_Qs0XdPpw8)
- [Smart contracts, private test chain and deployment to Ethereum with Nethereum - Juan Fran Blanco](https://www.youtube.com/watch?v=4t5Z3eX59k4)
- [Java and the Blockchain - ANZ Coders](https://www.youtube.com/watch?time_continue=9&v=ea3miXs_P6Y)

Ik heb toch een paar blogs gelezen

- [Lightweight Ethereum Clients Using Web3j](https://www.baeldung.com/web3j)
- [Web3j](https://web3j.io/)

#### Geth geÃ¯nstalleerd

Na de informatie vergaard te hebben over de blockchain stond mij een ding te wachten. Een lokale blockchain te starten voor development. Ik had hier echter geen ervaring mee. De software die nodig was (blijkend uit de filmpjes) is `geth`. Dit is een Ethereum blockchain node geprogrammeerd in `Go` (Google's eigen programmeertaal). Deze installatie kon echter niet op mijn werk laptop en heb ik gedaan op mijn persoonlijke. Ik heb nog geen admin rechten (mailtje is verstuurd naar de systeembeheerders). Toen ik dit eenmaal had geÃ¯nstalleerd was het alweer 6u en dat was etenstijd.

### Kwartaalmeeting (ISKA)

Na een heerlijk buffet met mijn mede collega's was het tijd voor de kwartaalmeeting. Deze was om 7u. Hier waren ook 2 collega's uit Nederland aanwezig, een van HR en eentje voor branding. Ik kwam hier binnen en wist niet wat ik moest verwachten; er lagen kleine kladblokjes klaar om gebruikt te worden (zie afbeelding).
![Kladblokje](https://raw.githubusercontent.com/zwolsman/g-log/master/img/IMG_5197.JPG "Kladblokje")
Dit kladblokje had vooral betrekking op de branding. Info Support wil meer zijn best gaan op het gebied van branding. Na deze avond ben ik naar huis gegaan en meteen naar bed; het was een lange dag.

## Dag 4, 6-9-2018

### MEER BLOCKCHAIN!

Na het inlezen gister nog ik niet wachten met beginnen. Ik wilde het echt graag begrijpen. Ik heb eerst lopen sukkelen met de blockchain daadwerkelijk lokaal werkend te krijgen. Uiteindelijk had ik een guide gevonden, ik was eerst bezig met op het `--testnet` te komen van ethereum (dit is nog steeds een _online_ blockchain) maar dat was helemaal niet de bedoeling. Ik kwam na het lezen van de blog post [How To: Create Your Own Private Ethereum Blockchain](https://medium.com/mercuryprotocol/how-to-create-your-own-private-ethereum-blockchain-dad6af82fc9f) erachter hoe het moest. Ik heb de volgende instructies gebruikt:

#### Genesis file

```json
{
  "config": {
    "chainId": 1994,
    "homesteadBlock": 0,
    "eip155Block": 0,
    "eip158Block": 0,
    "byzantiumBlock": 0
  },
  "difficulty": "400",
  "gasLimit": "2000000",
  "alloc": {
    "7b684d27167d208c66584ece7f09d8bc8f86ffff": {
      "balance": "100000000000000000000000"
    },
    "ae13d41d66af28380c7af6d825ab557eb271ffff": {
      "balance": "120000000000000000000000"
    }
  }
}
```

#### Commando's

```bash
murf@Marvins-MacBook-Pro: [~/info-chain] $ geth --datadir ./data init ./myGenesis.json # Initialize blockchain

murf@Marvins-MacBook-Pro: [~/info-chain] $ geth --datadir ./data --networkid 1114 console 2>> eth.log # Daadwerkelijk starten van de blockchain
```

Dit opende een terminal van mijn eigen, lokale, werkende blockchain! Ik was verbaasd en blij! Ik kwam erachter dat er een `coinbase` was en die moest ingevuld zijn. Ik vulde het commando `eth.coinbase` in, dit leverde jammer genoeg `null` op.. Hoe moet dit?!

Het was vrij simpel. Je moet een lokale wallet aanmaken (account) waarin de blockchain zijn coins in opslaat (ether in dit geval). Dit doe je simpelweg door het volgende commando uit te voeren:

```bash
> personal.newAccount("<YOUR_PASSPHRASE>")
```

Dit zorgde meteen voor het invullen van de coinbase en het minen kon beginnen. Waarom? Je hebt punten nodig om transacties te doen op het netwerk. Mijn lokale netwerk staat dus echt lokaal en weet niets van de buiten wereld dus hoe kom je aan die punten? Door te minen! Met deze gegeneerde punten kan je dan `smart contracts` laten uitvoeren (dit is wat ik begreep van mijn bronnen hierboven). Hier was ik nog niet aan toe, ik moest eerst beginnen met minen.

```bash
> miner.start()
```

Dit startte het minen en de ether kwam binnen stromen. Het was niet meteen, het moest eerst nog iets opbouwen (DAG, geen idee wat dat is..?). Ik heb de log hieronder toegevoegd voor meer informatie. Zoals je ziet begon het minen naar anderhalve minuut!

```log
INFO [09-06|09:25:04.572] Generating DAG in progress               epoch=0 percentage=99 elapsed=1m36.498s
INFO [09-06|09:25:04.575] Generated ethash verification cache      epoch=0 elapsed=1m36.501s
INFO [09-06|09:25:05.437] Successfully sealed new block            number=1 hash=394c39â€¦381da3 elapsed=1m37.952s
INFO [09-06|09:25:05.437] ðŸ”¨ mined potential block                  number=1 hash=394c39â€¦381da3
INFO [09-06|09:25:05.438] Commit new mining work                   number=2 uncles=0 txs=0 gas=0 fees=0 elapsed=199.778Âµs
INFO [09-06|09:25:07.078] Successfully sealed new block            number=2 hash=b05d7eâ€¦fb6a4f elapsed=1.640s
INFO [09-06|09:25:07.079] ðŸ”¨ mined potential block                  number=2 hash=b05d7eâ€¦fb6a4f
INFO [09-06|09:25:07.079] Commit new mining work                   number=3 uncles=0 txs=0 gas=0 fees=0 elapsed=158.549Âµs
INFO [09-06|09:25:07.568] Successfully sealed new block            number=3 hash=02490câ€¦cf97f0 elapsed=488.324ms
INFO [09-06|09:25:07.568] ðŸ”¨ mined potential block                  number=3 hash=02490câ€¦cf97f0
INFO [09-06|09:25:07.569] Commit new mining work                   number=4 uncles=0 txs=0 gas=0 fees=0 elapsed=169.166Âµs
INFO [09-06|09:25:07.877] Successfully sealed new block            number=4 hash=120374â€¦eacd92 elapsed=308.442ms
INFO [09-06|09:25:07.878] ðŸ”¨ mined potential block                  number=4 hash=120374â€¦eacd92
```

Als ik nu kijk wat mijn waarde was in mijn console zag ik het snel verhogen. Hieronder zie je output van de console. Hier zie je ook dat ik er maar 1 account op heb en deze werd gevuld.

```bash
Welcome to the Geth JavaScript console!

instance: Geth/v1.8.14-stable/darwin-amd64/go1.10.3
coinbase: 0x691a8c8438e67d37999f21a65bc91f41504a9aed
at block: 833 (Thu, 06 Sep 2018 09:41:39 CEST)
 datadir: /Users/murf/info-chain/data
 modules: admin:1.0 debug:1.0 eth:1.0 ethash:1.0 miner:1.0 net:1.0 personal:1.0 rpc:1.0 txpool:1.0 web3:1.0

> eth.accounts
["0x691a8c8438e67d37999f21a65bc91f41504a9aed"]
> eth.blockNumber
833
> eth.getBalance(eth.coinbase)
2.499e+21
```

### Web3j

Nadat de blockchain draaide moest ik een verbinding maken tussen ontwikkel omgeveing en de blockchain wereld. Dit werd gedaan door Web3 te gebruiken. In de bronnen hierboven kwam web3j naar voren en heb ik dat geprobeerd. Ik heb een test project aangemaakt. Het enige wat deze moest doen was de accounts ophalen.

Ik begon met de GitHub door te lezen die hier te vinden is: [web3j/web3j](https://github.com/web3j/web3j)

```kotlin
import org.web3j.protocol.Web3j
import org.web3j.protocol.http.HttpService

fun main(args: Array<String>) {
    val web3 = Web3j.build(HttpService())

    val accounts = web3.ethAccounts().send()

    println(accounts.accounts.joinToString ())
}
```

Dit werkte natuurlijk **NIET**, waarom niet vraag je je af? Hoe de blockchain gestart werd was zonder `rpc api` en dat is hoe deze web3j implementatie communiceert. Ik heb de blockchain afgesloten en opnieuw opgestart met andere parameters.

```bash
murf@Marvins-MacBook-Pro: [~/info-chain] $ geth --datadir ./data --networkid 1114 --rpcapi personal,db,eth,net,web3 --rpc console 2>> eth.log
```

Eenmaal opgestart kon ik de accounts zien. Dit was er natuurlijk maar een en dit was de output

```log
SLF4J: Failed to load class "org.slf4j.impl.StaticLoggerBinder".
SLF4J: Defaulting to no-operation (NOP) logger implementation
SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.
0x691a8c8438e67d37999f21a65bc91f41504a9aed

Process finished with exit code 0
```

### Slack intergratie

Het uiteindelijk systeem moet geÃ¯ntegreerd in Slack zijn.. maar hoe doe je dat nou eigenlijk? Ik ben begonnen met het bekijken van bonusly in Slack. Hier zag ik dat er een simpel commando `/give +100 @user`. Hoe maak je zo'n commando? Wat doet het? Waar leeft het? Dit waren dingen die ik uit moest zoeken. Ik ben begonnen met de [officiÃ«le Slack API documentatie](https://api.slack.com) te lezen. Hier zie je al aan de linkerkant onder het kopje _"App features"_ Slash Commando's staan. Mij leek het logisch dat dit het was natuurlijk. Na de documentatie te lezen van het desbetreffende onderwerp wist ik het zeker; dit is het!

### Hoe werkt zo'n slash commando?

Het werkt vrij simpel. Alle commando's die beginnen met een `/` worden doorgegeven via dit mechanisme. Wat je hier in moeten stellen zijn:

- **Command**

  Hoe ziet het commando er uit? Ik heb voor `/give` gekozen (hetzelfde als bonys.ly)

- **Request URL**

  Dit heeft iets meer diepgang dan dat het lijkt te hebben. Omdat alles publiekelijk toegankelijk moest zijn en ik lokaal aan het werk was moest dit anders. Ik heb er voor gekozen om `ngrok` te gebruiken. Dit wordt verder toegelicht in een ander hoofdstuk.

- **Short description**

  Korte beschrijven van het commando

- **Usage hint**

  Gebruik hint, ik heb voor de volledige syntax gekozen hoe ik wens het binnen te krijgen
  `/give +100 @username (@username2, etc..) reason #hashtag`

- **Escape usernames,channels & links**

  Dit is een optie die ik eerst niet zag.. Door deze optie over het hoofd te zien ben ik de hele dag bezig geweest met overbodige complexiteit werkend te krijgen.

Eenmaal dit ingesteld kon ik requests ontvangen. Ik heb een web handler gemaakt in Spring met Kotlin en kreeg mijn eerste data binnen. De basis handler zag er uit als volgt:

```kotlin
@RestController
class GiveSlashCommand(private val slackApi : SlackApi) {
    val logger = LoggerFactory.getLogger(this::class.java)!!

    @RequestMapping(value = "/slash-command", method = [RequestMethod.POST], consumes = [MediaType.APPLICATION_FORM_URLENCODED_VALUE])
    fun onReceiveSlashCommand(@RequestParam("token") token: String,
                        @RequestParam("team_id") teamId: String,
                        @RequestParam("team_domain") teamDomain: String,
                        @RequestParam("channel_id") channelId: String,
                        @RequestParam("channel_name") channelName: String,
                        @RequestParam("user_id") userId: String,
                        @RequestParam("user_name") userName: String,
                        @RequestParam("command") command: String,
                        @RequestParam("text") text: String,
                        @RequestParam("response_url") responseUrl: String):       String {
                                return "OK"
                              }
}
```

Zoals je ziet zat hier geen logica achter maar kon ik wel zien wat ik binnen kreeg. Omdat ik de optie `Escape usernames, channels & links` krijg ik plaintext mentions binnen. Dit betekende dat ik gewoon een `@gebruikersnaam` kreeg en deze niet kon mappen aan een user id. Hoe ik dit opgelost heb? Als mijn applicatie gestart werd gebruikte het de officiÃ«le Slack Web API om alle gebruikers van de desbetreffende workspace op te halen en te mappen in een in-memory database met gebruikersnaam, user id en email. Deze data had ik nodig.

Met de plaintext mention kon ik de gebruikersnamen eruit halen door een RegEx. Deze matches werden dan opgezocht in de vooraf opgehaalde data en zo kon ik er toch een email aan koppelen. Dit is natuurlijk niet de juiste manier want als er een nieuwe gebruiker zich aanmeld of een mention is die niet bestaat gaat het fout. Toch kon ik nergens vinden hoe het _wel_ moest totdat ik dit aan het schrijven was. Omdat ik goed door de opties heen las kwam ik er achter dat je dus wel het gebruikers id mee kan sturen waardoor je met een simpele request het profiel op kan halen en zo kan koppelen aan een email. Dit is iets voor morgen om verder uit te werken.

## Dag 5, 7-9-2018

### Slack dag

Om de dag te beginnen gaan we de fout van gister is oplossen. Het eerste wat gedaan moet worden is de RegEx aanpassen om de nieuwe _escaped_ mentions te vinden. Deze RegEx is opzich niet heel lastig en zal de volgende zijn: `<@([WU].+?)>`.

Een bericht ziet er als volgt uit met mentions

```log
dit is tekst en dan komt nu een mention <@UCNAPUFHT|joell> en dit is een andere mention <@UCNAJL7FF|murf> dit is een channel <#CCPG179GE|random>
```

Zoals je ziet is een mention een begin met `<@` en eindigt met een `>`. Dat is precies wat deze RegEx doet met een check dat een username id altijd met een **W** of een **U** begint. Ik heb deze RegEx getest met [RegexPal](https://www.regexpal.com). Dit is een website waarin je al je matches meteen ziet en live je RegEx kan aanpassen.

Nu ik makkelijk user id's kan ophalen uit een bericht kan ik ook een profiel ophalen en dus desbetreffende email. Toen heb ik met Benny overlegt welke data er op de blockchain zal komen en welke data er echt nodig is. Ik heb hier een diagram voor geschetst.

![Schets van data](https://raw.githubusercontent.com/zwolsman/g-log/master/img/IMG_9111.JPG "Schets van data")

De eerste vraag die Benny eigenlijk vroeg was, wie gaat de maandelijkse punten bijhouden? Het idee is dat er een x aantal punten vrijkomen per persoon per maand. Dus dat moet ergens bijgehouden worden.. maar waar? Dit is een probleem in ons achterhoofd te houden. Ik wou eerst een proof of concept maken met interactie tussen Slack & de blockchain.

### Solidity

Nu ik de user id's om kon vormen naar e-mails (en die gebruikt kunnen worden als id's) is de volgende stap ze ergens opslaan. Hoe doe je dit? Met smart contracts. Ik had de vorige dag al het een en ander meegekregen maar wist al niet meer precies hoe. Wat ik wel nog wist was het volgende interactie scenario.

> **Slack -> Web API (Spring Boot in Kotlin) (-> ...?) -> Blockchain**

Het eerste gedeelte (Slack -> Web API) had ik al een PoC van, ik kreeg berichtjes binnen, zette de user id's om naar email adressen en tijd voor de volgende stap. Ik begon met [de documentatie](https://solidity.readthedocs.io/en/develop/introduction-to-smart-contracts.html) van Solidity te lezen. Hier stond een simpel voorbeeld meteen in (zoals eerder aangegeven ik doe liever dan dat ik lees dus dit begon ik te bekijken)

```solidity
pragma solidity ^0.4.0;

contract SimpleStorage {
    uint storedData;

    function set(uint x) public {
        storedData = x;
    }

    function get() public view returns (uint) {
        return storedData;
    }
}
```

Dit was een contract die gewoon een nummertje opsloeg. Dat was alles! Ik keek er naar en snapte wel hoe het werkte, de taal had uiteraard veel beÃ¯nvloeding van C++, Python en JavaScript en daardoor voelde het wel bekend. Ik dacht bij mezelf, hoe moeilijk is het om een array van structs op te slaan waarin staat wie welke bonus heeft weggegeven. Ik vond dit wel een mooi idee om mee te starten.

#### Wat komt hier bij kijken?

Het idee is vrij simpel, een array van structs maar hoe interacteer je hier mee? Hoe voeg je een element toe aan de array? Dat zijn vragen die mij meteen binnen schoten. Ik begon met het lezen van hoe je een struct definieert. Dit is vrij simpel.

```solidity
 struct Bonus {
    string from;
    string to;
    uint256 points;
  }
```

Dit struct was mijn begin. Hoe maak ik er een array van die te gebruiken was in het contract zelf? Ook vrij simpel.

```solidity
Bonus[] public bonusses;
```

Dit was een publieke array. Waarom publiek? Dan wordt er automatisch een gratis `getter` gegeneerd. Dan kan je op index gebaseerd een element ophalen. Nu nog iets in de array stoppen, hoe moeilijk kan het zijn!

```solidity
function giveBonus(string from, string to, uint256 points) public {
  bonusses.push(Bonus(from, to, points));
}
```

Simpele functie die iedereen begrijpt. Ik hoef het niet verder uit te leggen. Dan doe je alles in een `Contract` (dit is eigenlijk gewoon een `Class`) en BAM! Je eerste smart contract!

```solidity
pragma solidity ^0.4.0;

contract InfoBonus {
    struct Bonus {
        string from;
        string to;
        uint256 points;
    }

    Bonus[] public bonusses;
    function giveBonus(string from, string to, uint256 points) public {
        bonusses.push(Bonus(from, to, points));
    }
}
```

#### Wat nu..?

OkÃ©, je hebt je contract en je wil deze deployen en gebruiken, maar hoe? Solidity heeft zijn eigen compiler genaamd `solc`. Ik heb deze aangeroepen met het volgende commando

```bash
murf@Marvins-MBP: [~/Projects/info-chain-api/contracts] $ solc test.sol --bin --abi --optimize -o ./bin
```

Dit maakt een _.bin_ en _.abi_. Deze bestanden heb je nodig om het contract te deployen en daarna mee te interacteren. Ik had mijn eigen `geth` node nog draaien met mijn privÃ© blockchain. Laten we die gebruiken! Hoe werkt dit allemaal? Geen idee. Ik wist wel dat de web3j een manier had om een smart contract te deployen; laten we daar is verder naar kijken.

```java
Web3j web3 = Web3j.build(new HttpService());  // defaults to http://localhost:8545/
Credentials credentials = WalletUtils.loadCredentials("password", "/path/to/walletfile");

YourSmartContract contract = YourSmartContract.deploy(
        <web3j>, <credentials>,
        GAS_PRICE, GAS_LIMIT,
        <param1>, ..., <paramN>).send();  // constructor params
```

OkÃ©, dit snap ik, dit is Java. Hoe kom ik aan credentials? Oh ja! Die had ik gister aangemaakt.. maar waar staat dat? In de keystore van de blockchain en deze had ik in de map `~/info-chain/data` opgeslagen. Ik vind daar 1 bestand in genaamd _UTC--2018-09-06T07-22-52.415241284Z--691a8c8438e67d37999f21a65bc91f41504a9aed_ dus dit zal wel mijn wallet zijn.

Nu moest ik alleen nog van de _.bin_ en _.abi_ iets maken waarmee ik in mijn project dus een wrapper had. Dit doet web3j dus ook. Dit kan je doen via een CLI die eenvoudig te installeren is op een MacBook. De volgende commando's deden het al.

```bash
murf@Marvins-MBP: [~] $ brew tap web3j/web3j
murf@Marvins-MBP: [~] $ brew install web3j
```

Op de README van web3j kon je een voorbeeld vinden hoe je dan een wrapper genereerde.

```bash
murf@Marvins-MBP: [~/Projects/info-chain-api/contracts] $ web3j solidity generate ./bin/InfoBonus.bin ./bin/InfoBonus.abi -o ../src/main/java -p com.zwolsman.infochain
```

Nu had ik dus Java Wrappers die het mogelijk maakte om met mijn contract te interacteren via Java (Kotlin in mijn geval). Ik heb dus `web3` gedeelte, de `credentials` en `params` heb ik niet nodig (dat zijn de constructor params van je contract). Nu alleen nog de `GAS_PRICE` en `GAS_LIMIT`. Geen idee wat dit was maar het moest wel een `BigInteger` zijn dus ik zette 1 en 10 neer. Het resultaat wat je terug krijgt is een contract instantie waar je dingen mee kan doen. Ik wist dat een smart contract een adres kreeg en dat je die in de toekomst moest gebruiken om het opnieuw aan te spreken. Dit gaf ik dus terug als feedback zodat ik wist dat het gelukt was.

```kotlin
val result = InfoBonus.deploy(web3, credentials, GAS_PRICE, GAS_LIMIT).send()
logger.info("Deployed contract; address: ${result.contractAddress}")
return "OK, address: ${result.contractAddress}"
```

De eerste paar x ging dit niet goed, `GAS_PRICE` was te laag, te hoog of gewoon niet goed en hetzelfde voor `GAS_LIMIT` maar ik wist gewoon echt niet wat dit moest zijn. Na wat spelen met nummertjes vond ik dat 10.000 werkte als price en 100.000 als limit. Nou! Het contract is gedeployed!

Kan ik dit ergens zien? Ik ben erg visueel ingesteld en een hash dat iets gelukt is zegt mij niet zoveel. Ik ben dus opzoek gegaan voor een `Blockchain explorer`, ik had het idee dat dit dus in zijn eigen block leefde en ik daar publiekelijk in kon kijken wat het nou deed etc. Na wat Google werk kwam ik al snel uit op [Ganache](https://www.truffleframework.com/ganache).

> Quickly fire up a personal Ethereum blockchain which you can use to run tests, execute commands, and inspect state while controlling how the chain operates.

Dit klinkt de oplossing voor mij, dit betekende wel dat ik de `geth` node uit moest zetten en dit "ding" werkend moest krijgen. Na installatie en opstarten kreeg ik het scherm met 10 accounts en elk 100 ETH erop, geen idee waar ze vandaan kwamen.

![Ganache account overzicht](https://raw.githubusercontent.com/zwolsman/g-log/master/img/ss_ganache_1.png "Ganache account overzicht")

Na het aanpassen van de instellingen om de server om de standaard poort (8545) te gebruiken begon ik mijn testen. Het eerste probleem waar ik tegenaan liep.. Die credentials ik inlaadde van mijn lokale keystore klopte natuurlijk niet! Hoe gebruik ik een account die ik hier voor me zie in mijn code? De oplossing was makkelijk; elk account had een private key. De private key kon ik ook gebruiken om credentials aan te maken i.p.v. in te laden via een file.

```kotlin
val credentials = Credentials.create("c6d79ddae40f8c9b9aa619d55c149f2724e28278b5ee3d4e1eb816d44398c5bc")
```

Nu ik weer geldige credentials had update ik de `GAS_PRICE` en `GAS_LIMIT` naar de getallen die ik zag in de interface van Ganache. Ik startte de applicatie en alles werkte! Ook zag ik nu in de interface van Ganache wat er gebeurde! Dit is wat ik nodig had.

![Ganache transactions overzicht](https://raw.githubusercontent.com/zwolsman/g-log/master/img/ss_ganache_2.png "Ganache transactions overzicht")

Nu wou ik de bonusses uit de array halen maar dit kon alleen op index gebaseerd. Je kon _niet_ een hele array ophalen om hoge gas prices te voorkomen. Mijn idee was dus om een counter bij te houden, die op te halen van de blockchain en dan in mijn Kotlin project een for loop te maken. Eenmaal het contract aangepast te hebben moest ik dit weer opnieuw compilen met `solc` en daarna met `web3j` een nieuwe wrapper. Nu het niet meer nieuw was wist ik wat ik moest doen en kostte dit mij nog geen 5 minuten. Nu kon ik de bonussen die opgeslagen waren op de blockchain ophalen en weergeven! De volgende stap? Het correct parsen van de berichten van Slack om te bepalen hoeveel punten er gegeven zijn (dit had ik nu hardcoded op 10). Dit is weer voor maandag; mijn weekend begint!

## Dag 6, 10-9-2018

> Super inrelevant maar ik heb eindelijk een liedje gevonden die ik al heel lang zocht: [Lucid Dreams - Juice WRLD](https://itunes.apple.com/nl/album/lucid-dreams/1407165109?i=1407165118&l=en)

### Begin van de dag.. RegEx!

Ik ben begonnen waar ik achter ben gebleven de vorige keer. Ik ben verder gegaan met een PoC op te stellen die mentions eruit filtert en weergeeft in Slack. Ik heb de RegEx aangepast zodat die niet meer hardcoded value's opslaat maar daadwerkelijk ontvangen punten.

```RegEx
\+(?<points>\d+)(?<mentions>(?:\s(?:<@(?:[WU].+?))>)+)\s(?<comment>.*)
```

Hier zie je capture groups met namen, de syntax hoe het commando wordt aangeroepen is `/give +100 @user @user2 text text #hashtag` and dit wordt er nu uitgehaald. Voor de repeating group van user haal ik alle mentions eruit; de RegEx implementatie is zo dat die de laatste value pakt van de groep dus dit doe ik nogmaals apart.

```RegEx
<@(?<id>[^|]+)(?:\|(?<displayname>.+?))>
```

Hiermee haal ik de `1..n` mentions eruit zodat die gebruikt kunnen worden in het opslaan van de bonus. Het contract heeft nu ook veld gekregen voor het commentaar dat bijgeleverd is.

#### Message formatting

Nu ik de gebruikers goed opsloeg wou ik ook wat doen aan de formatting van messages. Slack heeft een [hele brede](https://api.slack.com/docs/messages) uitleg over hoe je messages kan formateren en hier heb ik veel aan gehad. Ook de [Message Builder](https://api.slack.com/docs/messages/builder) kwam goed van pas. Het uiteindelijke resultaat wat ik heb behaald is te zien hieronder. De markdown werkt nog niet, dit moet ik nog verder uitzoeken hoe het werkt, wel heb ik de kleur al werkend, dit maakt gebruik van attachments.

![Slack bericht](https://raw.githubusercontent.com/zwolsman/g-log/master/img/ss_slack_message_design.png "Slack bericht")

### Blockchain events

Bonus.ly heeft een feature dat als iemand de meeste punten heeft dit gebroadcast wordt. Ik was benieuwd hoe ik dit kon gaan implementeren in Solidity. Ik had gezien dat er [events](https://solidity.readthedocs.io/en/v0.4.24/contracts.html#events) waren maar hoe werkt dit precies, en nog preciezer: hoe [werkt dit](https://docs.web3j.io/filters.html) met Web3J?

Na wat uitzoek werk kwam ik er achter dat ik een simpel veld moest aanmaken die bijhield wat het hoogste aantal was, en wie dit was. Dit heb ik in het contract gedaan met het volgende

```solidity
event NewTopReceiver(string name);

mapping(string => uint) bonusReceivers;
uint public highestReceived;
string topReceiver;
```

In de mapping hou ik bij wie hoeveel heeft ontvangen en in de andere 2 variables heb ik het hoogst totaal ontvangen en wie dat is. Ook is er een `NewTopReceiver` event. Deze wordt aangeroepen zodra er iemand is die een hoger totaal heeft dan de vorige. Dit wordt nu gecheckt bij elke x als er een bonus wordt opgeslagen.

```solidity
bonusses.push(Bonus(from, to, points, comment));
bonusReceivers[to] += points;

if(bonusReceivers[to] > highestReceived) {
    highestReceived = bonusReceivers[to];
    topReceiver = to;
    emit NewTopReceiver(to);
}
```

Nu ik dit heb aangepast moest het contract opnieuw gecompileerd worden met `solc` en een nieuwe wrapper met de `web3j` console library. Omdat ik deze stap vaker op een dag heb gedaan heb ik een klein shell scriptje (voor de [Fish Shell](https://fishshell.com)) geschreven. Dit gaat door alle `*.sol` bestanden en compileert die met de `solc` compiler en daarna nog eens met de `web3j`.

```bash
#!/usr/bin/env fish

for file in *.sol
    solc $file --bin --abi --optimize -o ./bin --overwrite
end

for file in ./bin/*.bin
    web3j solidity generate $file ./bin/(basename $file .bin).abi -o ../src/main/java -p com.zwolsman.infochain
end
```

### Events in web3j

In web3j is er een api om events aan te spreken. Deze heeft een filter nodig.. Een filter heeft een contract address nodig (**zonder** 0x, vandaar de `substring(2)`) en een instantie van het contract. Zoals bij de vorige functies zal de instantie ingeladen worden met de `PRIVATE_KEY` en het `CONTRACT_ADDRESS`. Eenmaal ingeladen kan je subscriben op het event dat gecreÃ«erd is in het contract. Hier krijg je dan de value's binnen.

```kotlin
val web3 = Web3j.build(HttpService())  // defaults to http://localhost:8545/
val credentials = Credentials.create(PRIVATE_KEY)
val contract = InfoBonus.load(CONTRACT_ADDRESS, web3, credentials, GAS_PRICE, GAS_LIMIT)
val filter = EthFilter(DefaultBlockParameterName.EARLIEST, DefaultBlockParameterName.LATEST, CONTRACT_ADDRESS.substring(2))
contract.newTopReceiverEventObservable(filter).subscribe {

    logger.info("NEW TOP RECEIVER: ${it.name}")
}
```

Nu ik binnen krijg wanneer er een nieuwe top receiver is kan ik hier acties aan hangen. Dit is voor een later stadia.

### Solidity verder leren

Ik merkte snel na wat pogingen dat ik Solidity nog niet helemaal begreep waardoor ik naar GitHub ben gegaan. Hier heb ik een tutorial reeks gevonden van 27 episodes. Op de [willitscale/learning-solidity](https://github.com/willitscale/learning-solidity) repo staan de uitgewerkte episodes en links naar elke episode dus deze kwam goed van pas. Ik heb deze reeks tot nu toe t/m aflevering 7 bekeken.

### Feedback PvA

Ik heb vandaag ook feedback van mijn PvA ontvangen van Benny. Ik heb deze echter nog niet kunnen verwerken omdat ik mezelf helemaal had gestort op solidity. Deze feedback zal morgen vroeg verwerkt worden zodat het nog eens besproken kan worden op onze afspraak.

## Dag 7, 11-9-2018

### PvA feedback

Ik ben de dag begonnen met de feedback van mijn PvA te verwerken. Eenmaal de verwerkte feedback is daarna besproken met de technisch begeleider.

### Gesprek met Benny

Ik had vandaag een gesprek met Benny, dit is de tweede keer dat we bij elkaar kwamen. We hebben gediscussieerd over het integreren van meerdere services (niet alleen Slack) en hoe we dit nu gaan aanpakken. Hieronder zie je een foto van het whiteboard waar het idee op staat.

\<FOTO VOLGT>

Eenmaal geworsteld over hoe dit in zijn werk zou gaan heb ik een overzichtje gemaakt over hoe de data gaat lopen. Dit heb ik gebruikt als voorbeeld hoe het in de code opgezet gaat worden. Alles moet generiek zijn waardoor er dus meerdere services toegevoegd kunnen worden.

\<FOTO VOLGT 2>

### Nieuw project

Alles wat ik tot nu toe heb gemaakt was een Proof of Concept, een manier voor mezelf om de stof beter te begrijpen. Nu ik een beter inzicht heb wat de opdracht precies in gaat houden ben ik een nieuw project begonnen. Dit project leeft nu ook op [Azure DevOps](https://is-belgie.visualstudio.com/BBB). Dit is de manier van werken binnen Info Support. Ook hebben we het beestje een naam gegeven!

> **BBB** (Benny's Blockchain Bonusses)

Het nieuwe project is beter gestructureerd en maakt gebruikt van best-practices betreft programmeren. Ook is het contract opnieuw geschreven, deze x ook iets overzichtelijker en nettere variable namen.

## Dag 8, 12-9-2018

### Message formatting v2

Vandaag ben ik bezig geweest met het formateren van commando reacties en het asynchroon reageren. Omdat operaties op de blockchain niet instant zijn maar juist langer duren is dit heel belangrijk. Een functie aanroepen op een smart contract moet gevalideerd worden door meerdere nodes, communicatie tussen deze nodes heeft een latency en zal daardoor dus langer duren.

De implementatie van Slack is als volgt; als je een commando binnen krijgt moet je binnen 3 seconde een reactie terug sturen anders krijg je een `Time out exception`. In het commando zit een `response_url`, hier kan je na ontvangst 5x een bericht naar sturen binnen 30 minuten. Met dit in het achterhoofd heb ik een `SlackCommandContext` gemaakt. Een `CommandContext` heeft de context van een commando, deze bevat op zijn minst de sender, het bericht en een respond functie. Voor Slack zit hier dus ook een `response_url` parameter in.

```kotlin
abstract class CommandContext {
    abstract val sender: String
    abstract val message: String
    abstract val identityService: IdentityService
    abstract val formatter: ServiceFormatter

    abstract fun respond(response: Any)
}

data class SlackCommandContext(override val sender: String, override val message: String, val responseUrl: String, override val identityService: IdentityService, override val formatter: ServiceFormatter) : CommandContext() {
    companion object {
        private val restTemplate = RestTemplate()
    }

    override fun respond(response: Any) {
        val formatted = formatter.format(response)
        println("Formatted: $formatted")
        val result:String? = restTemplate.postForObject(responseUrl, formatted)
        println("Response: $result")
    }

}
```

Zo zie je dus hoe de `respond` methode gemaakt is voor _Slack_ specifiek. Deze context wordt bijvoorbeeld gebruikt in de `ListBonusCommand` als volgt.

```kotlin
class ListBonusesCommand : Command("list") {

    override fun invoke(context: CommandContext) : String? {

        BBBCore.contract.bonusCount().observable()
                .flatMap {
                    Observable.range(0, it.toInt())
                }
                .flatMap { id -> BBBCore.contract.bonuses(BigInteger("$id")).observable() }
                .map { ... }
                .map { Bonus(it)  }
                .toList()
                .subscribeOn(Schedulers.newThread())
                .subscribe({ context.respond(it)},
                { err ->
                    println("ERROR!! $err")
                }, {
                    println("Loaded bonuses. Done")
                })
        return "Loading bonuses.."
    }

}
```

Hierboven zie je dus hoe er wordt gereageerd en hoe het asynchrone gedeelte werkt. De invoke functie geeft een String terug, dit is de reactie die binnen 3 seconde binnen zal komen. Hij zegt dus tegen de gebruiker `Loading bonuses..`. Dan gaat het smart contract zijn ding doen, die haalt op hoe veel bonuses er zijn (dit is een value in het contract). Dan maakt die een range aan en voor elk cijfertje in de range haalt die de value op (dit is een nieuwe observable). Om een array van observable te mappen naar een array van value's wordt `flatMap` gebruikt. Om te zorgen dat het niet blocking is wordt er gespecificeerd dat de subscribe methode op een nieuwe thread is waardoor het non-blocking is.

Dan heb je de service specifieke formatters nog. Het resultaat wat uit het commando hierboven komt is een `List<Bonus>` maar hoe moet ik die formateren? Voor Slack is de volgende implementatie.

```kotlin
@Service
class SlackFormatter : ServiceFormatter() {
    override fun formatString(input: String): Any {
        return mapOf("text" to input)
    }

    override fun formatBonuses(input: List<Bonus>): Any {
        return mapOf("attachments" to input.map { BonusWrapper(it) })
    }


    data class BonusWrapper(val text: String, val color: String, val mrkdown_in: List<String>, val actions: List<Map<String, String>>) {
        constructor(bonus: Bonus)
                : this("*${bonus.from}: +${bonus.points} ${bonus.to}* ${bonus.comment}",
                "good",
                listOf("text"),
                listOf(
                        mapOf("name" to "game",
                                "text" to "Add to this bonus",
                                "type" to "button",
                                "value" to "chess",
                                "style" to "primary")
                )
        )
    }
}
```

Deze formatter maakt dus een response payload aan die gebruikt wordt bij de `CommandContext` om te versturen. Dit zal dus anders zijn per service. Het uiteindelijke resultaat ziet er als volgt uit.

![Bonus lijst bericht](https://raw.githubusercontent.com/zwolsman/g-log/master/img/ss_bonus_list.png "Bonus lijst bericht")

Zoals je ziet wordt er hier ook gebruik gemaakt van mentions. In Slack kan dus op de gebruikersnaam geklikt worden en zo doorverwezen worden naar de gebruiker. Om dit te doen is er een vertaalslag nodig. De id's die opgeslagen worden op de blockchain zijn de emails (globale unieke id's), om die terug te zetten naar de user id van Slack is ook een service nodig. Er van uitgaande dat elke service een service afhankelijke user id om kan zetten naar een email is er een `IdentityService` ontworpen. Deze zal de lokale id's gekoppeld met het email adres opslaan in de database zodat ze "gecached" zijn. Elke user id zal dus maar 1x gerequest worden aan een service en zal daarna uit de eigen database gehaald worden. Om dit dus ook zo generiek mogelijk te maken hoeft een service specifieke implementatie maar 2 dingen te kunnen.

1. **Local id > email id**

   Om een email op te halen is bij Slack is er een API call voor nodig. Deze call's zijn geimplementeerd door de library `com.github.seratch:jslack:1.1.5`. Deze worden dan aangeroepen.

2. ** Email id > local id**
   Dit is nodig voor het creÃ«ren van een mention. Als je de bonuses ophaalt dan staan de `from` en `to` values ingevuld als email. Om dan een mention te maken is het lokale id nodig.

De gehele implementatie ziet er als volgt uit

```kotlin
@Service
class SlackIdentityService(repo: AccountRepository) : IdentityService(repo) {
    override val serviceName: String = "Slack"

    @Value("\${slack.oathToken}")
    lateinit var token: String

    override fun resolveLocalId(localId: String): String  = Slack.getInstance().methods().usersInfo(UsersInfoRequest.builder().token(token).user(localId).build()).user.profile.email

    override fun resolveEmail(email: String): String = Slack.getInstance().methods().usersLookupByEmail(UsersLookupByEmailRequest.builder().email(email).build()).user.id

    override fun createMention(email: String) = "<@${loadLocalId(email)}>"

}
```

Je ziet dat de implementatie dus geen rekening hoeft te houden met welke database, bestaat die al in de database etc. etc.. dat doet de `IdentityService` base class.

### Universiteit van Nederland

Ik ben in de avond nog naar Universiteit van Nederland gegaan. Deze hadden een lezing in Amsterdam over Big Data. Een vriend van mij ([@joelluijmes](https://github.com/joelluijmes)) kwam met het idee en ik vond het wel tof. We zijn hier samen naar toe gereisd met de trein. Eenmaal aangekomen hebben we een biertje gepakt en zijn gaan zitten.

![Universiteit van Nederland](https://raw.githubusercontent.com/zwolsman/g-log/master/img/universiteit_nederland.jpeg "Universiteit van Nederland")

Er waren een 5-tal sprekers aanwezig. De sprekers waren eigenlijk allemaal niet technisch diepgaand, dit was ook wel te verwachten met zo'n breed publiek.

1. Wat is Big Data

   Dat was eigenlijk een introductie. Niet heel veel nieuws hier.

2. Big Data bij de overheid

   Dit was een talk door een vrouw van universiteit van Leiden die rechten had gestudeerd. Het ging vooral over het feit dat de systemen zoals nu werken niet goed werken, laat staan met big data. De problemen die ze omschreef over het huidige systeem is een oplossing voor vonden wij; de brakke oude systemen niet proberen te maken maar een nieuw systeem laten ontwikkelen met nieuwe kennis.

3. Psychiatrische hulp met big data

   Dit was een zeer interessante talk. Dit ging over als je alle data hebt over elke patiÃ«nt ooit kan je de nieuwe patiÃ«nt zijn intake, brief, symptomen hierin matchen en een soort voorspelling maken. Dit zal niet de gehele dokter vervangen maar een hulpmiddel zijn. Dit was een duidelijke vrouw die wist waar ze over sprak. Als dit zou lukken zou dit ook de meeste maatschappelijke impact hebben.

4. Flow.ai chat bots/genereren van tekst

   Hoe algoritmes eigenlijk nieuwsartikelen schrijven (robotjournalistiek) en hoe dit meer menselijk kon lijken. Zijn idee van woorden omzetten naar vectoren was wel super interessant, zelf nooit zo over nagedacht. Verder had die een demo met Alexa.

5. Weersvoorspelingen met big data

   Metrologen hebben heel veel data nodig, om een gepersonaliseerd weerbericht te maken (met een radii van 100m) is er eigenlijk meer data nodig (huidige ia 12.5km). Deze data hebben ze getest van mobieltjes af te halen (luchtvochtigheid, temperatuur etc.) en daarop gebaseerd een voorspelling; dit werkte! Ze hebben ook de data van taxi chauffeurs zijn ruitenwissers gebruikt voor meer lokale informatie. Eigenlijk kan je veel meer data gebruiken dan die nu gebruikt wordt en daardoor het weerbericht meer lokaal maken.

Toen het afgelopen was hebben we de trein terug gepakt en was ik om 0:10u thuis (in Eindhoven).

## Dag 9, 13-9-2018

### Thuiswerken

Omdat ik gister zo laat thuis was heb ik besloten in de ochtend thuis te werken. Ik ben begonnen met de blog van gister te schrijven, hier ben ik al wel even mee bezig geweest. Toen ben ik verder gegaan aan het BBB-project. Ik ben om 12u vertrokken richting Mechelen om hier na de pauze weer aan te sluiten in het kantoor.

### Kantoor

Eenmaal aangekomen op kantoor wou ik aan de integratie met CosmosDB beginnen. Cosmos DB is een database service van Azure, dat wordt hier gebruikt. Ik had hier geen ervaring mee en vroeg een account aan. Eenmaal ingelogd kom je op een dashboard met een groot aantal functies. CosmosDB was niet moeilijk te vinden. Ik vroeg aan Tom Vervoort hoe ik een database aan moest maken. Het is vrij simpel; je klinkt op "resource toevoegen" en dan kies je de service en vul je de gegevens in. Voor mijn Cosmos DB heb ik de volgende waardes ingevuld.

![CosmosDB Config](https://raw.githubusercontent.com/zwolsman/g-log/master/img/ss_cosmosdb_values.png "CosmosDB Config")

Hier zie je dus ook dat het een MongoDB API gebruikt, dat kwam goed van pas! Ervaring met MongoDB had ik wel al (bijvoorbeeld: kwetter, proftaak). Nu moest ik dus ook de web-api aanpassen om dus CosmosDB te ondersteunen. Microsoft heeft [Microsoft/spring-data-cosmosdb](https://github.com/Microsoft/spring-data-cosmosdb) package die je kan gebruiken. Deze heb ik geÃ¯mporteerd en de regel van MySQL connector weggegooid. De volgende aanpassingen waren ook relatief klein.

#### Account model

```kotlin
// Oud
@Entity
data class Account(@Id val email: String = "", @ElementCollection val identities: MutableMap<String, String> = mutableMapOf())

// Nieuw
@Document(collection = "accounts")
@DocumentIndexingPolicy(mode = IndexingMode.Lazy)
data class Account(@Id val email: String = "", val identities: MutableMap<String, String> = mutableMapOf())
```

#### Account repository

```kotlin
// Oud
@Repository
interface AccountRepository : JpaRepository<Account, String>

// Nieuw
@Repository
interface AccountRepository : DocumentDbRepository<Account, String> {
    fun findByEmail(email: String): List<Account>
    fun existsByEmail(email: String): Boolean
}
```

Zoals je ziet is het grootste verschil van `Entity` naar `Document` en dan de kleinigheidjes in het checken of een document al bestaat. Echter, is er een probleem. De code werkt nu.. write/read operaties lukken maar ik kan de database niet inzien. Het lijkt alsof de [Microsoft/spring-data-cosmosdb](https://github.com/Microso ft/spring-data-cosmosdb) library foutieve data erin stopt waardoor de Mongo shell een error krijgt. Ik weet nog niet hoe ik dit moet oplossen maar daar ga ik morgen naar kijken. De foutmelding is de volgende

```shell
globaldb:PRIMARY> show dbs;
bbb-cosmosdb  0.000GB
myotherdb     0.000GB
globaldb:PRIMARY> use bbb-cosmosdb;
switched to db bbb-cosmosdb
globaldb:PRIMARY> show collections;
accounts
bbb-collection
globaldb:PRIMARY> db.accounts.find();
Error: error: {
    "_t" : "OKMongoResponse",
    "ok" : 0,
    "code" : 1,
    "errmsg" : "Unknown server error occurred when processing this request.",
    "$err" : "Unknown server error occurred when processing this request."
}
globaldb:PRIMARY> db.accounts.find({});
Error: error: {
    "_t" : "OKMongoResponse",
    "ok" : 0,
    "code" : 1,
    "errmsg" : "Unknown server error occurred when processing this request.",
    "$err" : "Unknown server error occurred when processing this request."
}
```

## Dag 10, 14-9-2018

### CosmosDB probleem

Na enige tijd te zoeken heb ik het vandaag gewoon opgegeven. Zolang de applicatie werkt vind ik het _voor nu_ wel prima. Ik heb mezelf gefocust op functionaliteit.

### Uitgaves inzien

Ik heb het commando `/give spending (@user)` gecreÃ«erd. Dit is zodat je als gebruiker kan opvragen hoeveel je zelf of iemand anders hebt uitgegeven deze periode. Ik heb hier het smart contract weer voor moeten aanpassen.

#### Aanpassingen smart contract

Initieel wou ik de mapping user => uint public maken. Dit mag echter niet. Omdat een string een array van bytes is, is dat niet mogelijk. Je krijgt dan de foutmelding dan een array geen key mag zijn in een mapping (wat wel logisch is).

Hoe los je dit op? Je eigen `getter` schrijven en je mapping **private** maken.

```solidity
    mapping(string => uint) private _spendings; // Works
    mapping(string => uint) public spendings; // Does not work!

    // Own getter
    function getPointsSpent(string user)
        public
        view
        returns (uint) {
        return _spendings[user];
    }
```

Ook heb ik de logica dat je niet meer dan een x-aantal punten mag uitgeven geÃ¯mplementeerd. Dit is doormiddel van een `require`. Als die conditie niet voldaan is wordt de `gas` terug uitbetaald en kostte de interactie niets. Dus als iemand te veel punten wil geven zal dit niet doorgaan.

### Service identity provider extract mentions

Het volgende waar ik tegenaan liep was dat de implementatie van de `GiveBonusCommand` ook service afhankelijk was. Ik had hier de RegEx van de mentions hardcoded in zitten in het Slack formaat. Om dit uitbreidbaar te maken heb ik deze functionaliteit in de abstracte classe `IdentityService`. Nu gebruikt de `GiveBonusCommand` en de `SpendingsCommand` allebei de service onafhankelijke implementatie die geleverd wordt door de `CommandContext`.

## Dag 11, 17-9-2018

### Begin

Deze maandag begint met het updaten van mijn Git. De `Azure DevOps` geeft elke keer een melding als ik een push doe dus dit ga ik eerst is even oplossen. De huidige versie die ik nu gebruik is `git version 2.15.2 (Apple Git-101.1)`.

Ik heb de nieuwe git [hier](https://git-scm.com/download/mac) gedownload en geÃ¯nstalleerd. De versie die ik nu op mijn systeem draai is `git version 2.18.0`.

```bin
murf@Marvins-MacBook-Pro: [~/Projects/bbb-api (dev)] $ git push                                                          09:05:10
Total 0 (delta 0), reused 0 (delta 0)
remote: We noticed you're using an older version of Git. For the best experience, upgrade to a newer version.
To https://is-belgie.visualstudio.com/DefaultCollection/BBB/_git/BBB
   2ac0a79..d01b5cc  dev -> dev
```

### Azure

Ook heb ik nog verder een kijkje genomen in de Azure omgeving. Hier vind ik een resource genaamd `Ethereum Proof-of-Work Consortium`. Als ik de beschrijving moet lezen is dit een soort auto-deploy resource die een ethereum netwerk opzet met verschillende mining nodes en transaction nodes. Morgen in mijn wekelijkse gesprek met Benny ga ik bespreken of dit een optie is voor het deployen van de een blockchain.

### Orienteren op een andere team chat applicatie

Ik ben nu aan het kijken welke team applicaties er nog meer zijn om hier ook een PoC plug-in voor te schrijven. HipChat was een van de grote competitors met Slack en dit is [overgenomen](https://www.atlassian.com/blog/announcements/new-atlassian-slack-partnership) sinds kort. Uit de lijst [27 Top Slack Alternatives in 2018](https://www.workzone.com/blog/slack-alternatives/) heb ik gekeken welke een plugin systeem hebben.

### Facbook integratie

Ik ben aan de slag gegaan met Facebook integratie. Er is een package available genaamd [messenger4j/messenger4j](https://github.com/messenger4j/messenger4j). Deze library ziet er goed uit en kan ik berichten mee ontvangen en versturen. Toen ik het ben gaan implementeren ben ik erachter gekomen dat mijn structuur niet Generic genoeg was. Dit zal moeten veranderen; meer hier over in het kopje _Opnieuw designen_. De implementatie is straight forward, je maakt een app aan bij facebook, kopieert de `app secret`, `page access token` en je bedenkt een `validation token`. Hiermee maak je een instantie van een `Messenger` object en kan je mee interacteren.

Er is ook een [voorbeeld](https://github.com/messenger4j/messenger4j-spring-boot-quickstart-template) beschikbaar met Spring. Hier heb ik ook naar gekeken voor een head-start.

### Opnieuw desginen

Wat ik merkte met de facebook integratie is dat het niet abstract genoeg was. Ik had met de implementatie van Slack wel rekening gehouden met het generiek opzetten maar dit kon beter, beter gezegd: **dit moest beter**. Ik ben gaan na denken en heb gediscussieerd met Tom Vervoort, dit is een collega die bij mij op de kamer zat. Ik heb uitgeschetst wat ik in gedachte had en Tom vond dit goed. We hebben wel zitten stoeien over de benamingen. Als een bericht binnen komt van een 3rd-party service hebben we dit een `RemoteMessage` genoemd en als de lokale id's van die service omgezet zijn naar publieke id's (e-mails) is het een `GlobalMessage`.

De flow hoe het nu gaat is

- Controller

  Hier komt een `POST` binnen met data van een bericht, dit is service afhankelijk. Op dit moment zijn Slack en Facebook Workspace ingebouwd.

- Service

  De controller heeft een service waar die een trigger doet dat er een nieuw bericht is binnen gekomen. De service erft over van CommandProccessor. Dit is een abstracte classe die de commando's processed. De taak van de service is het omzetten van een `Message` naar een `Context`. Een `Context` bevat alle nodige informatie voor een commando af te laten vuren. Hier staat de `Message` in (Remote en Global), de `IdentityService`, `FormatterService` en de respond methode. Elke service (Slack, Facebook) zal zijn eigen implementatie hiervan hebben.

- CommandProccessor

  Deze kijkt naar alle geregistreerde commando's en kijkt of er een matcht met het binnengekomen bericht. Zo ja, haal de context op van de `Service` en `invoke` de command.

- Command

  De daadwerkelijke logica van een commando. Deze kan async nog berichten sturen met de `.respond(Any)` methode van de `CommandContext`

![Abstract messaging uitgewerkt](https://raw.githubusercontent.com/zwolsman/g-log/master/img/IMG_4191.JPG "Abstract messaging uitgewerkt")

## Dag 12, 18-9-2018

### Gesprek met Benny

Nu we weer een week verder zijn is het weer onze wekelijkse meeting. Hierin hebben we besproken wat ik afgelopen week heb gedaan. Dit was het volgende:

- Wat ik met Tom Vervoort heb besproken over het design van het systeem.
- Configuratie beheer van de applicatie (`application.properties`)
- API beveiligen
- Nieuwe commando implementaties
  - List spendings
  - Echo
- Implementeren van CosmosDB

Hij was zeer tevreden over de progress. We hebben ook afgesproken om aankomende week op de implementatie van 2 services te supporten. Als dat gelukt is, een build pipeline op te zetten. Ook is de bedoeling dat ik het plan van aanpak uiterlijk vrijdag opstuur voor een review. Dit zou dan na goedkeuring de definitieve versie worden.

#### Feedback

Benny zou graag willen dat ik hem per outlook calender uitnodig voor deze bespreking zodat het inzichtelijk is. Ook stelde hij voor om een dag van te voren even een bullitlist te sturen met de te bespreken punten. Dan kan hij zich er op voorbereiden en ik ook.

Verder was die zeer benieuwd naar de abstracte implementatie.

### Facebook bot

Er ben tegen een aantal problemen aangelopen vandaag. Ik ben er achter gekomen dat de `messenger4j` niet het hele event object heeft waardoor ik geen mentions kon ophalen in een bericht. Dit is echter van cruciaal belang in deze applicatie. Oplossing? Zelf een wrapper schrijven. Ik heb de documentatie gelezen van Facebook en heb een eigen versimpelde implementatie gemaakt. Een ander probleem was dat een `Recipient` niet een `Thread (groepsgesprek)` kon zijn waardoor berichten alleen persoonlijk afgeleverd konden worden. Dit is ook niet de bedoeling.

Ik heb deze tekortkomingen in mijn eigen implementatie opgenomen en een eigen domain model gemaakt die matcht aan de volledige JSON die geleverd wordt bij een event. Het versturen van een bericht is het construeren van een specifiek JSON model en dit heb ik ook nog gemaakt. Toen dit werkte kreeg ik een `echo` terug van de bot in de groepsapp.

![Facebook echo in groepsapp](https://raw.githubusercontent.com/zwolsman/g-log/master/img/ss_echo_fb.png "Facebook echo in groepsapp")

Zoals je ziet heet de bot BBB**v3**, dit kwam omdat ik de instellingen niet goed kreeg. Ik verwarde Facebook Messenger API met de Facebook Workplace API, dit kwam omdat dit allemaal hetzelfde is alleen net op een andere pagina terwijl je in de Facebook Messenger API wel de custom integration te zien krijgt die je hebt gemaakt pp Facebook Workplace.. Dit mogen ze van mij echt wel een stuk duidelijker maken..!

## Dag 13, 19-9-2018

> Ik begin ziek te worden.. Bijna niet geslapen vannacht en ibuprofen gehaald bij de aptoheek (hier hebben ze dat alleen in apotheken..)

Ik ben aan de slag gegaan met het mention systeem. Hier is echter niet veel informatie over te vinden in de facebook developer docs. De enige informatie die ik heb gevonden is [hier](https://developers.facebook.com/docs/workplace/integrations/custom-integrations/bots/). Hier wordt heel kort het volgende gezegd.

> `Bots can also @mention people to get their attention, and be @mentioned to kick off a specific workflow or ask a question.`

Dit is echter nergens te vinden hoe je dit implementeert. In de [voorbeelden repo](https://github.com/fbsamples/workplace-platform-samples) van Facebook zie je in de [Thanksbot/app.js](https://github.com/fbsamples/workplace-platform-samples/blob/master/ThanksBot/app.js) op regel **172** hoe een mention wordt opgebouwd.

```javascript
summary += `@[${recipient}] has received ${recipient_thanks_received} thanks in the last ${interval}. Heads up to @[${
  managers[recipient]
}].\n`;
```

Echter krijg ik dit niet werkend, ik heb het getest met de recipient id, user id, volledige gebruikersnaam, met `[]` en niks werkt.. Ik weet niet goed hoe ik dit op moet lossen.

De Slack formatter kan wel mentions goed formatten waardoor ze clickable zijn.

### Ziek naar huis gegaan

Ik ben om rond 1u ziek naar huis gegaan, ik wou nog langer blijven omdat ik een gesprek had ingepland met Ilse (procesbegeleider). We hebben ze afspraak verzet naar morgen en dat was geen probleem verder.

## Dag 14, 20-9-2018

> Ik ben weer terug op stage na mijn ziekmelding gister middag.

### CI/CD

IK ben bezig geweest met het builden en deployen van mijn applicatie. Azure DevOps heeft hier ingebouwde ondersteuning voor. Ik had niet de juiste rechten dus had even contact op genomen met Benny, die had dit meteen gefixt!

Nu heb ik een volledige build pipeline alleen de deployment lukt nog niet helemaal. Zoals jullie waarschijnlijk kunnen zien aan de commit tijd is het al laat genoeg en moet ik het gewoon met rust laten en morgen verder, en dat is wat ik ga doen! Er volgt morgen een update over de deployment, als dit werkt dan is mijn volledige CI/CD klaar.

### Gesprek met Ilse

Het gesprek met Ilse was heel gezellig. We hebben het over de stage gehad, hoe het gaat en of ik tegen problemen ben aangelopen (niet-technisch). Ik ben zeer enthousiast over Info Support en Mechelen in het algemeen. Ik heb het echt naar mijn zin en de opdracht bevalt ook goed. Ik heb uitgelegd wat mijn doel is en wat ik al heb staan, ze was wel verbaasd. Ik vond het wel leuk en hebben het ook over niet-stage dingen gehad, dit was uiteraard een "kennismakingsgesprek".

## Dag 15, 21-9-2018

> De dag begon met ongelofelijk lang in de file staan, gelukkig had ik [goede](https://itunes.apple.com/nl/album/10-punten-feat-hef-valsbezig-single/1429932123?l=en) [muziek](https://itunes.apple.com/nl/album/aicha-single/300866961?l=en) [in](https://itunes.apple.com/nl/album/the-chronic/6654037?l=en) [de](https://itunes.apple.com/nl/album/all-amerikkkan-bada%24%24/1210537350?l=en) [auto](https://itunes.apple.com/nl/album/2014-forest-hills-drive/940845223?l=en)

### CI/CD, the next day

OkÃ©, CI/CD is niet helemaal mijn ding; daar ben ik gewoon eerlijk in. De build pipeline opzetten was echt ongelofelijk makkelijk. Maar het deployen.. Man man man, wat een drama! Of ik ben gewoon te stom om het te begrijpen of ze doen toch echt iets mis bij Microsoft op het kantoor.

Ik heb contact opgenomen met Benny en [verchillende](https://docs.microsoft.com/en-us/azure/app-service/app-service-web-get-started-java) [tutorials](https://docs.microsoft.com/en-us/azure/app-service/web-sites-java-add-app) gelezen maar het werkte allemaal niet. Na de Benny-hulplijn te activeren is het gelukt. Het deployen is gelukt maar het opvragen van dingen werkt nog niet. Ik ben dit nu nog verder aan het onderzoeken.

![Screenshot van de build agent](https://raw.githubusercontent.com/zwolsman/g-log/master/img/ss_agent_log.png "Screenshot van de build agent")

### Pluralsight

Terwijl ik dit aan het uitzoeken was, was ik er even klaar mee. Wat doe je dan? Iets anders ICT gerelateerd. IK was benieuwd hoe goed ik in sommige dingen was en een vriend van mij had een [Skill IQ](https://www.pluralsight.com/product/skill-iq) test doorgestuurd.

Zo fanatiek als ik was, ben ik meteen begonnen met tests! De resultaten bevielen mij zeer goed. In de foto hier onder zie je dat ik het niveau **expert** scoorde op Node.JS, Android, Java en JavaScript. Spring & Angular was boven gemiddeld.

![Screenshot Skill IQ](https://raw.githubusercontent.com/zwolsman/g-log/master/img/ss_skill_iq.png "Screenshot  Skill IQ")

## Dag 16, 24-9-2018

### CI/CD Continued

Alright, het deployen ging maar er ging toch wat fout. Bij het deployen zou de `.war` uitgepakt moeten worden en die folder structuur geplaatst in `/webapps`. Dit gebeurde niet, de daadwerkelijke `.war` files stonden er.

Na zoeken en proberen van de logs in te lezen kwam ik tot de conclusie de resource te verwijderen van de Azure cloud. Eenmaal verwijderd heb ik een nieuwe aangemaakt, een WebApp met runtime Tomcat 9.0.

Toen de resource was gedeployed heb ik een nieuw leeg project gemaakt met alleen web en actuator. Dit project had ik de packaging ook op war gezet. Tot mijn verbazing had mijn nieuwe project een bestand wat ik nog nooit had gezien; ik had altijd jar packaging. De `ServletInitializer`! Is dit het missende stukje? Ik heb een aparte repo, build- en releasepipeline aangemaakt voor dit demo project. Eenmaal gedeployed en gereleased werkte het! Wel met de naam van de war file in de url. De url zag er als volgt uit: [https://bbb-api.azurewebsites.net/demo-0.0.1-SNAPSHOT/actuator/health](https://bbb-api.azurewebsites.net/demo-0.0.1-SNAPSHOT/actuator/health)

```kotlin
import org.springframework.boot.builder.SpringApplicationBuilder
import org.springframework.boot.web.servlet.support.SpringBootServletInitializer

class ServletInitializer : SpringBootServletInitializer() {

    override fun configure(application: SpringApplicationBuilder): SpringApplicationBuilder {
        return application.sources(BbbApiApplication::class.java)
    }

}
```

Toen dit werkte heb ik dit toegevoegd aan mijn hoofdproject en gedeployed. En het werkte niet! Elk pad wat ik probeerde kreeg ik de text "Hello" terug. Toen bedacht ik mezelf dat komt door mijn demo project! Daar had ik een hello controller in die gewoon tekst terug stuurde. De map `demo-0.0.1-SNAPSHOT` verwijderd in de `wepapps` en nogmaals geprobeerd en het werkte.

Nu is de url [https://bbb-api.azurewebsites.net/bbb-api-1.0.0/actuator/health](https://bbb-api.azurewebsites.net/bbb-api-1.0.0/actuator/health) en geeft de status `UP`

```json
{
  "status": "UP"
}
```

Nu heb ik mijn API dus gedployed en is het aanspreekbaar. Ik heb de Slack slash command url aangepast naar de nieuwe url. Het echo commando werkt nu. Ik moet nu alleen uitzoeken hoe de blockchain erin ga pluggen. Dit is weer een opdracht voor morgen.

### Blockchain lees voer

Je hebt 2 verschillende versies van een blockchain, PoW (Proof-of-Work) en PoA (Proof-of-Authority). Ik moet gaan uitzoeken wat de verschillen zijn en wat het beste bij de applicatie past.

Ook is er een _Azure Blockchain Workbench_ en _Azure Etherium Consortium_. Hier moet ik ook verder onderzoek naar doen.

[Azure Blockchain Workbench Documentation - Tutorials, API Reference](https://docs.microsoft.com/en-us/azure/blockchain-workbench/)

[Ethereum Blockchain as a Service now on Azure](https://azure.microsoft.com/en-us/blog/ethereum-blockchain-as-a-service-now-on-azure/)

[Setting Up Ethereum Blockchain On Azure](https://www.c-sharpcorner.com/article/setting-up-ethereum-blockchain-on-azure/)

## Dag 17, 25-9-2018

### Nog meer blockchain leer voer

Zoals hier boven beschreven is er PoW, PoA. Ik ben vandaag de dag begonnen met de simpele google search _"ethereum pow"_. Het eerste wat ik tegen kwam was [Proof of Work vs Proof of Stake: Basic Mining Guide](https://blockgeeks.com/guides/proof-of-work-vs-proof-of-stake/)

#### Proof of Work (PoW)

- Computers die berekingen doen: **miners**

- Computer die de eerste berekening wint (nieuwe block) krijgt een reward

- Kost veel stroom (omdat de miners constant berekeningen aan het doen zijn)

#### Proof of Stake (PoS)

- Computers die berekingen doen: **forgers**

- Per block wordt een random eigenaar gekozen (gebaseerd op wealth/stake)

- Geen block rewards

- Digital currency is al gemaakt in het begin, deze hoeven niet "gemined" te worden

- Zuiniger omdat niet alle forgers constant berekeningen aan het doen zijn

- Mee doen om eigenaar te worden kost ether, als je de regels breekt ben je de inzet kwijt. (Soort goksysteem)

- PoS algorithme naam: **CASPER**

Je hebt 2 verschillende stylen van PoS, `chain-based proof of stake` en `BFT-style proof of stake`.

##### Chain-based proof of stake

Het algoritme selecteert pseudo-random een validator gedurende elk tijdslot (bijvoorbeeld 10 seconden), en wijst de validator naar het vorige block (meestal die de langste chain heeft), en zo wordt de chain steeds langer.

##### BFT-style proof of stake

Validators krijgen willekeurig het recht om blocks voor te stellen, maar overeenstemming bereiken over welk block canonisch is, wordt gedaan door een meervoudig proces waarbij elke validator een "stem" stuurt voor een specifiek block tijdens elke ronde, en aan het einde van het proces zijn alle (eerlijke en online) validators het er permanent over eens of een bepaald blok deel uitmaakt van de chain. Het grootste verschil is dat het overeenkomen welk block deel uitmaakt bepaald kan worden zonder enige informatie van de chain.

[Github - ethereum/wiki - Proof of Stake FAQs](https://github.com/ethereum/wiki/wiki/Proof-of-Stake-FAQs)

#### Proof of Authority (PoA)

- Computers die berekingen doen: **validators**

- Gebaseerd op Proof of Stake

Dit systeem is een soort "verbeterde" versie van PoS. In plaats van een stake van tokens is de stake de identiteit. De indentiteit wordt ingezet door een groep validators die vooraf goedgekeurd zijn. De groep validators is dan de enige groep die verantwoordelijk is voor het valideren van transacties en blocks binnen het netwerk.

## Deployen van Ethereum Proof-of-Authority Consortium

### Config

Als je dit wil deployen moet je het volgende invullen: email, vm user name, password, hoeveel nodes en of je monitoring wil.

Ik heb monitoring ingesteld en de 2 goedkoopste nodes gekozen (2 is het minimum). Na op deploy te klikken heb ik even moeten wachten. Toen het eenmaal klaar was snapte ik waarom ik moest wachten. Er was nogal wat gedeployed.

![Deployed result](https://raw.githubusercontent.com/zwolsman/g-log/master/img/ss_azure_deployments.png "Deployed result")

Eenmaal genavigeerd naar het deployement tabje kon je het tabje outputs selecteren. Hierin staan de waardes die nodig zijn voor mijn applicatie. De `ETHEREUM_RPC_ENDPOINT` wordt gebruikt voor het communiceren van de blockchain. Deze heb ik toegevoegd in mijn applicatie.

![Screenshot Azure Outputs](https://raw.githubusercontent.com/zwolsman/g-log/master/img/ss_azure_outputs.png "Screenshot Azure Outputs")

### Applicatie

Na het updaten van de configuratie heb ik nu de web3j instantie lazy gemaakt, die wordt pas aangemaakt wanneer die nodig is. Dit is omdat die nu afhankelijk is van de `ApplicationContext` om de RPC-url in te laden.

```kotlin
  val web3 by lazy {
        Web3j.build(HttpService(RPC_ENDPOINT))
    }
```

Deze instantie wordt dan gebruikt door de applicatie zelf. Ik heb het deploy commando geprobeerd maar geen succes. De melding die ik terug krijg is als volgt.

```bash
java.lang.RuntimeException: java.net.ConnectException: Failed to connect to ethvtnlhf-dns-reg1.westeurope.cloudapp.azure.com/13.95.7.170:8540
```

Dit betekend eigenlijk dat de server nog niet werkt of toegankelijk is. Misschien als ik langer wacht dat die het wel doet, dit zal ik morgen proberen. De `ADMIN_SITE` doet het ook nog niet, dit geeft de indicatie dat het allemaal nog niet publieke beschikbaar is (DNS etc.).

## Dag 18, 26-9-2018

### Nieuwe deployment

Ik heb vandaag de PoA blockchain opnieuw gedeployed (zodat die 's nachts niet aan blijft) en nu werkt het portal wel. Echter loop ik tegen andere problemen aan. Het Info Support netwerk is best wel dicht getimmerd, de RPC poort is `8540` en hier kan ik geen verbinding mee maken. Dit betekend dus dat ik geen commando's kan gebruiken, smart-contracts deployen etc. In de online interface kan ik wel zien wat de status er van is en dus bevestigen dat het werkt.

![Screenshot blockchain status](https://raw.githubusercontent.com/zwolsman/g-log/master/img/ss_blockchain_status.png "Screenshot blockchain status")

Het probleem is dat op de administratie pagina je verbinding maakt met poort 3001, deze is ook afgesloten. Ik kan dus op het moment van schrijven geen administratieve handelingen doen. Het enige wat ik te zien krijg is _"Waiting on local ethereum node to boot..."_.

Ik heb aan het systeem beheer gevraagd of ze poort `3001` & `8540` willen open zetten voor mij en dat is nu even afwachten.

### Thuiswerken

Omdat het niet werkte op het werk en ik na enige tijd nog geen reactie had van systeem beheer ben ik na goedkeuring thuis gaan werken. Hier kon ik de blockchain testen. Het eerste waar ik tegen aanliep was dat het account wat ik probeerde te gebruiken geen ETH had, dit moet ik oplossen. Dit betekende wel dat mijn applicatie nu verbinding had met de gedeployde blockchain!

```log
Formatted: {text=Whoops, couldn't deploy contract..
`java.lang.RuntimeException: java.lang.RuntimeException: Error processing transaction request: Insufficient funds. The account you tried to send transaction from does not have enough funds. Required 13443950000000000 and got: 0.`}
```

Ik kon zo 1 2 3 niet vinden hoe ik credits toe moest voegen, in [deze guide](https://www.c-sharpcorner.com/article/setting-up-ethereum-blockchain-on-azure/) wordt er verwezen naar de admin pagina maar die is geÃ¼pdatet. Dit moet ik nog verder gaan uitzoeken.

### Feedback PvA Fontys

Blijkbaar heb ik het helemaal verkeerd gedaan. Bartosz stuurde mij een mail met de volgende tekst.

> zie feedback op canvas. Nog veel werk te verrichten!

Waarop ik dacht bij mezelf, hoezo dan? Benny vond het wel een goed document. Blijkbaar school niet, die willen perse dat ik hun eigen template gebruik terwijl Info Support die van hun eist. Oplossing..? Het document opnieuw maken speciaal voor school.. want daar zit ik op te wachten..

Anyways, dat is wat ik nu ga doen. Het PID (**niet** PvA) maar is maken.

Ik heb een concept versie opgeleverd aan Bartosz en ben nu aan het wachten op feedback zodat ik dit zo snel mogelijk kan verwerken.

## Dag 19, 27-9-2018

### Gesprek met Benny via Slack

We hadden de afspraak van dinsdag verzet naar donderdag op Benny's verzoek. We hebben dit via Slack call gedaan, dit was goed te doen. Ik heb mijn scherm gedeeld zodat ik dingen kon laten zien en hebben zo afgelopen anderhalve week besproken. We hebben de planning van aankomende week ook in Azure DevOps gezet. Ik had dit niet goed gedaan de vorige keer dus nu hebben we het samen gedaan.

![Screenshot sprint dashboard](https://raw.githubusercontent.com/zwolsman/g-log/master/img/ss_dashboard_wk5.png "Screenshot sprint dashboard")

Zoals je zit in het screenshot hierboven zie je dat de rest van deze week (4 dagen) vooral het documenteren van belang is. Zoals gelezen ben ik de vorige dag begonnen aan mijn PID, hier ben ik vandaag verder aan gegaan.

Morgen heb ik om 12u een lunch met Benny en dan zie ik hem, hier heb ik wel zin in!

## Dag 20, 28-9-2018

### Begin van de dag

Ik ben nog verder gegaan met mijn PID en heb deze ingeleverd op Canvas. Ik heb Bartosz een mailtje gestuurd met de vraag of die z.s.m. feedback kan geven zodat ik dit kan verwerken. Toen heb ik met Benny gesproken via Slack om te vragen of het Dashboard goed ingericht was, dit kon beter.

![Screenshot algemeen dashboard](https://raw.githubusercontent.com/zwolsman/g-log/master/img/ss_ingericht_dashboard.png "Screenshot algemeen dashboard")

Vanuit Benny was de vraag naar een diagram, om de structuur te verduidelijken en linkjes zodat die alles terug kon vinden. Hier heb ik vandaag werk van gemaakt. Ook heb ik linkjes toegevoegd voor Swagger, deze moet ik echter nog wel implementeren.

### Lunch

Vandaag had ik een lunch, met Tim Vermeulen (Manager), Tim Mahy (Manager), Benny (die kennen jullie ondertussen) en Mathias (Stagiair). Dit was een interessante lunch, we hebben het gehad over de toekomst van ICT, welke technieken we aanraden als jonge ICTers en natuurlijk over onze stage opdrachten. We hebben ook gegeten natuurlijk! Ik heb een typisch Vlaams gerecht op genaamd Vol-au-vent. Dit was zeer lekker. We hebben hier ruim een uur gekletst en dit was een leuke ervaring.

De managers zijn heel nuchter, dat had ik de weken ervoor al gemerkt. Hier is geen bureaucratie van toepassing. Ook zijn ze grappig, de ene heeft een kindje en klinkt als een grappige papa.

## Teambuilding, 29-9-2018

Op deze mooie maar toch frisse zaterdag is er een teambuilding uitje. We gaan golfen! Ik had echter nog maar 1x gegolfd met een bekende die het mij een beetje had uitgelegd. Dit was toch net wat anders..

### Intro

Het begon om 3u, we waren met een groep van 25. Eenmaal compleet hebben we uitleg gekregen over golf in het algemeen; handicap, hoe ver je slaat, welke clubs je hebt etc. etc. Dit was voor vele allemaal nieuwe informatie, er had bijna niemand echt golf ervaring.

Eenmaal de uitleg gehad over de grip voor de driving range zijn we opgedeeld in 2 groepen. Ik zat bij de groep die als eerste ging putten, dit is precies het tegenovergestelde. Dit is heel precies een kleine afstand, het liefst in 2x, in de hole krijgen. Hier gebruik je ook een andere grip voor.

Toen zijn we na een half uur omgewisseld en gingen wij op de driving range. Dit is veel leuker, hier kan je de bal zo ver mogelijk slaan! Je moet hem wel raken.. en je club vasthouden (moeilijker dan je denkt..).

### BBQ

Na zo'n 3-4u bezig te zijn geweest met golfen hadden we een BBQ. Deze was extern verzorgd en lekker! Heerlijke entrecote en speenvarken. Dit alles vergezeld met een lekker koud biertje, top! Later de avond, rond 22:00uur ben ik weer naar huis gegaan.

## Thuis werken, 30-9-2018

Vandaag is het zondag, de dag na teambuilding. Ik wil vandaag echter nog wat aan mijn project doen. Ik heb besloten om swagger documentatie te implementeren. Dit leek mij een handige toevoeging. Ook heb ik nog verder aan mijn PID gewerkt, deze heb ik nu voor de 4e x ingeleverd en om feedback gevraagd. Ik weet dat die nog steeds in concept fase is maar dit is wel alweer een stuk verder.

## Dag 21, 1-10,2018

### Deployment

Vandaag ben ik verder gegaan met mijn deployment. Ik wou dat de URL gewoon correct was en dus in de root deployed werd en niet met `bbb-api-1.0.0` er tussen. Hiervoor moest ik de `gradle.build` aanpassen zodat de `bootWar` output `ROOT.war` had. Dit had ik al is eerder geprobeerd maar werkte toen niet.

Eenmaal aangepast heb ik dit gepushed en gedeployed en ben ik in de logs gaan kijken. Uit de logs bleek dat de applicatie te lang deed over opstarten, dit kwam omdat de server niet krachtig genoeg was.. en 2 applicaties draaide, de vorige `bbb-api` draaide nog! Deze heb ik verwijderd en de server opniew opgestart en nu werkte alles. Nu is de API beschikbaar vanaf [http://bbb-api.azurewebsites.net](http://bbb-api.azurewebsites.net) en swagger vanaf [http://bbb-api.azurewebsites.net/swagger-ui.html](http://bbb-api.azurewebsites.net/swagger-ui.html)

### Problemen met de database

Als je al langer en aandachtig deze blog leest kan je je misschien herinneren dat ik problemen had met het inzien van de data van CosmosDB. Vandaag kwam ik er achter dat het inladen van de data te lang duurde, 15 seconde voor 8 documenten! Dit is te gek voor woorden. Dit moet opgelost worden.

Hoe los ik dit probleem op? SQL Server i.p.v. ComosDB. In het begin draaide ik een lokale MySQL server om op te testen en deze werkte na behoren, ik zag dat Azure een SQL Server deployment had en ik dacht, laat ik dat is proberen.

Eenmaal de SQL Server gedeployed wou ik er bij, dit kon niet! Natuurlijk niet! Firewalls.. Ik de exceptie toegevoegd van mijn systeem en ik kon er in, en de applicatie draaide lokaal. Ik heb het `Account` model aangepast naar standaard JPA annotaties (ipv CosmosDB) en in de properties de `datasource` ingegeven.

De response was meteen een stuk sneller. Het volgende stukje wat de bottle neck was, het niet hebben van een query in de `IdentityService`.

```kotlin
// TODO make this a query
return repo.findAll().firstOrNull { it.identities[key] == localId }?.email ?: "-"
```

Hoe maak ik een JPA Query met een `ElementCollection`, dit heb ik opgezocht en vond [hier](https://stackoverflow.com/questions/29852701/is-it-possible-to-query-jpa-entities-by-elementcollections-where-the-elementcoll?rq=1) een voorbeeld. Deze heb ik aangepast naar het volgende

```kotlin
@Query("SELECT DISTINCT a " +
        "FROM Account a JOIN a.identities i " +
        "WHERE KEY(i) IN :service AND VALUE(i) IN :value")
fun findByService(service: List<String>, value: List<String>) : Account?
```

Deze methode werkte. Door het niet te hoevel laden van alle accounts (en de mappings etc) was dit ook een performance winst. Het voordeel van het hebben van een query is dat je ze kan cachen met de `@Cachable` annotatie in Spring. Door dit toe te voegen is alles nog sneller geworden, het heletijd querien is niet nodig omdat dit nu in memory geladen is.

## Dag 22, 1-10-2018

### Gesprek met Benny

Vandaag was het stage gesprek tijd. Ik was best blij met alles wat ik had gedaan en ik kon een demo geven in Slack met een gedeployde applicatie en blockchain. Alles werkte wat ik wou demoen. Eenmaal laten zien was Benny wel enthousiast maar heeft een paar problemen uitgewezen.

Het eerste was, het verwerken van Blockchain transacties gebeurde nu asynchroon waarna een reactie verstuurd werd als het was gelukt of fout gegaan. Dit is een probleem.. Waarom? Omdat als er 10 requests draaiende zijn en de webserver herstart, de applicatie state niet herbouwd kan worden. Dit moet ik gaan oplossen. Ik stelde voor een token-based systeem. Dat er in de database tokens bijgehouden worden en een referentie naar de blockchain transactie. Dan heb je een job die elke x seconde/minuten/whatever draait en dus uit de database de te-verwerken tokens gaat controleren en indien er een status update is, verder te verwerken.

Het tweede, de endpoints die nu ge-exposed zijn in swagger zijn de facebook en slagger webhooks, deze zijn niet interessant voor de gebruiker. Hij wil de commando's die geimplementeerd zijn als rest endpoints ge-exposed hebben. Hiervoor zal dus de structuur moeten aangepast worden.

Al met al betekend dit eigenlijk een nieuwe structuur en manier van afhandelen van asynchrone operaties. Dit betekend dat alles omgegooid moet worden en ik me hier de rest van de week op zal gaan focussen.

### Talk in Amsterdam

Ik ben 's middags vertrokken naar Amsterdam. Hier had ik een talk van NLHTML5. Dit waren een drietal sprekers. De meeting was volledig in het Engels omdat er veel internationale mensen waren. Het publiek kwam uit Portugal, Spanje, ItaliÃ«, BraziliÃ« en nog een paar landen.

- Go voor de frontend - United Kingdom

  Hier was ik op papier het meest enthousiast over, ik dacht dit gaat over Go naar WASM te compileren. Echter bleek dit niet het onderwerp te zijn. Het onderwerp van Gopherjs, dit is een library die Javascript kan wrappen. Hoe het er uit ziet? Lelijk in my opinion. Het leek me op geen enkele manier een eenvoudige oplossing of bruikbaar voor productie.

  De Go compiler heeft sinds augustus ondersteuning om direct naar WASM te compilen, dit is echter nog in een vroege stage. Omdat het zo nieuw is, is de grootte nog enorm in front-end termen.

- Accessible animations - Australia

  Dit was een spreker die bij ABC nieuws had gewerkt in AustraliÃ«. Die kwam eigenlijk met een punt waar niemand over na denkt, tenminste ik niet. Gebruikers die gevoelig zijn voor epileptische aanvallen hadden problemen met het automatisch afspelen van GIFs. Hier heeft die informatie over gegeven en was wel een interessant onderwerp. Ook over wat Apple allemaal doet omtrent deze problemen.

- XR in de browser - Netherlands

  Deze presentatie was heel cool. Hij had zijn eigen companion-app geschreven, te openen via een linkje. Als die dan door de slides heen klikte update dit realtime op je telefoon. Dit ging over VR en AR in de browser. Hij heeft ook een live code demo gegeven die gelinkt was aan de companion app. Dit was wel super cool.

## Dag 23, 2-10-2018

### Token implementatie

Ik ben vandaag begonnen met het implementeren van token-based systeem. In plaats van een thread/proces/iets hebben wat wacht op een response van de blockchain ga ik dit nu anders aanpakken. Als je een functie aanroept op de blockchain krijg je een `txhash`, dit is eigenlijk het adres van de transactie. Deze kan je dus opvragen bij de blockchain en kijken of die bestaat. Als die bestaat is die gemined en gevalideerd en is die afgehandeld. Meer informatie is [hier](https://medium.com/blockchannel/life-cycle-of-an-ethereum-transaction-e5c66bae0f6e) te vinden over de life cycle van een transactie.

De default implementatie van web3j is dat web3j het voor je doet pollen en je dus laat wachten. Dit wil ik dus **niet**, ik wil dit zelf doen zodat ik er een database laag tussen kan bouwen. Dan met een zelf geschreven `QuartzJob` gaan pollen en verwerken.

Met web3j kan je een eigen transactie processor en manager schrijven. Echter is dit helemaal niet nodig, er is een `NoOpProcessor` en een `FastRawTransactionManager`, dit zijn implementaties die gewoon de blockchain data rechtstreeks terug geven zonder extra functionaliteit. Dit is precies wat ik nodig had! Bij het laden van het contract geef ik de `FastRawTransactionManager` mee en wordt daar gebruik van gemaakt. Dit houd in dat bij het aanroepen van een functie ik meteen response krijg en dus niet hoef te wachten. In de code hieronder zie je hoe nu het contract wordt geladen, en de manager + processor. Dit idee kwam van een [issue](https://github.com/web3j/web3j/issues/457) in de web3j repo, ik was niet de eerste die dit nodig had.

```kotlin
 val processor by lazy { NoOpProcessor(web3) }
    val txManager by lazy { FastRawTransactionManager(web3, credentials, processor)}


    val contract: BBBContract
        get() {
            if(_contract == null)
                _contract = BBBContract.load(CONTRACT_ADDRESS, web3, txManager, GAS_PRICE, GAS_LIMIT)
            return _contract!!
        }
```

Toen ik de tokens terug kreeg was de volgende taak, de database layer en de job. De job is zeer eenvoudig, ik maak gebruik van de `QuartzScheduler`, dit is een open-source [Enterprise Job Scheduler](http://www.quartz-scheduler.org). Spring heeft hier ook integratie voor waardoor het goed samen werkt. Het aanmaken van een `Job` is heel simpel, je hebt een class die inherit van `Job`. Mijn job ziet er als volgt uit.

```kotlin
@Component
class TransactionStatusJob : Job {
    @Autowired
    private lateinit var transactionRepository: TransactionRepository

    override fun execute(context: JobExecutionContext) {
        val transactions = transactionRepository.listNewTransaction()
        logger.info("Found ${transactions.size} transactions")
        transactions.forEach(::processTransaction)
    }
}
```

Door de Spring integratie kan ik er beans in injecteren, in dit geval dus de `TransactionRepository`. Deze haalt alle transacties op die aangemaakt zijn en nog niet verwerkt zijn. Als ze opgehaald zijn worden deze verwerkt in deze job.

Het probleem was, hoe serialize ik een `Transaction`. Opzich niet moeilijk zou je denken, je hebt een `id` en een `hash`, that's it! Dat klopt, echter heb je ook een context nodig. Waarom? Als de transactie opgehaald wordt en gecontroleerd en hij is verwerkt. Dan zal er ergens iets getriggerd moeten worden als response op de transactie. Dit is dus verschillend, is die aangeroepen via Slack? Dan zal er een Slack berichtje gestuurd worden, is dit via Facebook? Dan moet er een Facebook berichtje gestuurd worden. Zoals jullie kunnen raden is dit chat-service afhankelijk. Dit moet dus abstract zijn.

Nou, wat doe je dan? Je maakt een `BaseContext` aan en de andere contexten implementeren deze. De `BaseContext` heeft alleen een `id` en een `naam`. De `SlackContext` zal als extra veld een `response_url` hebben en de `FacebookContext` een `thread_id`. Het probleem was echter met het serializen van deze contexten met JPA. De achterliggende database is een SQL Server, dit is dus een relationale database. Dit betekend dat deze verschillende contexten opgeslagen gaan worden maar dus wel per transactie kunnen verschillen. En dit kan dus ook in de runtime verschillen. Hoe doe je dit? Met een one-to-one relatie. In de code hieronder zie je voorbeeld entities, de daadwerkelijke implementatie is er uitgehaald voor de leesbaarheid.

```kotlin
@Entity
@Inheritance(strategy = InheritanceType.JOINED)
abstract class BaseContext (_name: String) {
    val name = _name.toUpperCase()
    @Id
    @GeneratedValue
    val id = -1
}

@Entity
data class SlackCtx(val responseUrl: String) : BaseContext("Slack")

@Entity
data class FacebookCtx(val threadId: Int) : BaseContext("Facebook")
```

Zoals je ziet is dit wel mooi. De code is leesbaar en uitbreidbaar. Als er een andere service komt kan je de BaseContext inheriten en dan kan deze opgeslagen worden. De transactie ziet er als volgt uit.

```kotlin
data class Transaction(val hash: String, var status: TransactionStatus = TransactionStatus.NEW, @OneToOne(cascade = [CascadeType.ALL]) val context: BaseContext)
```

Zoals je ziet zit hier dus de `BaseContext` in, runtime kan gecontroleerd worden wat voor context het daadwerkelijk is. Met de feature van Smart Casts in Kotlin werkt dit geweldig. De code om te controleren wat voor Context het is ziet er ook duidelijk uit. Je kan in de If statement de properties aan van de daadwerkelijk Context. Zo zie je bij Facebook de `threadId` en bij Slack de `responseUrl`.

```kotlin
    fun sendResponse(transaction: Transaction) {
        if(transaction.context is FacebookCtx) {
            logger.info("Sending response with fb context, thread id: ${transaction.context.threadId}")
        }

        if(transaction.context is SlackCtx) {
            logger.info("Sending response with slack context, response url: ${transaction.context.responseUrl}")
        }
    }
```

### ISKA

Deze ISKA ging over AddIns, ik had hier nog nooit van gehoord. Dat is eigenlijk het systeem wat Chrome gebruikt, elke tab is zijn eigen proces in een host proces. Als er 1 tab crasht, doet de rest het wel nog gewoon. Dit concept hebben ze dus toegevoegd aan een project van hun. Dit werkte met verschillende entiteiten die dingen konden doen. Om deze onafhankelijk van elkaar te kunnen ontwikkelen was dit een oplossing. Je had alleen een interface nodig waar een `GetUI()` functie in zat die dus de daadwerkelijk UI terug gaf. Dan deed het host process dat regelen dat het te zien was.

Het team wat hier op zat had dit nodig, i.p.v. allemaal aparte backends zal er nu 1 overkoepelende backend zijn. Dit was een requirement die gesteld werd waardoor ze dus de fundamenten van de applicatie moesten veranderen. Het was een leerzame talk omdat ik hier dus niks vanaf wist. Ik denk alleen dat ik het niet zelf zou gebruiken, het is echt een oplossing voor een probleem waar ik zelf niet snel tegenaan zal lopen. Toch is dit ook een mooie manier om een plugin systeem te maken, Windows Media Player gebruikt deze manier ook.

## 4-10-2018

Vandaag heb ik vrij! Ik heb deze vrije dag besteed met het beginnen van de cursus `Building applications with React and Redux in ES6` op Pluralsight. Hier heb ik een goede 90 minuten mee bezig gehouden. De rest van de dag heb ik met mijn zusje afgesproken. Die heeft de trein gepakt vanuit Eindhoven naar Antwerpen, we zijn samen gaan shoppen. Dit dagje was een leuk gezellig en toch (in de 90 minuten) leerzaam.

## Dag 24, 5-10-2018

Deze dag ben ik bezig geweest met het verder refactoren van alles. Ik heb letterlijk alle implementatie van de `Command`'s en `Service` gerelateerd. Ik ben met een schone lei begonnen.

Dit was een hele uitdaging om het hele systeem te designen zodat het uitbreidbaar is & toch opgeslagen kan worden (dynamisch) in de database. Ik heb een classe diagram toegevoegd met de uiteindelijk uitgewerkte modellen.

![Architectuur](https://raw.githubusercontent.com/zwolsman/g-log/master/img/ss_architectuur.png "Architectuur")

De implementatie is nog helemaal af, er zal nog wat kunnen veranderen. Zoals je ziet is de Facebook Controller niet geimplementeerd, deze zal nog komen.

## Dag 25, 8-10-2018

We gaan verder aan het `Job` systeem die transacties moet valideren. Ik heb eerst [gelezen](https://codeburst.io/deep-dive-into-ethereum-logs-a8d2047c7371) hoe Ethereum logs en events nu echt werken. Met deze kennis heb ik mijn `Job` en smart contract aangepast. Ik heb nu dat als er een bonus gegeven is dat er een event aangeroepen wordt. Doormiddel van een transaction receipt hash kan ik opvragen welke `logs` er zijn van die specifieke hash. Die log kan ik omzetten in de data die uit het event komt (in mijn geval, de complete bonus). Eenmaal de bonus binnen wordt deze verstuurd vanuit de job naar degene die het heeft aangeroepen.

```kotlin
val receipt = web3j.ethGetTransactionReceipt(transaction.hash).sendAsync().get()
val bonuses = BBBCore.contract.getBonusGivenEvents(receipt.result)

for(bonusGivenEvent in bonuses) {
    transaction.sendResponse(Bonus(bonusGivenEvent))
}
```

## Dag 26, 9-10-2018

Normaliter zou ik vandaag weer een gesprek hebben met Benny, hij vroeg echter of dit donderdag kon zodat die met zijn project door kon werken. Dit was geen probleem van mij. De sprint verliep wel en heb een nieuwe planning gemaakt voor aankomende week.

Ik ben weer bezig geweest met de architectuur, het voelde nog niet helemaal goed. Ik heb hier zelf naar zitten staren en dingen nog hernoemd, voor duidelijkheid. Het bedenken van namen was echter best lastig. Ik heb met een mede stagiair Mathias door mijn code heen gelopen. Omdat het zo complex was raakte hij mij vaak kwijt en voelde het nog niet helemaal goed. 's avonds na het eten heb ik met een vriend ([@Joelluijmes](https://github.com/joelluijmes)) nog eens door de code heen gekeken. We hebeen een basic idee gemaakt in C#, zie [architectuur.playground.cs](https://github.com/zwolsman/g-log/blob/master/architectuur.playground.cs). Dit principe had ik ook al in Kotlin, we zijn het er alleen over eens dat de benamingen die ik gebruikte heel verwarrend waren. Ik heb dus nieuwe benamingen gekozen. Ook heb ik het versturen van een response veranderd.

Voor het versturen van een response is er nu een apart type, een `ServiceResponder<T : ServiceProperties>`. Er zal een per type chat service een implementatie voor zijn. Voor Slack ziet die er als volgt uit.

```kotlin
@Component
class SlackServiceResponder(private val formatter: SlackFormatter) : ServiceResponder<SlackProperties>() {

    override fun respond(props: SlackProperties, response: Any) {
        val formatted = formatter.format(response)
        val result: String? = RestTemplate().postForObject(props.responseUrl, formatted)
        println("Result: $result")
    }

}
```

Hier zie je dat de SlackFormatter gebruikt wordt en deze de response format. Eenmaal geformatteerd wordt de Slack Property `responseUrl` gebruikt voor het versturen van het berichtje. Dit is een strongly typed implementatie die gebruikt kan worden voor dependency injection.

![Architectuur v2](https://raw.githubusercontent.com/zwolsman/g-log/master/img/ss_architectuur_v2.png "Architectuur v2")

Ik heb morgen een gesprek met Tim Mahy over mijn architectuur. Dan kijken er een stel andere, meer ervaren, ogen naar. Ik ben echt benieuwd wat die er van gaat vinden. Ik ben er alweer veelste lang mee bezig, het is 22:30 en ik ga naar bed! Het was me een dagje wel!

## Dag 27, 10-10-2018

### Begin van de dag

Vandaag ben ik verder gegaan met de architectuur. Zoals je ziet is er nog steeds een samenhang van database entity en class die gebruikt wordt. De `SlackPropertiesEntity` is nog steeds een `SlackProperties` en een `ServicePropertiesEntity`. Dit is nog steeds een beetje gek. Ik wil dat mijn data class helemaal los is van mijn service class. Ook is er nog een `CommandContext` voor elke class, dit is ook eigenlijk niet nodig en slecht design. Deze classes hebben ook de `Properties` en `CommandContext`, dit wil ik ook niet meer.

Oplossing? `CommandContext` geen interface maken maar een daadwerkelijke class. Een `Mapper` die van een `CommandContext` een `ServiceEntity` kan maken, een soort brug tussen 2 werelden. Dan heb je de logica van hoe iets opgelsagen wordt in een aparte class per service en staat het echt los van elkaar. Een versimpelde versie zie je hier beneden.

![Architectuur v3 simple](https://raw.githubusercontent.com/zwolsman/g-log/master/img/ss_architectuur_v3.jpeg "Architectuur v3 simple")

Hier zie je dus een `ServiceMapper`, die kan van een `ServiceProperties` een `DatabaseEntity` maken. Deze `DatabaseEntity` is een database class, die heeft 0 logica en alleen de velden die opgeslagen moeten worden. De `ServiceProperties` is een interface met niks er in, deze wordt gebruikt bij de `CommandProcessor` zodat die weet dat er een `DatabaseEntity` gemaakt kan worden. Het principe van een `ServiceResponder` is niet veranderd.

### Implementatie

Na het _opnieuw_ herschrijven van mijn architectuur ben ik naar Tim gegaan. De volledige implementatie die ik had zie je hier beneden op de foto. Ik was hier wel trots op, van de wirwar van de eerste versie (zie [Dag 24, 5-10-2018](https://github.com/zwolsman/g-log#dag-24-5-10-2018)) heb ik nu een versie die helemaal los is van elkaar, en zich aan de SOLID principes houdt.

- Single responsibility principle

  Elke classe heeft zijn specifieke doel, de `ServiceResponder` respond, de `ServiceMapper` is de brug tussen `ServiceProperties` en `DatabaseEntity`, de `Command` handeld ook de daadwerkelijke commando's af.

- Open/closed principle

  Zoals je ziet zijn er 3 `Command` subclasses, deze zijn specifieke implementaties van een commando.

- Liskov substitution principle

  Elke subclass heeft de volledige implementatie van de super classe, er is geen een `Command` die geen `Invoke()` kan of geen een `ServiceResponder` die niet kan reageren. Dit is natuurlijk vanzelfsprekend.

- Interface segregation principle

  Je ziet dat er gebruik gemaakt wordt van 3 interfaces, deze zijn allemaal voor 1 functionaliteit i.p.v. 1 grote. De `ServiceProperties` kon ook de `ServiceResponder` zijn maar hier is expres niet voor gekozen.

- Dependency inversion principle

  De `Command` wordt geÃ¯nvoked met een `CommandContext` in deze context zit een `ServiceResponder` en `IdService`. Dit zijn geen speicifkee implementaties maar worden wel gevuld met de specifieke implementatie door de `CommandHandler`.

![Architectuur v3 implementatie](https://raw.githubusercontent.com/zwolsman/g-log/master/img/ss_architectuur_v3_impl.jpeg "Architectuur v3 implementatie")

### Feedback Tim Mahy

Nou, spannend! Ik ga feedback krijgen van een van de managers die al vele jaren ervaring heeft. Na het gesprek tijdens de lunch vrijdag was ik heel benieuwd wat hij er van zou vinden. Voor mijn gevoel heb ik het beste ontwerp tot nu toe en is het nogal geÃ«valueerd na deze iteraties. Door mijn eigen kritische blik was ik wel zelfverzekerd dat het niet fout kon gaan.

Na hem mijn code base te hebben laten zien en het te hebben besproken was die zeer positief. Hij vond dat ik het netjes had geÃ¯mplementeerd en het enige wat die gek vond was hoe ik de REST implementatie aan het doen was, daar was ik het mee eens. Mijn architectuur is alsnog zo ontworpen om op een asynchrone manier te reageren op berichten (met de `ServiceReponder`) en met REST kon dit niet. Hoe ik dit oploste? Bij de aanvraag van een REST request geneerde ik een uniek ID. Deze sloeg ik dan op in de `RestEntity` en kwam zo in de database. Dan in de `RestResponder` had ik contact met de database i.p.v. met een service. Dan kon daarna iemand de verwerkte bonus ophalen door het id van de request te gebruiken. Dit voelde inderdaad een beetje gek.

Ik was benieuwd, wat heeft Tim dan voor suggesties. Hieronder zie je onze tekeningen op het whiteboard. Rechts onder was mijn huidige situaties, alles in laagjes en de afspraken vast in interfaces. Elke service moest zich aan die afspraken houden. Links daarvan die je het geheel. Hier heb je 1 groot blokje, dat is de applicatie en daarin zie je verschillende blokjes; die staan voor Rest, Slack, Facebook etc. Ik behandel Rest als een vorm van communicatie net zo als dat ik Slack en Facebook behandelde. Dit is niet verkeerd maar dus ook niet ideaal.

Als je daar boven kijkt zie je veel gekrabbel, als je goed kijkt zie je een vierkantje met REST staan. Dit is het core project, hier zitten geen blokjes in maar op. Elk blokje is een service. Die service is helemaal verantwoordelijk voor het omvormen van id's, het handelen van dingen opslaan (als dat nodig is) etc. etc. Door deze manier is rest eigenlijk een projectje WEB, en is elke andere implementatie zijn eigen projectje. Helemaal onafhankelijk van elkaar. Dit had voordelen, waarom? Je hoeft niet alle interfaces te implementeren, je hebt je afspraken in REST vorm i.p.v. interface vorm. Dit betekend dat je elke programmeertaal kan gebruiken voor elke implementatie die je wil. Ook heb je hierdoor een core project die verantwoordelijk is voor de interactie met blockchain. Niet meer en niet minder. Ook heeft dit het voordeel in het idee van webhooks.

Als je een bonus aanvraagt duurt dit even. Hoe handel je dit af? Je vraagt een bonus aan en je geeft een `responseUrl`. Deze refereert naar je eigen projectje zodat het core project daar een `POST` naar kan doen met de bonus zodra die gecreÃ«erd is. In deze response url kan je dus ook nog extra query parameters mee geven. Zo kan de implementatie van Facebook een `threadId=xxx` mee geven en Slack een `shi=xxx/xxx`. De core slaat de hash van een transactie samen met de response url op, zo heeft de database geen `NULL` values en is dit ook helemaal netjes. Als een transactie gelukt is en geverifieerd door het core project wordt er dus een `POST` gedaan naar de opgegeven url en krijg bijvoorbeeld de Slack implementatie die binnen, deze implementatie is dan verantwoordelijk wat die er mee doet. In dit geval dus, formateren en door sturen naar Slack! Ik vond dit een heel mooi concept en ben hier over na gaan denken. Dit moest ik natuurlijk wel bespreken met Benny want dit veranderd de applicatie weer fundamenteel. Ik spreek Benny morgen dus dan ga ik dit is voorstellen.

![Whiteboard met Tim](https://raw.githubusercontent.com/zwolsman/g-log/master/img/IMG_5516.jpg "Whiteboard met Tim")

## Dag 28, 11-10-2018

Het gesprek met Benny is vandaag. Dit was verzet van dinsdag naar donderdag omdat dat beter uitkwam. Ik was dinsdag wel al begonnen met de nieuwe sprint. Na de feedback van Tim Mahy gister heb ik een paar agenda punten voorbereid en wil ik het voorstel doen om een microservice architectuur te gaan gebruiken.

Eenmaal in de Slack call met Benny hebben we het doorgesproken. Ik ben door de huidige architectuur heen gelopen en heb uitgelegd wat er een beetje gek aanvoelde en waarom. Dit heb ik hierboven ook beschreven. Toen heb ik het voorstel gedaan van een microservice architectuur en de voordelen besproken. Hier was Benny wel voor in op de voorwaarde dat ik het lean opzette.

Het is een beetje onzin om elk project in zijn eigen repository, build- en deploypipeline + project te doen als er maar 1 ontwikkelaar (ik) aan zit. Ik heb nu het project opgedeeld in verschillende packages: core, Slack, web. De namen spreken voor zich. Voor nu heb ik ook in de root package een paar helper functies zitten in web & Slack gebruiken. Dit hou ik wel minimaal zodat als het een apart project gaat worden er niet veel herschreven moet worden. Hieronder vind je een diagram met hoe de flow nu gaat.

![Architectuur diagram v4](https://raw.githubusercontent.com/zwolsman/g-log/master/img/architectuur_v4_schets.png "Architectuur diagram v4")

Zoals je ziet heb ik nu de 3 applicaties die ik ga maken erin gezet; Slack, Web en Facebook. Omdat de core nu aan te spreken is via REST kan er een andere applicatie in een andere taal ook mee communiceren. De core communiceert dan via web3 met de blockchain.

Toen ik goedkeuring had ben ik begonnen met het herschrijven van de code en een nieuw database model. De database entity is nu best straight-forward. Het is een Transaction entry, die heeft een transaction hash, een responeUrl en een status. Er is een job die elke x aantal seconde alle transacties ophaalt die de status NEW hebben en die worden dan gecontroleerd. Zodra een transaction verwerkt is zal er een post gedaan worden naar de response url en de status op verwerkt gezet worden.

```kotlin
@Entity
data class TransactionEntry(val txHash: String, val responseUrl: String, @Enumerated(EnumType.STRING) var status: TransactionStatus = TransactionStatus.NEW)
```

Er is nu dus 1 `CommandController`, een Rest Controller. Deze zit in het core project en heeft alle logica van een commando. De `GetMapping`s en `PostMapping`s komen hier in voor de commando's.

De Slack implementatie is nu ook een stuk simpeler. Bij Slack is het belangrijk het omzetten van id's naar emails, hier wordt dan ook rekening mee gehouden. In de hoofdfunctie komt de slash command aan. Hier wordt die verwerkt en dan wordt er een daadwerkelijke functie aangeroepen. In de functie wordt er een URL opgebouwd waar de core op moet reageren. Deze url ziet er uit als volgt "TODO: Link slack url"

```kotlin
val url = this.url(::bonusWebhook, params = mapOf("shi" to responseUrl.substringAfter(HOOKS_URL)))
```

Als de url opgebouwd is wordt deze op de achtergrond via een [co-routine](https://kotlinlang.org/docs/reference/coroutines-overview.html) opgestart die met de core interact.

```kotlin
GlobalScope.launch {
            val senderEmail = emailResolver.resolve(message.sender)
            for ((_, _, id) in message.entities) {
                val email = emailResolver.resolve(id)
                core.createBonus(senderEmail, email, points, comment, url)
                logger.info("Sent bonus, from: $senderEmail, to: $email")
            }
        }
```

Dit is dus Slack specifiek. De `PostMapping` voor de bonus is waar de daadwerkelijke bonus asynchroon binnen komt. Ook komt hier de query parameter binnen die mee gegeven wordt bij het creÃ«ren van de response url (de `shi`).

```kotlin
@PostMapping("/bonus")
    fun bonusWebhook(@RequestBody bonus: Bonus, @RequestParam("shi") slackHookId: String) : ResponseEntity<String> {
        val url = HOOKS_URL + slackHookId
        try {
            rest.postForObject<String>(url, mapOf("attachments" to listOf(SlackBonusWrapper(bonus))))
        } catch(ex: Exception) {
            logger.warn("Couldn't post bonus to Slack")
        }
        return ResponseEntity.accepted().build()
    }
```

Als de bonus binnen komt post deze hem naar Slack en komt het berichtje binnen!

## Dag 29, 12-10-2018

Gister heb ik de proof of concept opgezet van hoe het gaat werken. Vandaag gaat de echte implementatie van Slack beginnen. De commando's bonus, spendings en lijst van bonussen moet nu werken.

Voor de communicatie tussen de core en de applicaties gebruik ik Feign, dit is een Declarative REST Client. Door de functie namen en mappings te kopiÃ«ren van de core en in een interface te zetten kan ik die gebruiken bij andere controllers. Hier kan je mee geven wat de request params zijn en wat er terug gegeven wordt. Door Spring wordt er dan een instantie gemaakt en die kan je gebruiken.

```kotlin
@FeignClient(name = "coreClient", url = "localhost:8080/core")
interface CoreClient {

    @PostMapping("bonus")
    fun createBonus(@RequestParam from: String, @RequestParam to: String, @RequestParam points: Int, @RequestParam comment: String, @RequestParam responseUrl: String): Any

    @GetMapping("spending")
    fun getSpending(@RequestParam users: List<String>) : List<Spending>

    @GetMapping("bonus")
    fun getBonuses() : List<Bonus>

    @GetMapping("bonus/{txHash}")
    fun getBonus(@PathVariable txHash: String) : Bonus

}
```

De web controller is eigenlijk een soort mapping van buitenaf. Het enige wat die wel moet doen is het bijhouden van het aanmaken van een bonus. Omdat dit dus langer kan duren krijgt de client een `200 - Accepted` binnen als de aanvraag binnen is gekomen en krijgt die een header met de locatie van de bonus. De bonus zal in het begin een 404 terug geven, pas als die verwerkt is komt er een 200.

In de database moet dus wel bijgehouden worden welk request id hoort bij welke bonus transactie. Dit wordt ook in de database opgeslagen. Reminder: dit kan in een aparte database zijn, op een aparte server, w/e. Dit is helemaal onafhankelijk van de core database. Voor gemak sla ik het nu op in dezelfde database zodat ik snel aan de slag kan. Dit is dus ook echt een pair van request id & transaction hash. De rest is eigenlijk gewoon doorgeven naar de core.

```kotlin
@GetMapping("spending")
fun getSpending(@RequestParam users: List<String>) = core.getSpending(users)

@GetMapping("bonus")
fun getBonuses() : List<Bonus> = core.getBonuses()
```

De Slack controller is echter de implementatie van het omzetten van id's naar emails. Ook is deze verantwoordelijk voor het parsen van een bericht om het aantal punten, de comment, en de ontvanger(s) eruit te halen. Als het commando niet in de goede manier binnen komt zal er ook een foutmelding gegeven worden. Ook is deze verantwoordelijk voor het formateren van een bonus, hiervoor heb ik Wrappers gemaakt. Deze wrappers komen overeen met de JSON die verstuurd moet worden naar Slack toe.

![Bonus received](https://raw.githubusercontent.com/zwolsman/g-log/master/img/ss_bonus_processed.png "Bonus Received")

Zoals je ziet is de implementatie nog niet helemaal klaar. Het omzetten van de globale email naar een Slack mention moet nog gemaakt worden. Dit is een vertaalslag die dus **alleen** bij Slack moet gebeuren.

### Project structuur

De totale project structuur ziet er nu als volgt uit.

![Project structuur](https://raw.githubusercontent.com/zwolsman/g-log/master/img/ss_project_structuur.png "Project structuur")

Je moet je dus inbeelden de Slack, core en web aparte projecten zijn. Deze projecten zijn dus de specifieke implementaties. Zoals je ziet bij web is er vrij weinig nodig. Alleen een Repository om de koppeling tussen request id & transaction hash op te slaan. Dit is bij Slack dus helemaal niet nodig. Deze heeft juist weer een Email Resolver en het idee van een Message.

## Dag 30, 15-10-2018

### Slack

Vandaag ben ik begonnen met het formateren van mentions voor Slack. Dit was een kleine aanpassing maar maakt wel een wereld van verschil. In plaats van lange emails zie je nu mooi de gebruikersnaam! Top! Slack: **Done âœ…**

### Facebook

Nou, op naar de volgende. Facebook! Weer even de [docs](https://developers.facebook.com/docs/messenger-platform/webhook/#response) in gedoken hoe het ook alweer allemaal zat. Terwijl ik de documentatie aan het lezen was kwam ik nog meer non-functional requirements tegen.

> Your webhook should meet the following minimum performance standards:
>
> - Respond to all webhook events with a 200 OK.
> - Respond to all webhook events in 20 seconds or less.

Binnen 20 seconde moet er dus een `200 - OK` zijn anders heb je een probleem bij facebook. Duidelijk, dat moet lukken. Ik ben begonnen met het opzetten van de webhook voor facebook, hier komen de `payload` en `signature` binnen als request parameters. Hoe werkt de signature in facebook? Dat staat [hier](https://developers.facebook.com/docs/messenger-platform/webhook#security) uitgelegd. Eigenlijk is het heel simpel. Je pakt de payload (JSON) en je maakt er een SHA1 hash van met de app secret als key. De implementatie in Kotlin is daarom ook heel straight forward.

```kotlin
fun isSignatureValid(payload: String, signature: String, appSecret: String): Boolean {
    return try {
        val mac = Mac.getInstance(HMAC_SHA1)
        mac.init(SecretKeySpec(appSecret.toByteArray(), HMAC_SHA1))
        val rawHmac = mac.doFinal(payload.toByteArray())

        val expected = signature.substring(5)
        val actual = bytesToHexString(rawHmac)

        expected == actual
    } catch (e: NoSuchAlgorithmException) {
        false
    } catch (e: InvalidKeyException) {
        false
    }

}
```

Na het valideren van de signature wordt de message geprocessed. Op het moment worden er alleen de mentions uitgehaald en daar een bonus naar gestuurd met statische tekst. Echter is er bij messenger verschil tussen groep chats en privÃ© chats.

Om onderscheid te maken tussen wat voor type bericht het is wordt er gekeken of er een `threadId` beschikbaar is, als dat zo is, is het een groep chat! Met deze informatie wordt er een url opgebouwd voor de response url voor het core project. Hierin wordt de `tid` meegenomen, indien deze niet aanwezig is wordt er een `rid` mee gegeven. De webhook die de bonus afhandelt maakt hier dan weer gebruik van voor het type bericht te onderscheiden.

```kotlin
 @PostMapping("bonus")
    fun bonusWebhook(@RequestBody bonus: Bonus, @RequestParam("tid") threadId: String?, @RequestParam("rid") recipientId: String?) {
        require(threadId != null || recipientId != null)

        logger.info("Received bonus!")
        val recipient = if(threadId != null) {
            ThreadRecipient(threadId)
        } else {
            UserRecipient(recipientId!!)
        }

        val data = Response(recipient, FacebookBonusWrapper(bonus))
        rest.postForObject<String>("https://graph.facebook.com/v3.1/me/messages?access_token=$token", data)
    }
```

Zoals je ziet wordt hier ook weer gebruik gemaakt van specifieke wrappers, dit is normaliter dus een apart project. Op deze manier kan facebook een berichtje sturen met tekst.

![Screenshot facebook bonus](https://raw.githubusercontent.com/zwolsman/g-log/master/img/ss_bonus_fb.png "Screenshot facebook bonus")

Hier zie je ook weer dat de mentions niet werken. Het omzetten van facbeook id's naar email werkt wel. Ik heb morgen weer een gesprek met Benny want het is dinsdag dus ik ben benieuwd wat die er van vindt.

## Dag 31, 16-10-2018

### Service koppeling

Ik wil mezelf vandaag bezig houden met het koppelen van verschillende services. Op het moment worden lokale id's (Slack + Facebook) omgezet naar e-mails volgens de API's van de services. Dit werkt allemaal prima totdat ik mijn privÃ© facebook account wil gebruiken en die email dus anders is dan mijn Slack account zijn email. Ik wil mijn privÃ© email account kunnen koppelen aan mijn werk Slack zijn email.

Ik ga er van uit dat Slack de primaire email bevat en dat andere services hier dus aan gelinkt gaan worden. Hoe ga ik er voor zorgen dat mijn Facebook service niet naar mijn privÃ© email resolved maar naar de email van Slack..? Slack en Facebook weten niet van elkaar dat ze bestaan en het enige wat ze gemeen hebben met elkaar is het gebruik van de Core.

Het is dus logisch om de Core verantwoordelijk te maken om een mapping bij te houden van e-mails en de lokale ids, echter wil je niet dat de core verantwoordelijk is voor het omzetten van id's als deze **NIET** in de database staan.. Dat is weer de verantwoordelijkheid van de service.

### Service koppeling oplossing

Ik zat te denken, misschien is er zoiets nodig als service discovery en dat het core project op die manier een id kan resolven (indien nodig) en dat brengt eigenlijk wel veel complexiteit met zich mee voor wat het opbrengt. Het idee is natuurlijk dat het nog steeds een LEAN project blijft.

Als ik service discovery zou toepassen moet het project ook echt opgedeeld worden in verschillende projecten, alsnog een overeenkomst maken voor het resolven van id's yada yada. Precies van alles wat ik NIET wil. Ik wil dat mijn CORE project dom blijft en dat de rest eigenlijk gewoon bij de service zelf gebeurt.

**Oplossing:** een database die het core project kan benaderen. Deze slaat puur email-adressen op. Een email adres kan 0..\* andere email-adressen hebben die een alias zijn. Door dit toe te passen hoeft de core project nooit extra implementatie te hebben, de services leveren alleen email-adressen aan en veranderd er dus vrij weinig. Wel moet het core project ondersteuning hebben om dus een email-adres toe te voegen, dit wordt gedaan door een `PUT /core/accounts/{email}`.

## Dag 32, 17-10-2018

### Service koppeling implementatie

Naar het Proof of Concept gister ben ik vandaag begonnen met de implementatie. De entity classes zijn heel zelf-uitleggend.

```kotlin
@Entity
data class AccountEntry(@ElementCollection val emails: List<EmailEntry>)

@Embeddable
data class EmailEntry(@Column(unique = true) val email: String, val service: String, val isPrimary: Boolean)
```

Een account heeft een collectie van emails en een email heeft 3 attributen, de email (logisch), service naam en of die primair is. De service naam is zodat de combinatie van email en service uniek zijn. Deze worden dan in de database opgeslagen.

Bij het ontvangen van een email adres in de core wordt deze gemapt naar de primaire. Zo kan ik met mijn secondaire email gebruik maken van de service en zal niemand dit zien dat het niet van mijn primaire email komt. De functie daarvoor is een helper functie die ook een account aanmaakt als die nog niet bestaat.

```kotlin
    fun getPrimaryEmail(email: String, service: String) : String {
        val entry = accountRepo.findByEmail(email) ?: accountRepo.save(AccountEntry(EmailEntry(email, service, true)))
        return entry.primaryEmail
    }
```

### Processbegeleiding

Vandaag was ook de dag voor proces begeleiding. Dit is een gesprek met Ilse om 3u. We hebben het gehad over de afspraken met school, mijn terugkomdag (1 nov), mijn documenten en over mijn schrijfstijl. Mijn terugkomdag is op een officiÃ«le vrije dag van BelgiÃ«, dat is wel weer jammer! 1 november is het hier _[Allerheiligen](https://nl.wikipedia.org/wiki/Allerheiligen)_. Verder ging het over hoe het ging met mijn opdracht etc., dit gaat allemaal goed en was een fijn gesprek. We hebben het ook over Antwerpen gehad en nog wat dingetjes die niet werk gerelateerd waren. Al met al hebben we een goed, fijn en gezellig gesprek gehad. Blijkbaar leest ze ook soms mijn blog dus als ze dit leest, hey Ilse!

### ISKA

's Avonds na het eten (wat erg lekker was; stoofvlees, aardappel puree en visje) was er een ISKA van Benny. Ja, Benny de begeleider. Die ging vertellen over ProLeague. Ik had hier nog nooit van gehoord en dat is niet zo gek, dat is de voetbal bond van de 1e en 2e klasse van professioneel voetbal in BelgiÃ« (als ik het goed heb onthouden, ik heb 0 verstand van voetbal..). Hier hadden ze een applicatie voor moeten maken. Het speciale aan deze applicatie was dat het voor aanvragen was van licenties, deze aanvragen verschillen per jaar en ze wouden niet elk jaar voor een "update" vragen omdat er een nieuw veldje bij was gekomen of juist weggehaald. Om dit op te lossen hebben ze een heel meta model gemaakt die totaal aanpasbaar was met relaties etc. Die objecten kon je dan weer gebruiken om wizards te maken en dan te versturen naar clubs. De clubs lopen door de wizard heen en vullen alles in.

De demonstratie van de applicatie was wel interessant en de terugblikken en inzichten die verteld waren was ook leuk. Je ziet dan eigenlijk hoeveel een opdracht kan afwijken van waar ze initieel mee begonnen zijn en hoe het helemaal groeit.

## Dag 33, 18-10-2018

### Gesprek Benny

Het geplande gesprek van dinsdag ging niet door omdat Benny het te druk had op het moment. Ik stelde voor om het dan te verplaatsen naar donderdag (net zo als de vorige keren) en dat hebben we gedaan. We hebben het gehad over de architectuur hoe ik het nu heb neergezet en wat ik nu aan het implementeren was (gister, het email systeem). Ook heb ik een code review aangevraagd, ik ben benieuwd wat hij nu daadwerkelijk van de code vind. Verder hebben we afgesproken dat ik me bezig ga houden met het testen van mijn smart contract.

### Review

Benny heeft een review gedaan op mijn code en setup. Hij had een user story aangemaakt met allemaal verschillende taakjes die hij tegen kwam. Ik ben daar toen meteen mee aan de slag gegaan. Hij waren taakjes van `Database - enforce unique constraint` tot `CommandController - getPrimaryEmail`. Functie benamingen tot echt functionaliteit dingetjes. Ik vind het wel fijn dat er iemand kritisch naar gekeken heeft.

## Dag 34, 19-10-2018

### Test dag!

Ik ben bezig geweest met tests. Ik heb gekeken hoe ik mijn smart contract moest testen. Toen ik Ganache installeerde zag ik op de webiste ook een tool om je smart contract te testen. Deze tool heette [Truffle](https://www.truffleframework.com/truffle). Dit is een framework met de slogan _"SMART CONTRACTS MADE SWEETER"_. Dit is een NPM package die je installeerd doormiddel van het uitvoeren van `npm install truffle -g`, echter gebruik ik yarn dus voerde ik het volgende commando uit.

```bash
murf@Marvins-MacBook-Pro: [~] $ yarn global add truffle
```

Toen dit toegevoegd was als package kon ik er gebruik van maken. Met [de docs]() er bij ben ik begonnen aan een leeg project. De eerste stap is `truffle init` intypen in een lege directory. Dit maakt dan een structuur aan waarin je je smart contract kan ontwikkelen en testen. Ik ben natuurlijk het meest geÃ¯nteresseerd in het testen. Ik heb mijn smart-contract over gekopieerd van mijn bbb-api project en ben begonnen met tests te schrijven. Dit ging super makkelijk. Ik had al ervaring met JavaScript en met Mocha (het test framework). Hierdoor was het super simpel om gewoon te beginnen. Hieronder staat een test die geschreven is. Hier wordt het contract (de .sol) als een artifact gezien. Die kan je dan opvragen, een instantie van maken en dan met JavaScript functies op aanroepen.

```javascript
const BBBContract = artifacts.require("BBBContract");
const createInstance = async (amount = 150) => BBBContract.new(amount);

it("Should have a maximum of 100 points", async () => {
  const MAX_SPENDINGS = 100;
  const instance = await createInstance(MAX_SPENDINGS);

  const maxAllowed = (await instance.maxAllowed.call()).toNumber();
  assert.equal(MAX_SPENDINGS, maxAllowed);
});
```

Toen ik de tests had geschreven voor het smart-contract had ik ze aan Benny laten zien. De tests die ik had geschreven vond die voldoende, de use-cases waren erin getest en de edge cases ook. Toen ben ik mezelf gaan focussen op het testen van de Spring applicatie.

De enige test die ik tot nu toe had was een integratie test, die keek gewoon of de applicatie volledig kon opstarten (en dus alle beans kon aanmaken). Hier moet wel wat meer getest worden! Ik ben gaan kijken, wat zijn de echte belangrijke interactie dingen die gedaan moeten worden, wat kan niet fout gaan.

- Een account ophalen bij primary of alias email adres.

  Dit is van essentieel belang voor de koppeling tussen email adressen.

- Email adressen moeten uniek zijn

  Het moet niet zo zijn dat hetzelfde email adres toegestaan is om in de database te komen. De combinatie van service & email moet uniek zijn.

- Het omzetten van facebook/Slack id's naar email adressen

  Dit is mooie herbruikbare en goed te testen code. Dit is ook belangrijk en wou ik ook getest hebben.

Hier ben ik als eerste mee bezig geweest. De unique constraint bleek toch niet zo goed te werken als ik dacht. Door de test besefte ik pas dat het niet goed werkte, hier ben ik toen ook mee bezig geweest zodat de test slagen. Hieronder zie je een test van het vertalen van Slack id's naar e-mails.

```kotlin
    @Test
    fun `Resolve slack id's from email`() {
        val idMap = mapOf("UCNAJL7FF" to "murf@majos.nl", "UCSBFCBSS" to "goos.bekerom@gmail.com", "UCNAPUFHT" to "joell@majos.nl")

        for((id, email) in idMap) {
            val resolvedId = userCache.getLocalId(email)
            assertEquals("<@$id>", resolvedId)
        }
    }
```

zoals je ziet is het zeer eenvoudig te begrijpen en is het duidelijk wat er getest wordt.

## Dag 35, 22-10-2018

### Pageable

Alright, ik begin veel bonussen te hebben (veel testen natuurlijk). Dit begint een probleem te worden met weergeven. In Slack mag je Ã¼berhaupt maar 100 attachments hebben; bij mij is elke bonus een attachment. Nou, hoe ga ik dit oplossen? Pageable!

De core api moet pagination gaan ondersteunen. In Spring heb je `Pageable` en dan kan je een `PageImpl` maken met de `Pageable` en de content. Dit klinkt natuurlijk zeer eenvoudig en dit is ook wel "oke" om op te zetten. Echter, het de-serializen wordt een probleem. `PageImpl` heeft geen default constructors, die wordt altijd met een static methode aangemaakt, dit snapt de serializer niet.

Tussen de `CORE` en de `SLACK` zit http communicatie, het (de)serializen van data wordt gedaan door Jackson, dit is een standaard library die gebruikt wordt binnen het Spring Framework. Wat ik heb gedaan is van de JSON die gegenereerd wordt van een `Page<T>` mijn eigen domein classes gemaakt. Deze hebben wel een default constructor en zo kan mijn Slack client de page dus deserializen. Met deze informatie wordt nu een lijst opgebouwd van maximaal 10 items per pagina, dit is het aangerade aantal [volgens](https://api.slack.com/docs/message-attachments) Slack.

### Slack button integratie (next/prev)

Nu de data pageable is zullen er _next_ en _previous_ knoppen moeten komen om er door heen te browsen. Deze knoppen kan je ook als attachment toevoegen. Om interactieve knoppen werkend te krijgen moet je _"Interactivity"_ aanzetten. Hierbij moet je een URL invullen waar Slack data naartoe kan posten.

![Foto van Slack Interactivity](https://github.com/zwolsman/g-log/raw/master/img/ss_slack_interactivity.png)

Eenmaal dit aangezet heb ik een endpoint gemaakt in mijn Spring project. Ik heb het `/actions` genoemd. Hier komt form-url encoded data binnen met 1 parameter genaamd `payload`. Deze parameter heeft een url-encoded JSON object. Dit vind ik zelf heel raar, dit lijkt mij niet de bedoeling. Het zou logischer zijn dat ze de json gewoon als request body mee zouden sturen. Nu moet ik zelf de string omzetten naar een object omdat het een parameter value is. Eenmaal het object kijk ik wat voor knop er is ingedrukt, dat staat in het object.

Gebaseerd op de knop neem ik actie, volgende of vorige. Ik stuur dan de gehele nieuwe lijst (met knoppen) naar de response url, deze update dan het huidige bericht met de nieuwe data.

Nu de knoppen het doen besefte ik mezelf, de oudste bonussen staan op de eerste pagina, logisch. Hoe ga ik dit reversen? Heel simpel. Met een simpele formule loop je achterstevoren door de bonussen heen.

```kotlin
    val total = BBBCore.contract.bonusCount().send().toInt()
    val list = mutableListOf<Bonus>()

    val start = total - pageable.offset - 1
    val end = start - pageable.pageSize + 1

    for(i in start downTo end) { }
```

Dit levert het volgende resultaat op

![Foto van prev/next](https://github.com/zwolsman/g-log/raw/master/img/next_prev_buttons.gif)

### Slack button (repost bonus)

Nu ben ik begonnen met het reposten van een bonus. Het idee is dat er iemand een bonus geeft en dat een gebruiker op "repost bonus" kan klikken. Deze stuurt dezelfde bonus, met hetzelfde aantal punten nog een keer naar de gebruiker. Hierdoor krijgt de gebruiker dus nog eens de punten. Om dit te implementeren moet je dus wel weten op welke bonus er geklikt wordt en door wie.

Ik heb het begin gemaakt, ik kan onderscheid maken tussen next/prev knop en de repost bonus knop. In deze repost bonus functie krijg ik binnen wat de `response_url` is, de gebruiker en de index van de bonus (van de lijst op de blockchain). Morgen ga ik verder implementeren, de bonus ophalen etc. en het daadwerkelijk opnieuw posten.

## Dag 36, 23-10-2018

### Repost button afmaken

Gister had ik de basis gelegd voor het reposten. Ik kon binnen krijgen als er op een knop werd geklikt en dan op welke bonus. Die informatie heb ik nu gebruikt om de bonus op te halen en daarna dezelfde functie aan te roepen als het origineel creÃ«ren van een bonus.

```kotlin
    @PostMapping("bonus/{bonusIndex}/repost")
    fun repostBonus(...) : String {
        val max = BBBCore.contract.bonusCount().send()

        if(bonusIndex >= max.toInt())
            throw BonusNotFoundException(bonusIndex)

        val (_, to, points,comment) = Bonus.from(BBBCore.contract.bonuses(bonusIndex.toBigInteger()).send(), bonusIndex)
        return createBonus(from, to, points, comment, responseUrl, serviceName)
    }
```

Echter als ik iemand een bonus gaf kwam hier ook met de response de _repost button_ bij. Dit wilde ik niet omdat het raar voelt om een bonus te reposten die je net hebt aangemaakt. Dit heb ik opgelost door een nullable field toe te voegen met de index van de bonus. Deze kan alleen ingeladen worden als de lijst van bonussen gebruikt wordt. Op deze manier kon ik dus onderscheid maken en zal die knop niet te zien zijn als je feedback krijgt van je bonus aanvraag.

### Rest van de dag

Rest van de dag was een beetje shitty, ik liep weer tegen problemen aan met Azure. Ik heb mijn helper functies gerefactored zodat ze wel in de spring context komen en dan met dependency injection inlaad. Hierdoor zijn ze wel instelbaar. Dit was een eis van Benny. Toen ik dit had gemaakt wou ik het proberen in te stellen via Azure, dit lukte echter al niet. Toen begonnen de echte vraagstukken.. Waar is mijn logging? (Geen idee! Zelfs nu niet..), waar kan ik mijn applicatie Ã¼berhaupt zien staan? Waarom werkt het niet?! Welke waardes worden er doorgegeven? Ik kon niks zien.. Ik heb dit bij Benny gemeld en gevraagd om hulp. Ik hoop dat ik snel een reactie krijg en dat ik verder kan gaan met het configureren van de applicatie in de cloud.

Ook had ik nog steeds het probleem dat als ik hem deploy dat het enige tijd duurt (voor mijn gevoel een eeuwigheid) voordat hij "live" was. De Azure DevOps zei dat de deployment succesvol was maar vaak laadde de website niet. Ik heb aan Tom gevraagd hoe dit zou kunnen; zijn oplossing: stop & start de service voor en na het daadwerkelijk deployen.

Ik dit geregeld in mijn release pipeline, veranderde echter niks. Toen heb ik aan Gaston gevraagd en gedemonstreerd wat er gebeurt. Hij snapte er ook niets van. Ook dit heb ik bij Benny voorgelegd.

## Dag 37, 24-10-2018

### React leren

Door de "problemen" van gister kon ik niet echt concrete stappen zetten. Ik heb er voor gekozen om een React course te gaan doen. Ik zou die technologie graag willen gebruiken in mijn front-end voor deze opdracht en heb hier nog 0 kennis van. Misschien herinner je het je nog maar ik had tests gemaakt op Pluralsight (SkillIQ) en die had ik ook van React gemaakt. Door gewoon de basis ooit eens gelezen te hebben werd mij aangeraden om de "beginner" over te slaan, die kennis had ik al.

Ik ben toen begonnen aan de course _Building Applications with React and Redux in ES6_ van Cory House. Deze course duurt in zijn totaal 6 uur en 13 minuten. Ik wist wat Redux was/deed door mijn ervaring met Angular en NgStore. Vandaar dat ik de urgentie er van in zie om dit te gebruiken in de React wereld.

Ik heb nu de eerste 9 hoofdstukken af. De code is [hier](https://github.com/zwolsman/pluralsight-redux) te vinden in een GitHub repo. Een paar dingen waren wel al veranderd. De `redux-router` heeft een update gehad naar 4.0. Door even te Googelen kwam ik op een blog uit. Deze blog heet [A Simple React Router v4 Tutorial](https://medium.com/@pshrmn/a-simple-react-router-v4-tutorial-7f23ff27adf), door deze blog door te lezen kon ik de verouderde, niet werkende dingen vervangen met de nieuwe versie. Bijvoorbeeld de `Link` component bestaat niet meer, dat moet een `BrowserLink` zijn. Zo waren er nog een paar dingetjes.

### Gaston helpen

Terwijl ik bezig was met mijn React course hoorde ik Gaston wat zuchten. Dus ik vroeg van hey Gaston, wat is het probleem. Hij riep "**TYPESCRIPT**!" Ik zo ah joh, zo erg kan het niet zijn. Ik vind het een super leuke taal. Dus ik ging is even mee kijken wat die aan het doen was. Aan de programmeerstyle kon je zien dat die niet veel ervaring had met typescript. Bijvoorbeeld een constructor met properties gebruikte die niet, hij deed alles met getters en setters en dan private backing fields. Ik heb is even met Gaston gepraat en het project doorgesproken.

Ik heb toen meteen gevraagd of op [de repo](https://gitlab.com/Gaston_KDG/js-presentation-server) erbij mocht en dat mocht. IK ben toen begonnen op een nieuwe branch en ben gestart met het herschrijven. Veel code die er staat was niet optimaal, zoals die zelf ook al zei het is een PoC.

Hij vond het heel fijn dat ik hem hielp en keek de hele tijd mee. Terwijl ik aan het programmeren was legde ik uit waarom ik dingen deed en hoe ze werkte. Ook gaf ik hem een code review, hier vroeg die om. Hij vond het allemaal heel prettig.

## Dag 38, 25-10-2018

Vandaag heb ik weer met Benny afgesproken. Ik had de problemen al eerder doorgemaild. Het gesprek vind plaats om 10u, tot dan kan ik nog verder aan Gaston zijn project.

Tijdens het gesprek heb ik uitgelegd dat Azure nog niet helemaal goed gaat en graag meer uitleg wou. We hebben zitten kijken waarom het deployen niet goed gaat en dat komt door de cpu usage! Als ik mijn applicatie deploy/laat starten gebruikt die 100% cpu. Blijkbaar was ik gewoon te ongeduldig en moet ik gewoon wat langer wachten (5-10 min). Dat is weer een probleem minder. Het volgende was de environment variables, die werden niet goed ingelagden. Als je de AppSettings aanpast van Azurre zet die ze ook in je Bash. Die namen mogen geen `.` bevatten en dat deden ze wel bij mij. Het ging om de variables `url.host`, `url.port` en `url.scheme`. Deze heb ik gerenamed naar de upper-case variant en de `.` met een `_` vervangen. Dus nu zijn het `URL_HOST`, `URL_SCHEME` en `URL_PORT`, deze werken nu wel.

Ook de logging hebben we uitgezocht. Nu kan ik de foutmelding zien waardoor de gedeployde endpoints niet werken. Die was een `FeignException`. Hier ga ik na het gesprek verder naar kijken.

### Informatie beschikbaar stellen

Omdat het deployen zo lang duurt is het handig om te weten welke versie er nu draait. Ik maak al gebruik van `actuator`, deze heeft echter alleen een `health` endpoint en een `info` endpoint zonder enige data. Tijd om dit te veranderen!

Als eerste heb ik de health check geÃ¼pdatet, hier kijk ik nu ook of de `WebBonusRepository` een `count()` kan uitvoeren, zo nee? Service down!

Toen de stap om informatie over de applicatie beschikbaar te maken. Ik heb gekeken hoe de actuator endpoint werkt, deze leest gegevens uit van je applicatie. Meer informatie over de actuator endpoint is [hier](https://docs.spring.io/spring-boot/docs/current/reference/html/production-ready-endpoints.html) te vinden. Het belangrijkste was is dat ik niet steeds de versie handmatig zou moeten updaten. Ik wil dat Gradle dit doet.

Dit kan heel simpel. Je kan een sectie `springBoot` aanmaken en daarin de `buildInfo()` aanroepen. Deze zorgt ervoor dat build informatie in de war/jar wordt meegenomen.

```groovy
springBoot {
    buildInfo()
}
```

Ik wou dat mijn versie ook de git commit in de versie heeft zodat het makkelijk terug te koppelen aan de release. Een release in Azure DevOps heeft altijd het commit id erbij van de laatste commit. Dit heb ik gedaan door een git plug-in te gebruiken in Gradle. Door die toe te voegen kon ik de versie updaten door `version = "1.0.0.${git.head().abbreviatedId}"` neer te zetten.

```json
{
  "build": {
    "version": "1.0.0.156d142",
    "artifact": "bbb-api",
    "name": "bbb-api",
    "group": "com.infosupport",
    "time": "2018-10-25T12:37:47.211Z"
  }
}
```

De volgende endpoint was de `/env`. Hier staan alle environment variables, dus ook de app settings van Azure! Deze hoefde ik alleen te activeren in de `application.properties` en was daarn al inzichtelijk. Het bestand is te groot om hier te laten zien maar je kan hem [hier](https://bbb-api.azurewebsites.net/actuator/env) zelf bekijken. Door deze variables te bekijken weet ik zeker dat de app settings ingeladen zijn en gebruikt worden!

### FeignException

Alright, de API call werkt niet omdat ik een Feign Exception krijg. Error code [411](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/411), dit is de `Length required` code. Hmm, waar komt dit vandaan en hoe ga ik debuggen hoe mijn FeignClient dingen stuurt.. Ah ja! Ik ga [RequestBin](https://requestbin.fullcontact.com) gebruiken. Dit is een website die je een URL geeft en daar kan je dan HTTP methodes naar sturen. Hier zie je dan de request in terug en kan je dus zien wat een andere server allemaal binnen krijgt. Ik heb de feign base url aangepast naar de RequestBin url en heb de functie aangeroepen zoals ik het normaal ook doe. Hieronder zie je een schermafbeelding van de Request Bin.

![Request Bin](https://github.com/zwolsman/g-log/raw/master/img/ss_request_bin.png)

Zoals je ziet worden de `@RequestParam` mee gestuurd als query string en is de `Content-Length` op `0` gezet. Dat klopt ook omdat er geen body is.. maar dit is niet de bedoeling!

Dit moet ik oplossen door de parameters als form-url-encoded mee te sturen. Feign heeft hier een eigen package voor, de [OpenFeign/feign-form](https://github.com/OpenFeign/feign-form). Die hebben ook een voorbeeld hoe je het in Spring moet integreren.

```java
@FeignClient(name = "file-upload-service", configuration = FileUploadServiceClient.MultipartSupportConfig.class)
public interface FileUploadServiceClient extends IFileUploadServiceClient {

    public class MultipartSupportConfig {

        @Bean
        public Encoder feignFormEncoder() {
            return new SpringFormEncoder();
        }
    }
}
```

Met deze informatie ben ik dit gaan implementeren in mijn Feign client maar geen succes! Het zijn nog steeds query parameters.. Dit moet ik morgen verder gaan uitzoeken.

## Dag 39, 26-10-2018

### Probleem Feign Exception oplossen

Alright, ik ben bezig geweest met het oplossen van de Feign Client. Ik kreeg het niet voor elkaar om de `FormEncoder` aan de praat te krijgen dus heb ik een andere manier bedacht. Ik maak een model aan, `BonusRequestParameters`, en stop daar alle waardes in. Dit object wordt dan gewoon naar `json` geconverteerd en verstuurd. Dit zou moeten werken!

Ik moet wel de ontvangende kant aanpassen, i.p.v. `@RequestParam from, @RequestParam to, ..` wordt dat nu dus `@RequestBody params` waar de params de `BonusRequestParams` zijn. Dit is een makkelijke aanpassing en eigenlijk maakt het de code ook nog een deel leesbaarder.

Eenmaal geÃ¼pdatet en getest bleek het te werken! Ik heb het met de master gemerged, gebuild & gereleased. Even wachten en hij staat online! Toen heb ik de Slack API aangepast naar het publieke endpoint op de server en testen maar. Alles werkte! Het probleem is verholpen.

Op naar het volgende.

### Authorisatie

De API zoals die nu is, is die beschikbaar voor iedereen. Dat is natuurlijk niet de bedoeling, ze moeten toegang krijgen voor dit. Hier is een mechanisme voor bedacht genaamd `OAuth`. De originele versie stamt uit 2006 maar de nieuwe versie heet `OAuth 2`. Deze versie is gepubliceerd in 2012. OAUth is een open standaard voor autorisatie. Hiermee kan het geregeld worden dat een applicatie toegang krijgt tot de API als die de juiste token mee stuurt. Deze token is voor een bepaalde tijd geldig en er is ook een ververs token. Zoals je raad, deze geeft een nieuwe (verse) token terug. Omdat dit een industrie standaard is (kijk naar Facebook, Github, LinkedIn, Google, Twitter, Netflix, Paypal, Microsoft, Instagram en nog [vele meer grote organisaties](https://en.wikipedia.org/wiki/List_of_OAuth_providers)) had ik hier interesse in.

Ik ga mezelf eerst is inlezen hoe het nou echt werkt, ik heb een blog gevonden genaamd [Wat is OAuth en hoe werkt het precies?](https://computerworld.nl/security/100443-wat-is-oauth-en-hoe-werkt-het-precies) in het Nederlands. Ben benieuwd!

Het artikel is een beetje nietszeggend. Het vertelt de stappen in een versimpelde versie en verder is het een beetje kale informatie. Dit is duidelijk niet wat ik zoek.

Ik ben Spring specifiek gaan zoeken en vond meer waardevolle dingen.

- [OAuth 2 Developers Guide](https://projects.spring.io/spring-security-oauth/docs/oauth2.html)
- [Spring Boot 2 OAuth2 Authorization Server | JWT | MySQL](https://www.youtube.com/watch?v=wxebTn_a930)

Na dit gezien & gelezen te hebben besef ik mezelf 2 dingen.

Je hebt het verschil tussen een `Provider` `Resource Server`. Een provider provide endpoints om je op aan te melden, deze authenticeert je. Deze geeft uiteindelijk dus een token die je kan gebruiken bij de `resource server`. De `resource server` gaat de API zijn, hier moet je de token gebruiken voor het mogen ophalen/versturen van data.

Ook gaat de API een `Provider` zijn, hier zal een configuratie bestandje of database of iets dergelijks moeten zijn met de client idâ€™s, client secrets, scopes.

Scopes is wat de client allemaal mag doen. Als je deze leeg laat zal die alles mogen (dat is mijn geval de gewenste situatie). Ik zal hier maandag verder mee aan de slag gaan en kijken of het lukt.

## Dag 40, 29-10-2018

Alright, vandaag gaat de dag worden voor de implementatie. Ik wil dat dit vandaag gaat lukken! Na een weekend hackathon te houden voor mijn eigen project met een vriend van mij ([@joelluijmes](github.com/joelluijmes)). We hebben aan ons product "Facto" gewerkt, in 36u tijd samen zijn 22u geprogrammeerd. Je kan dit wel een succesvol weekend noemen! Nu weer terug aan stage.

### OAuth in Spring

OAuth in Spring, zoals de titel zegt. Dit was een uitdaging. Ik had al wat gelezen over OAuth dus ik had een idee van wat ik moest doen. Ik moest een `Provider` & `Resource` opzetten. Ik ben weer terug gegaan naar [de docs](https://projects.spring.io/spring-security-oauth/docs/oauth2.html). In deze docs wordt gerefereerd naar de sample apps. Deze heb ik gebruikt als referentie.

De eerste stap was de juiste dependencies toevoegen, dit zijn `spring-security-oauth2` en `spring-boot-starter-security`.

```groovy
    compile('org.springframework.security.oauth.boot:spring-security-oauth2-autoconfigure')
    compile('org.springframework.boot:spring-boot-starter-security')
```

Als je deze 2 hebt toegevoegd is je applicatie op de "standaard" manier bevieligd. Er zijn alleen geen gebruikers en je hebt nergens meer rechten op (want je moet ingelogd zijn). Alle requests geven dus een `401` error.

Van de sample projecten was [de configuratie](https://github.com/spring-projects/spring-security-oauth/blob/master/samples/oauth2/sparklr/src/main/java/org/springframework/security/oauth/examples/sparklr/config/OAuth2ServerConfig.java) het interessants. Hier zie je hoe de OAuth wordt opgezet, hoe de tokens worden opgeslagen en welke er uberhaupt zijn.

### PoC - In Memory

De eerste configuratie is sterk gebaseerd op de samples. Ik heb een InMemory token store en daar heb ik 1 client in zitten. De Slack Client natuurlijk. Hier heb ik met de grant types getest. De grant type die ik heb gekozen is [client credentials](https://oauth.net/2/grant-types/client-credentials/) geworden. Client credentials is voor een client die een token wil ophalen bij een provider buiten de user scope om. Omdat mijn systeem (het core project) geen "users" heeft zal dit ook nooit mee gestuurd worden. Dit is puur het toestaan dat een specifieke service toegang heeft, vandaar de client client credentials.

```kotlin
    clients.inMemory()
            .withClient("slack")
                .authorizedGrantTypes("client_credentials")
                .authorities("ROLE_CLIENT", "ROLE_TRUSTED_CLIENT")
                .scopes("read", "write", "trust")
                .secret("slack-secret")
```

Dit heb ik getest met postman, die heeft een interface voor het ophalen van een oauth token (dit is natuurlijk mogelijk omdat het een standard is). Wat je moet invullen zijn de token url, client id & client secret. Als je geen scopes op geeft krijg je ze allemaal terug. Ik heb de scopes `read`, `write` en `trust`. Dit kan ik in een later stadia toevoegen als criteria voor het aanroepen van rest api's.

![Postman token](https://github.com/zwolsman/g-log/raw/master/img/ss_postman_token.png)

### Uitwerking JDBC

Nu de In Memory werkte wou ik het uitbreiden. Zodat er dynamisch clients toegevoegd kunnen worden. Er is een schema beschikbaar wat gebruikt wordt voor de tests. Deze is gelinkt door de docs en verwijst naar een [sql script](https://github.com/spring-projects/spring-security-oauth/blob/master/spring-security-oauth2/src/test/resources/schema.sql). Dit is alleen een `HSQL` syntax en ik gebruik `MS SQL`. Het probleem is dat `LONGVARBINARY` niet ondersteund wordt, dit is een `VARBINARY(max)`. Eenmaal die aanpassing door te voeren had een lege tabellen in mijn database. Dan moest ik nu de token store aanpassen en de clientDetails.

```kotlin
    // In configure
    clients.jdbc(dataSource)

    //Gebruik bij de andere beans
    @Autowired
    lateinit var dataSource: DataSource

    //Nieuwe bean
    @Bean
    @Autowired
    fun tokenStore(_dataSource: DataSource) = JdbcTokenStore(_dataSource)
```

Nu nog het aanmaken van de client.. Hoe doe je dat.. Ik heb het eerst handmatig ingevuld maar dat werkte niet. Het blijkt dat je op de `client.jdbc()` een functie hebt om dit aan te maken, ze de snippet hieronder.

```kotlin
                clients.jdbc(dataSource).withClient("slack")
                       .authorizedGrantTypes("client_credentials")
                       .resourceIds(RESOURCE_ID)
                       .authorities("ROLE_CLIENT", "ROLE_TRUSTED_CLIENT")
                       .scopes("read", "write", "trust")
                       .secret("slack-secret")
                       .and().build()
```

De `and().build()` is wat het daadwerkelijk invult in de database. Eenmaal ingevuld kan er op dezelfde manier een token worden opgehaald. Ik besprak dit met een collegaâ€™s (Tom Vervoort & Mathias Spanhove) en gaf een demo. Hun zeiden, het is nu wel zo dat de "secret" in de database staat, plaintext. Dit is natuurlijk niet veilig, als de db gehackt wordt gaat die dit kunnen uitlezen.

#### Secrets encrypted opslaan

Hoe los je het vorige probleem op..? Met een password encoder! Die encoder maak je beschikbaar als een `bean` en wordt dan opgepakt door de `AuthenticationManager` en je moet hem handmatig zetten in de `ClientDetailsServiceConfigurer`. Dit is nu `clients.jdbc(dataSource).passwordEncoder(BCryptPasswordEncoder())`. Door dit te gebruiken worden de secrets opgeslagen als [BCRypt](https://en.wikipedia.org/wiki/Bcrypt) encrypted secrets. Deze password hashing functie is gebaseerd op [Blowfish](<https://en.wikipedia.org/wiki/Blowfish_(cipher)>). BCrypt maakt gebruik van salts voor tegen rainbow attacks en is een adoptieve funtie

## Dag 41, 30-10-2018

Vandaag heb ik gesprek gehad met Benny. Hij was om 10u nog druk bezig dus moest ik even wachten, dit was natuurlijk geen probleem. Na een half uur had die tijd en hebben we besproken wat ik heb uitgevoerd. We hebben het over de OAuth gehad en ik heb hem gevraagd hoe hij de beveiliging wil omtrent het project. Er is nu een CORE project die beveiligd is en toegestaan is voor andere clients, bijvoorbeeld een web client. Deze web client is natuurlijk ook aanspreekbaar voor andere gebruikers. Dit heeft natuurlijk niet veel nut alhoewel de core alleen toegankelijk moet zijn voor directe clients (bijvoorbeeld Slack of Facebook).

Hoe ik dit ga oplossen is een oauth layer op de web api brengen die dan weer beveiligd met de core communiceert. Dit is iets wat voor de toekomst ligt.

Omdat hier in BelgiÃ« aller heiligen en aller zielen gevierd wordt (officiÃ«le feestdagen) is deze sprint relatief kort. Daardoor hebben we gekozen om de beveiliging van de web api uit te stellen. Om dit werkend te krijgen moet het project sowieso een apart project worden en zal alles dus opgebroken moeten worden. Dit is nu zoveel overhead en voegt te weinig toe om dat te verantwoorden om het nu te doen.

Waar we wel voor hebben gekozen is de deployment op orde te krijgen. Ik heb de feedback gekregen om de database te configureren als deploy stap. Dit is natuurlijk logisch, nu deed mijn applicatie dat door een DDL script te generen. Dit mag dus niet meer van Benny, ik moet handmatig de database en de tabellen maken, hierdoor kan ik wel de constraint toevoegen dat een account 1 primary email mag hebben, dit was mij niet gelukt met JPA annotaties.

Door een SQL script te maken, deze in de resources toe te voegen kan ik deze ook onderhouden in het versie beheer van de applicatie. Bij het builden van de applicatie wordt er naar een `*.war` gezocht, hier heb ik nu ook een `*.sql` aan toegevoegd. Door dit te doen heb je nu 2 artifacts, `ROOT.war` en `schema.sql`. Deze `schema.sql` kan ik gebruiken in een deployment step.

In deze stap heb ik de connectie string opgezet voor de database, deze vertrouwelijke gegevens worden opgeslagen in Azure KeyVault en zijn hierdoor niet toegankelijk voor de buitenwereld. Door dit script uit te voeren is de database bij het deployen helemaal geleegd en worden de tabellen aangemaakt.

## Dag 42, 31-10-2018

Vandaag ben ik nog verder gegaan aan mijn SQL script gegaan. Ik ben er achter gekomen dat Azure nog geen ondersteuning heeft voor de `CREATE IF NOT EXISTS`, dit is iets van SQL server 2016. Hierdoor heb ik zelf checks moeten schrijven en dat is allemaal gelukt. Nu wordt de database niet meer leeggegooid.

### Gesprek met Ilse

Ik had om 3u gesprek met Ilse, we hebben het gehad over de voortgang van het project en over nog een aantal zaken. Het was een fijn & goed gesprek. We hebben anderhalf uur gepraat over van alles en nog wat. We hebben ook de afspraak gemaakt dat ik morgen zal gaan navragen wat er verwacht wordt van mij op school betreffend mijn Portfolio. Ik heb hier eigenlijk weinig informatie over en vind het zelf ook belangrijk hier verduidelijking in te hebben.

Ilse leest ook echt mijn blogs, ze had het er zelfs over in de gesprekken. Dit is wel fijn, dan weet ze ook wat ik allemaal aan het doen ben tijdens mijn uren dat ik 10 meter verderop zit van haar. Het volgende gesprek is weer over 2 weken.

## Dag 43, 1-11-2018

### Terugkomdag op school

We hebben vandaag officiÃ«le terugkomdag op school, we gaan hier les hebben over schrijven (workshop) en een intervisie met mede stagiaires. De workshop hadden we al eens gehad heb ik het idee. Het ging hier vooral over Nederlands en hoe je het moet schrijven wat je niet/wel moet doen. Ik heb het idee dat als je de slides leest je dan ook al een heel eind komt. Echter is dit wel goed om nog eens aan herinnerd te worden voor websites zoals [woordenleest.org](http://woordenlijst.org) en de tooling om je Nederlands te controleren bij de KU Leuven.

#### Intervisie

Na de workshop hebben we een intervisie bij de stagebegeleider. Hier zaten nog een vijftal andere stagiaires, hier hebben we het over de -/+ punten gehad over de stage en dit was wel interessant. Veel mensen hadden een stage met machine learning kwam ik achter, ik was de enige eigenlijk met blockchain. Er werden wel een paar vragen gesteld over wat ik van blockchain technologie vond en of ik er de toekomst in zie. Ook heb ik vragen gesteld, ik heb gevraagd wat er nu echt verwacht wordt van je portfolio en hoe het in zijn werk gaat.

#### Portfolio

- Leeswijzer
- Alles wat je denkt dat een aspect kan bewijzen
  - Screenshots van de sprints
  - Code
  - Blog (ja deze!)
  - E-mails
- Inlever datum 8 januari vÃ³Ã³r 2 uur 's middags

-- Ik was op vrijdag 2-11-2018 vrij i.v.m. aller zielen, dit is een officiÃ«le feestdag in BelgiÃ« --

## Dag 44, 5-11-2018

Na de intervisie van donderdag had ik wel inspiratie om te beginnen aan mijn leeswijzer! Ik heb [de voorbeelden](https://fhict.instructure.com/courses/6218/pages/examples-portfolios?module_item_id=266180) gedownload en bekeken en vond die van Ricardo wel heel mooi. Dit is wel een goed voorbeeld. Ik ben begonnen met het downloaden van de Info Support huisstijl, dit vind ik wel een mooie bonus als je hier gebruik van maakt.

Ik heb vandaag een groffe opzet opgezet en ga hier morgen weer aan verder. Ik heb geen gesprek met Benny want die is weg (een talk geven in Moscow) en heb dus besloten mijzelf volledig te storten op mijn leeswijzer. Wish me luck!

## Dag 45, 6-11-2018

### Leeswijzer

Zoals ik gister zei ging ik vandaag verder met de leeswijzer. Dit heb ik ook gedaan. Ik vind het wel echt lastig om dit voor elkaar te krijgen. Ik heb mijn stage document van mijn vorige stage erbij gepakt om een beetje gevoel te krijgen voor het schrijven. Daar heb ik toen met veel moeite aan gewerkt en veel feedback van Carli voor gekregen. Ik heb hier heel de dag mee bezig geweest.

### Universiteit van Nederland, 6 nov 2018

Het is weer zo ver! Er is weer een opname van de Universiteit van Nederland en ik ben er weer bij samen met [@joel](https://github.com/joelluijmes). We hebben samen bij de Griek gegeten, Joel een pita gyros (het was zijn eerste keer!) en ik een gyros schotel. Het smaakte goed en zijn daarna naar Amsterdam gereden.

Eenmaal aangekomen in Amsterdam hebben we de P+R faciliteit gebruikt van de Amsterdam ArenA. Daar staat de auto droog, veilig & goedkoop (aanrader). Je kan vanuit daar de metro pakken naar het centraal station echter moesten we daar niet zijn. We hoefde maar 4 haltes met de metro en toen waren we al bij Amsterdam AIR, waar de lezing plaatst vind!

![Universiteit van Nederland](https://github.com/zwolsman/g-log/raw/master/img/foto-uni-van-nederland.JPG)

Het thema van de avond is _het einde der tijden_. Er zijn een 5-tal professor met verschillende achtergronden. Dat zie je ook terug in de onderwerpen. Ik heb hieronder een lijstje met de onderwerpen en wat ik er van vond!

#### Wat gebeurt er als de golfstroom stilvalt?

Dit was een leuke talk! Er was zelfs een live experiment, dat maakt het altijd duidelijker, interessanter en mooier! Ze had een bak water bij en ze deed er ijs in met blauw kleurstof. Ze was aan het vertellen over de golfstroom dat die heet water mee neemt, af laat koelen, naar de bodem zakt (omdat het kouder is, dus zwaarder), en dan weer teruggevoerd wordt naar richting de evenaar om weer opgewarmd te worden. Dit zag je perfect in haar experiment, het blauwe water zag je naar beneden gaan en dan deed ze rood kleurstof bovenop en dat zag je naar het ijs toegetrokken worden.

Met dit principe wordt het klimaat dus ook beÃ¯nvloed, ze had een film als voorbeeld: the day after tomorrow. Dit is een sciencefiction/thriller en gebruikt dit principe, de stroom wordt omgedraaid waardoor het klimaat totaal veranderd. Ze zei dat dit wel mogelijk was, de kern van de film. In de film gebeurt dit in een week maar in het echt zou dit 50-100 jaar duren.

#### Waarom gaan we uiteindelijk ten onder aan plastic soep?

Deze was wel een eye opener, hoeveel plastic wij gebruiken als mensheid is echt niet normaal. Ze noemde plastic een design fout, het is helemaal uit de hand gelopen en er zijn voorspellingen dat ze in het jaar 3.000 nog steeds plastics vinden van _nu_. Dat is echt ongelofelijk! Het is ook werkelijk overal, ze heeft op verschillende punten metingen gedaan naar micro-plastics. Dit zijn de kleinste deeltjes van plastic die er bestaan. Omdat we plastic overal gebruiken komt het dus ook echt overal, het zit in onze kleren (polyester), ons eten is er in verpakt, onze telefoons zijn er van gemaakt etc. etc. Ze had een meeting gedaan naar microplastics in het afvalwater uit huis en daar kwam ze plastic tegen, uit het polyester van je kleren die je in de wasmachine stopt. Deze microdeeltjes komen in het riool terecht, gaan naar het zuiveringsstation en worden daar grote deels eruit gefilterd, maar niet alles! Wat er doorheen glipt komt in de natuur terecht of in ons drinkwater. Met die ontdekking was ze gaan onderzoeken of wij het ook in ons hebben. Dit is nog niet vastgesteld, wel de additieven (zoals brandvertragers, pigment, antistatisch etc.) zijn wel al terug gevonden in ons lichaam!

Sinds dat onderzoek zijn er ook een x aantal additieven verboden omdat ze toxisch zijn voor ons lichaam. Eenmaal in je lichaam kom je er niet van af en kunnen er chronische ontstekingen ontstaan. Dit wil je natuurlijk niet..

#### Zijn wij wel goed voorbereid op de volgende pandemie?

Dit was een vrouw die gespecialiseerd was in virussen. We hebben een basis les gekregen over hoe een virus werkt en wat de elementen zijn waar ze uit bestaan (de basis). Ook over de 5 verspieding methodes: door de lucht, aanraking, bloed, seks en mond naar kont. Die laatste is bijvoorbeeld de buikgriep, dit gaat door de darmen er weer uit.

Na deze informatie hebben we bekeken wat voor uitbraken er zijn geweest en hoe we er op hebben gereageerd. Als voorbeeld hebben we naar de Spaanse griep, ebola en de gewone griep gekeken. Griep kennen we allemaal en heeft iedereen wel eens gehad. De laatste griep pandemie was in 2012 (Mexicaanse griep) en was zo gemuteerd dat ons immuunsysteem het niet herkende/mee om kon gaan. Wat had dit als gevolg? Overvolle ziekenhuizen, scholen die moesten sluiten. Meer dan 250.000 mensen waren geÃ¯nfecteerd en er waren 13.000+ doden gevallen. Dit is ongelofelijk voor een griep.

Natuurlijk hebben we het nieuws over ebola ook gehoord, dit was eerst alleen in een dorp ergens in Kongo en hield telkens op omdat het dorp zo afgelegen was. De mensen waren op; ze waren dood of immuun waardoor het virus zich niet verder kon verspreiden. Er is ergens iets gebeurd waardoor het mee kwam naar het westen (een mega stad) waarna het zich als een gek heeft verspreid. Dit had dodelijke gevolgen, gelukkig is het nu onder controle.

Ook als voorbeeld is er het Zika virus, de virussen die behandeld worden Ã¼berhaupt komen eigenlijk uit de dieren wereld. Het virus is dan zo gemuteerd dat het vatbaar was voor de mens; Zika is er hier ook een van. Eerst was het een mug-aap-mug cyclus, op een begeven moment is de aap vervangen door de mens en zij wij de dragers geworden. Dit heeft heel veel gevolgen in de samenleving.

Al met al was dit ook een interessante talk, veel geleerd over virussen en wat ze eigenlijk doen; ik wist niet eens dat ze vanuit de dieren wereld kwamen.

#### Hoe ziet een wereld zonder insecten eruit?

Een wereld zonder insecten, geweldig toch? Geen muggen, geen spinnen (handig he Ilse ðŸ˜›), eigenlijk gewoon geen vieze beestjes meer. Maar deze zijn wel degelijk nodig. In de afgelopen 30 jaar zijn de insecten met 76% afgenomen! Ongelofelijk, meer dan 3/4e. Dit heeft impact op heel veel dingen. Insecten zijn een belangrijk iets in de voedsel keten en in de bestuivingen van bloemen. In China zijn de wilde bijen al uitgestorven en moet de hand alle bloemen bestuifd worden; dit is toch te gek voor worden! Als dit zo door gaat wordt fruit een luxe wat alleen de super rijke zich kunnen veroorloven. Als het voedsel web ook verstoord wordt vallen er een heleboel beesten ook af omdat er gewoonweg geen eten meer is voor ze.

Ook hebben de insecten een lang leven onder de grond, als voorbeeld de langpootmug. Deze mug is 7 jaar lang een larf onder de grond.. hier heeft het een functie om samen met de bacteriÃ«n alles te verwerken wat op de grond valt. Hierdoor blijft de grond mooi zwart en vruchtbaar. Als deze ook allemaal weg zijn hebben we een kleiachtige wit/gele grond zonder enige voedingsstoffen. Dit is nadelig voor de landbouw en zal ook meer met de hand moeten gebeuren. Ook zullen bijvoorbeeld de bladeren niet meer opgenomen worden in de grond maar gaan ze rotten boven op de grond.. Dit is ook niet ideaal.

Al met al, we moeten ze niet allemaal dood willen hebben. Het voordeel is is dat insecten zich goed kunnen voortplanten, meerdere generaties per jaar en veel offspring. Ze moeten hier wel de ruimte voor hebben, dus als tip kregen we mee. Plant bloemen buiten voor de bijen en denk 2x na voordat je er eentje vermoord.

#### Hoe kan een cyberaanval het internet platleggen?

Dit was de laatste van de avond en natuurlijk de meest interessante voor ons (allebei ICTers). Kan dit echt? Ik was er sceptisch over. Internet is meer dan wat de consument denkt, wat wel kan is dat de services plat gaan die de consument gebruikt (en interpreteert als internet). Hij had het over DDoS aanvallen die vroeger enkele GBits/s waren die nu al TBits/s kunnen zijn. Dit is een ongelofelijke hoeveelheid data. De vergelijking had die met mensen die tegelijk HD Netflix kijken. De aanval met een paar GBits/s was evenveel als dat alle inwoners van Texel tegelijk Netflix zouden kijken. Dit is al aardig wat in mijn ogen. Die aanval met een paar TBit/s is alsof 300.000 mensen tegelijk Netflix HD gaan kijken. Dit is al ongelofelijk in mijn ogen.

De nieuwe aanvallen die er aan zitten te komen worden alleen maar krachtiger en krachtiger. Hij had het over een aanval die overeen kwam met 30.000.000 mensen die Netflix HD kijken. De problemen die hierdoor kunnen opkomen gaan groots zijn, banken die het niet doen; vliegtuigen die niet kunnen vliegen.. en nog meer!

Wat die voorstelde? Een noodplan. Een plan voor wat we doen als we aangevallen worden in een (toekomstige) cyberoorlog. We moeten onszelf kunnen disconnecten van het Internet en een infrastructuur hebben die ook door kan zonder internet. Als bij ons de dijken doorbreken hebben we ook een duidelijk stappenplan wat we moeten doen. Dit zouden we ook moeten hebben voor de cyberoorlog!

### Conclusie

Het was weer een productief, leuk & druk dagje. Veel geleerd en druk bezig met de leeswijzer. Hier zal ik morgen ook weer mee verder gaan. Ook staat er een ISKA gepland over het GIF bestands formaat.

## Dag 46, 7-11-2018

### Overdag

Overdag ben ik bezig geweest met mijn leeswijzer.. Ik begin hem wel een beetje beu te worden. Ik merk dat ik er echt niet goed in ben en vaak hele lappen teksten weer verwijder omdat het me niet aanstaat. Hierdoor heb ik eigenlijk nog niet heel veel maar ik doe mijn best.

Omdat we pas rond 6u eten heb ik om 5u besloten iets voor mezelf te doen. Ik ben begonnen aan een nieuwe programmeertaal, puur uit interesse. Je leest steeds meer over functionele programmeertalen en ik heb [Elixir](https://elixir-lang.org) uitgekozen. Ik vind het schrijven van web api's altijd interessant en heb over en [phoenix framework](http://phoenixframework.org) gelezen. Dit is blijkbaar een super snel web framework.

Na een dik uur hier mee bezig te zijn was het eten er! Pizza ðŸ•â¤ï¸!

### Iska GIF

Na het eten begon de ISKA van Jasper, dit was zijn eerste ooit. Dit gaf hij van te voren aan en wou graag feedback achteraf voor mogelijk toekomstige ISKA's. Het ging over GIF en over het compressie algoritme. Ik vond dat zelf heel interessant, we hebben op school met `S-JCF41-S41` een huffman compressie moeten maken.

Het compressie algoritme die gebruikt wordt bij GIF is een [Lemple-Ziv-Welch-algoritme](https://nl.wikipedia.org/wiki/Lempel_Ziv_Welch). Dit zelfde algoritme wordt ook gebruikt door de unix `compress` command. Hij had dit zelf geÃ¯mplementeerd in Java, je had 3 verschillende varianten. Eentje met een 8-bit dictionary, 12-bit en een variable. Het algoritme maakt een dictionairy met herhaalbare tokens waardoor het dus een token van > 1 tekens op kan slaan als 1 byte.

Dit algorithme was het grootste deel van de talk, het ging over bit shiften, bytes lezen en nog meer low level dingen (masks etc.). Dit was leuk want daar ben je normaal de dag niet meer mee bezig maar dit is wel hoe het allemaal under-the-hood werkt.

Door veel gepraat over het algoritme was het al snel anderhalf uur later en zijn we snel overgestapt naar de daadwerkelijke gif implementatie. Hij had een GIF decoder geschreven die alle frames van een gif eruit haalde en weg schreef als los plaatje.

Al met al was het een leuke leerzame ISKA ook al was het zijn eerste x. De volgende ISKA gaat over React Native maar die zal nog even duren.

## Dag 47, 8-11-2018

Vandaag begon ik weer aan mijn leeswijzer. Terwijl ik bezig was met mijn leeswijzer dacht ik, waarom moet dit op deze manier. Waar komt dit vandaan? De leeswijzer zou een verduidelijking moeten zijn op mijn portfolio en het proces moeten toelichten.

Ik bedacht mezelf, kan ik niet een mini documentaire maken over mijn stage en die dan inleveren bij school zodat ze een beeld hebben bij wat ik heb gedaan? Ik ben met dit idee aan de slag gegaan.

De elementen die in de leeswijzer moeten zitten heb ik omgeschreven naar interview vragen en een vriend van mij een bericht gestuurd. Hij woont in Brussel en ik kan daar wel langs gaan. Hij studeert film en heb hem het idee uitgelegd. Ik heb gekeken naar mini documentaires en heb een hele mooie duidelijke gevonden die ik als voorbeeld zie. [Deze](https://www.youtube.com/watch?v=lxYFOM3UJzo) documentaire duurt 12 minuten en belicht toe hoe een programmeur een programmeertaal heeft gemaakt en hoe het verloop is gegaan. Ik heb aan Ilse gevraagd of ik de dag er na (morgen) thuis mag werken en dan ga ik aan het interview werken.

Ik heb zelf niet veel verstand van interviewen maar Wessel wel, hij heeft nog eens geholpen met de vragen te formuleren en hoe hij ze heeft gesteld kan je ze goed editen. Ook dit is nieuw voor mij maar wel een leuke uitdaging.

## Dag 48, 9-11-2018

### Interviewen!

Vandaag is de dag dat het interview plaats vind voor de proof-of-concept. Ik weet nog niet wat school er van gaat vinden maar een ga een ruwe opzet doen. Ik heb met Wessel afgesproken en zijn gaan zitten. We hebben de vragen samen besproken en we zijn begonnen.

Wessel heeft zelf geen programmeerachtergrond. De vragen die en antwoorden zouden dus zo gegeven moeten worden dat hij ze ook snapt.

Eenmaal het ruwe footage opgenomen te hebben ben ik het gaan verwerken. Ik had de vragen wel voorbereid maar de antwoorden niet. De antwoorden bevatte vaak een "uh" en die heb ik er allemaal uit geedit.

Eenmaal klaar met het verwerken heb ik het geÃ¼pload naar YouTube, die is [hier](https://www.youtube.com/watch?v=3A_tpx_T0N8) terug te vinden. Dit is een ruwe versie. Het streefdoel is zoiets als [dit](https://www.youtube.com/watch?v=lxYFOM3UJzo) neer te zetten.

Ik heb een mail opgesteld en verstuurd naar Bartosz! Ik ben benieuwd.

## 11-11-2018

### Reactie van Bartosz

Bartosz heeft gereageerd! Hij is er enthousiast over, wel moet ik toestemming vragen aan Marcel. Ik zal hier morgen een mail voor opstellen! Ik ben echt blij dat ik zo'n positieve reactie heb gekregen. Wel stelt hij voor om een transcriptie te maken van het interview om daar feedback op te krijgen en te verwerken. Hier zal ik morgen mee aan de slag gaan.

## Dag 49, 12-11-2018

Terugkomend op de reactie van Bartosz ga ik vandaag een transcriptie maken van het _hele_ interview, ook wat ik niet had bewerkt. Dit is zodat er feedback gegeven kan worden op het interview. Ik heb ook een mail opgesteld naar Marcel om het idee voor te leggen. Ik ben benieuwd wat die daar van vind.

Uiteindelijk heel de transcriptie geschreven (2000+ woorden) na talloos terugluisteren van het interview. Ik heb mezelf nu wel genoeg gehoord & gezien. Dit heb ik op de mail gezet naar Bartosz toe en ben benieuwd wat voor feedback ik ga krijgen.

## Dag 50, 13-11-2018

### Gesprek Tim Mahy

Vandaag had ik om 10.00u een gesprek met Tim Mahy. Dit ging over een code-review. Ik ging hier onvoorbereid naar toe en wist niet goed wat ik moest verwachten. We zijn apart gaan zitten en hij vertelde mij dat dit een review was of ik binnen Info Support pas en in aanmerking zou kunnen komen voor een contract. Aan het einde van dit gesprek moet hij een advies geven over mij.

Ik dacht oh shit, ik ben hier niet op voorbereid! Hij zei ook dat dit de bedoeling was. Ik ben begonnen met mijn opdracht uit te leggen en wat wel en niet binnen mijn opdracht valt. Toen heb ik de architectuur geschetst. Hij had er meteen vragen over waarom en wat de voordelen waren. Voor mijn gevoel kon ik het goed verdedigen en mijn keuzes onderbouwen. Toen zijn we ingegaan op de blockchain; wat het toevoegt, waarom, aanrader of niet. Ook hebben we het over documentatie gehad, ik heb toen mijn dashboard laten zien in Azure DevOps, de readme die ik had gemaakt en mijn PID. Ook hebben we gekeken naar de actuator endpoints en waarom ik die beschikbaar heb gesteld.

Het onderwerp testen kwam ook in beeld, Tim had van te voren al in mijn repo gekeken maar kon de testen niet goed terug vinden. Dit kwam omdat er een mapje "tests" is onder src. Toen ik die liet zien en was dat nog niet alles. Dit waren de unit tests van de applicatie maar ik heb unit tests geschreven voor het smart contract. Deze waren terug te vinden in het mapje "truffle". Die had die niet gezien! Hij vond het wel cool dat ik dit had gemaakt en heeft er ook van geleerd.

Ook hebben we het over toepassing van de blockchain gehad, wat ik er van vind. Ik heb hem [crypto kitties](http://cryptokitties.co) laten zien en uitgelegd waarom dit een echte blockchain applicatie is en waarom dit wat ik nu maak niet een echte blockchain applicatie is. Hij vond het goed dat ik ook de echte concepten snapte en daardoor ook kon concluderen dat ik dit geen gepaste applicatie vind.

Al met al was Tim zeer positief en heb ik ook een "meer dan positief" advies gekregen zei die. Dit is wel fijn om te horen en ben er ook trots op.

### De dag verder

Verder ben ik aan de slag gegaan met mijn documentatie. Ik heb met Marcel gemaild over wat er nu verwacht wordt en heb nu een beoordelingsformulier gekregen. Als ik mijn leeswijzer verfilm moet ik mijn _schrijftelijke verslaglegging_ op een andere manier aantonen. Dit zal mede doormiddel van deze blog zijn. Het probleem.. Deze blog is niet heel netjes geschreven, het waren mijn ruwe gedachtes. Ik ben begonnen met alle typ- en spellingsfouten eruit te halen. Dit waren er behoorlijk veel, __153__ om precies te zijn! Ook heb een ik een table of contents toegevoegd, deze zal ik eens in de week updaten zodat die overeen komt met het huidige document.

![Spellingscontrole](https://github.com/zwolsman/g-log/raw/master/img/ss_spellingscontrole.png)

Ook ben ik nog bezig geweest met Git/GitHub en mijn file encoding. Deze stond op `UTF-16LE` waardoor die gezien werd als `binary` file. Dit is niet fijn want dan kan ik mijn changes niet zien. Ik heb met een git commando mijn hele history opniew neergeschreven met `UTF-8` encoding en nu werkt wel alles. Als ik dit niet had gedaan kon ik bijvoorbeeld de changes van mijn spellingscontrole niet inzien, het enige wat er dan kwam te staan is `xxx bytes` toegevoegd.

Het git commando wat ik heb gebruikt is het volgende

```bash
murf@Marvins-MacBook-Pro: [~] $ git filter-branch --tree-filter $pwd/tmp/recode-all-files HEAD
```

`$pwd` is de `pwd` functie in de fish shell, dit verwijst naar een scriptje met de volgende code.

```bash
#!/bin/sh

find . -type f -print | while read f; do
        mv -i "$f" "$f.recode.$$"
        iconv -f utf-16-le -t utf-8 < "$f.recode.$$" > "$f"
        rm -f "$f.recode.$$"
done
```

Deze maakt een kopie aan van elk bestandje en gebruikt de `iconv` tool voor de nieuwe encoding. Op deze manier blijft je history hetzelfde en is de encoding wel aangepast. Je moet dit dan pushen met de `--force` flag.

## Dag 51, 14-11-2018

Vandaag ben ik verder gegaan met mijn React course op Pluralsight. De elementen die nu aangekomen zijn is het testen van applicaties. Dit is wel een interessant onderwerp. Het verschil tussen de frameworks (met code voorbeelden) en hoe je ook je recuders moet testen etc.

Deze kennis ga ik gebruiken bij het bouwen van een web frontend voor mijn stage opdracht. Omdat ik geen contact heb met Benny op het moment (hij is in Rusland op een lezing) bereid ik mezelf alvast voor zodat ik dan stappen kan maken.

### CROQUE MIDDAG!

Stefanie had een croque (tosti) middag georganiseerd! Ik heb meegeholpen in de _assembly line_ en heb samen met 5 andere collega's alle tosti verzorgt. Hieronder zie je een foto van ons in actie. Ik heb in het totaal 3 tosti's op en ze waren heerlijk. Zeker voor herhaling vatbaar als je het aan mij vraagt!

> Random fact: Ham heet hier _hesp_

![Croque assembly line](https://github.com/zwolsman/g-log/raw/master/img/ss_croques.jpg)

### Gesprek met Ilse

Vandaag is ook weer het 2-wekelijkse gesprek met Ilse. We hebben het gehad over mijn portfolio; hoe ik dit ga aanpakken. Hier heb ik zelf nog wel enige vragen bij. Omdat ik met het idee van een interview kwam moet ik een beetje de weg vinden wat nu nog schriftelijk moet en wat niet. Dit heb ik ook samen met Ilse besproken. Ook hebben we het over het interview gehad en de feedback die ik had gekregen. Op het moment wacht ik nog op een reactie van Bartosz, als die het uitgewerkte interview voldoende vind  weet ik ook wat er nog in een eventueel `portfolio abstract` moet wat dus **niet** in het interview zit.

## Dag 52, 15-11-2018

Vandaag ben ik begonnen aan een [course Bulma](https://app.pluralsight.com/library/courses/building-websites-bulma/table-of-contents). Dit is een CSS framework gebaseerd op Flexbox. Omdat ik uiteindelijk een webapp moet maken was ik benieuwd naar hoe [Bulma](https://bulma.io) werkt. Dit was een duidelijke course en had ik wel wat aan.

Ik ben daarna gaan kijken of ik dit kon toepassen in React. De eerste blogpost die ik las was [Introduction to Bulma with React](https://alligator.io/react/intro-react-bulma-components/), deze maakte gebruik van de npm package `react-bulma-components`. Die documentatie was te vinden [in een storybook](https://couds.github.io/react-bulma-components/), dit is een playground waar je code ziet en het resultaat. Hier kan je ook live dingen aanpassen, deze manier is heel gebruikelijk binnen de React community.

Met deze informatie heb ik een basis design gemaakt met react components!

### After lunch talk van collega

Een van onze collega's (Tom Cools) gaf een talk bij Devox Belgium, het ging over side projects. Deze hebben we met zijn alle bekeken op een tv scherm (foto hieronder).

De 3 punten die hij besprak waren *limit yourself*, *automate whatever* en *replicate*. Door die 3 principes te gebruiken bij je pet projects leer je nieuwe dingen die je daarna weer kan toepassen in je professionele leven.

Limit yourself was een game die hij had gemaakt zonder enige libraries en zijn eigen basis physics engine te maken.

Automate whatever was in zijn tijd als leraar de preventielijst automaten. Als er gezichten herkend werden stuurde hij ze naar de cloud en werden ze aan een naam gematcht. Op die manier hoefde hij de preventie lijst niet meer zelf bij te houden.

Replicate was zijn pokemon go reverse engineering trip. Hij heeft een pokemon go server nagemaakt en is anders gaan denken. Hij nam als voorbeeld dat toen hij het eerst bedachte alles met JSON en HATEOS te doen maar uiteindelik bleek de implementatie super anders. 1 Endpoint (`/rpc`) met Google Protocol Buffers.

Van al die projecten leerde hij verschillende dingen die hij dus daadwerkelijk meenam in zijn professionele leven. Ik vond het wel een leuke talk.

De video is [hier](https://www.youtube.com/watch?v=KADksbmr8NY) te vinden, hij heet _Learning Through Tinkering: The Need for Pet Projects by Tom Cools_

![Tom talk](https://github.com/zwolsman/g-log/raw/master/img/ss_talk_tom.jpg)

## Dag 53, 16-11-2018

Vandaag wou ik typescript gebruiken in mijn React webapp. Dit is een superset op javascript, het voegt types toe. Door types toe te voegen werkt de intellisense vele malen beter in Visual Studio Code en vind ik het fijner werken.

Ik ben naar blog's gegaan op medium om te kijken wat mensen al hadden ondervonden. Tot mijn verbazing vond ik een blogpost genaamt [Why I no longer use TypeScript with React and why you might want to switch too](https://hackernoon.com/why-i-no-longer-use-typescript-with-react-and-why-you-shouldnt-either-e744d27452b4). Dit zag ik niet aankomen, de javascript community is juist altijd super positief over typescript en hier vind ik iemand die zegt dat je het niet moet doen?! Wat zijn de minpunten. Eigenlijk is het grote minpunt waarom hij het afwijst de compile time. Als je een change maakt in typescript moet de hele file opniew gecompiled worden, dit duurt langer dan dat het.. niet hoeft? Dit was een minpunt waar ik wel mee kon leven, het was alsnog snel genoeg op mijn laptop.

Ik vond ook een blog genaamt [React + TypeScript = â¤ï¸](https://medium.com/@amcdnl/react-typescript-%EF%B8%8F-647aa7d054a9), kijk! Dat lijkt er meer op! Je ziet hier iemand eigenlijk heel typescript zelf instellen voor react, deze post komt ook uit augustus 2018. Dit is alweer 3 maanden geleden. Wat zou er allemaal al veranderd zijn? Ik ging kijken naar de `react-scripts-ts` die [hier](https://github.com/wmonk/create-react-app-typescript) te vinden is en heb het volgende commando uitgevoerd

```bash
murf@Marvins-MacBook-Pro: [~] $ create-react-app my-app --scripts-version=react-scripts-ts
```

Dit maakt een applicatie genaamt `my-app` aan met typescript! Alles is al geconfigureerd en werkt out-of-the-box. Dit is natuurlijk geweldig! Ik heb ook gekeken voor een andere UI library, kijken hoe dat werkt.

Ik kwam uit op [ant.design](https://ant.design), de style trok mij heel erg. Ook vond ik het een pluspunt dat het **meer** is dan een component library, het is een design language. Wat betekend dit? Dat er guidelines zijn waar je een button neer zet en _waarom_. Ik vind dit wel waardevolle informatie waardoor je consistent blijft in je vormgeving. Dit is zeker een pluspunt. __PLUS__ het ondersteund typescript! Dit is gewoon mooi. Ik heb een proof-of-concept gemaakt in react, typescript en ant. Hieronder zie je een screenshot. Dit is nu nog statische dummy data, ik wil dit laten zien aan Benny aankomende dinsdag zodat we kunnen bespreken of ik dit mag gaan uitwerken.

![Screenshot webapp proof of concept](https://github.com/zwolsman/g-log/raw/master/img/ss_webapp_poc.png)

## Dag 54, 19-11-2018

Ik ben bezig met react maar zou het graag een stap verder willen nemen. Omdat react zo "vrij" is dat je alles zelf mag bepalen ben ik "te" vrij als nieuweling. Ik weet niet wat de juiste mappen structuur is en ben gaan zoeken.

### Mappen structuur react app

Ik vond blogs op [medium](https://medium.com) betreffend dit vraagstuk. De blog [How to better organize your React applications?](https://medium.com/@alexmngn/how-to-better-organize-your-react-applications-2fd3ea1920f1) maakt duidelijk onderscheid tussen "features" en "scenes". Veel mensen zien een pagina ook als een component en hebben 1 component map. Deze map raakt snel vol met alle losse componenten die gebruikt worden op een pagina en heb je dus geen onderscheid tussen een "dumb" component en een "smart" component.

#### Smart component

Een smart component, oftewel een container component is een component met logica. Deze heeft de callbacks, de data en als je redux gebruikt is deze ook verbonden met de store. Deze heeft verder geen styling maar heeft een opbouw van "dumb" components. De dumb components referenen terug naar de smart/container components voor bijvoorbeeld als er op een knop wordt geklikt.

#### Dumb component

Een dumb component, oftewel een presentation component heeft geen logica. Deze heeft een lijst van properties die meegegeven moeten worden (data, callbacks) en zal deze dan weergeven. Dumb components hebben wel styling, die bepalen de look. Een dumb component heeft geen idee hoe die aan data moet komen, wat er moet gebeuren als er op een knop wordt gedrukt etc. etc. Deze weet wel WAAR de knop moet staan en HOE die er uit ziet. Als er op wordt geklikt wordt dat teruggekoppeld naar de smart component.

Nu we dit weten kunnen we concluderen dat een page een dumb component is die container components heeft. Deze container components hebben dan weer dumb components om dingen weer te geven. Op deze manier kan je dus onderscheid maken tussen scenes en components. Ook is het mogelijk om op 1 component afhankelijk te zijn van andere components die nergens anders worden gebruikt, deze moeten dan genest worden in de map van het component.

Op deze manier hou je orde en overzicht. Ik heb op github een rock paper scissors voorbeeld gevonden in deze opbouw; die is [hier](https://github.com/alexmngn/react-rock-paper-scissors) te vinden.

## Dag 55, 20-11-2018

> Het is mijn verjaardag! Ik heb taart gehaald voor mijn collega's. Er was krieken-, flannen- en rijstentaart.
> ![Screenshot webapp proof of concept](https://github.com/zwolsman/g-log/raw/master/img/IMG_F20BFA16AFBB-1.jpg)

Vandaag hebben Mathias en ik een afspraak 's middags met Mark Stap over de arbeidsvoorwaarde bij Info Support. Ik kijk daar wel naar uit.

### Reacten

Ik ben ook weer bezig geweest met reacten. Ik heb een "add bonus" knop gemaakt die een venster weergeeft waarop je data kan invoeren. De data die ingevoerd moet worden is natuurlijk naar wie, hoeveel punten en de tekst om er aan toe te voegen.

### Arbeidsvoorwaarde presentatie

Omdat het gesprek met Tim Mahy goed ging kwamen we in aanraking voor een contract. Deze presentatie werd gegeven door Mark Stap, een collega van HR. In de presentatie kwam heel veel aan bod, van aantal vrije dagen tot pensioen. De eerste presentatie ging over de voorwaarde in Belgie, deze zijn iets anders dan in Nederland. Na al deze informatie ben ik nog apart genomen en heb ik de presentatie van Nederland gekregen. Ik had aangegeven dat ik niet persee terug naar Nederland moet en er heel erg open-minded over ben vandaar de 2 presentaties.

Onder de streep scheelt het bijna niks met elkaar, het is alleen iets anders opgebouwd. Een van de verschillen die er wel uitsprongen was het aantal vrije dagen. In Nederland is dit 5 weken, in Belgie 8! Dat is nogal een groot verschil vond ik zelf, dit is alleen wettelijk bepaalt dus vandaar.

Ook viel het mij op dat je in Belgie netto maaltijdcheques krijgt, dat is blijkbaar iets typisch belgisch. Over 80% van de gewerkte dagen in de maand krijg je een x bedrag als maaltijdcheque.

Ik ben ook een uur eerder gestopt vandaag ivm mijn verjaardag. Mijn familie komt mij opzoeken en Mechelen en gaan met zijn alle uiteten. Aangezien ik morgen naar de ISKA ga haal ik dat uur weer in en klopt alles gewoon.

## Dag 56, 21-11-2018

### Aanpassingen core

Aangezien ik in mijn OAuth implementatie alleen de Slack client heb geregistreert werkte de web api niet meer. Omdat ik zo verder aan het gaan ben met mijn front-end react app moest ik dit eens updaten. Wat komt er allemaal bij kijken?

#### Schema.sql updaten

`Schema.sql` is het script wat uitgevoerd wordt bij het deployen. Deze gooit de database weg en maakt een nieuwe aan. Hier heb ik ook insert statements in zitten voor het aanmaken van de clients. Hier moet nu dus een extra client bij.

#### OAuth filter voor de Feign client van de web api

Nu de API geregistreert is moet er in de `resources.properties` de `clientId` en `clientSecret` opgenomen worden zodat deze gebruikt kunnen worden voor de WebClient. De client krijgt een OAuth filter die hier gebruik van maakt voor het aanvragen van een token, deze implementatie is hetzelfde als die van Slack maar met een andere id/secret.

Na deze aanpassingen kan de webclient weer gebruik maken van de core. Ik kan bonussen ophalen!

### React bonuses laten laden

Oke, de API is in orde. Nu het React gedeelte. Hoe gaan we dit aanpakken. De normale JavaScript fetch api is beschikbaar (want het is tenslotte een JavaScript omgeving). Deze ga ik gebruiken! Hoe ga ik er voor zorgen dat hier types worden gebruikt voor TypeScript? Hieronder zie je een snippet van de code. In de container class (BonusList) wordt er in de `componentDidLoad()` een call gemaakt naar `loadBonuses` die dan de state update van het desbetreffend component.

```typescript
interface IPage<T> {
  content: T[];
  last: boolean;
  number: number;
}

export interface IBonus {
  from: string;
  to: string;
  points: number;
  comment: string;
}

async function loadBonuses(): Promise<IBonus[]> {
  const response = await fetch(API_URL);
  const page = (await response.json()) as IPage<IBonus>;

  return page.content;
}
```

Dit component laad dan alle bonussen zien die van de API komen. Ik heb er voor gekozen om de e-mailadressen te splitten op een `@` en alleen het eerste deel te laten zien.

Nu is het `18:15` en ga ik eten! Om `19:00` begint de ISKA over React Native! Ik ben benieuwd.

### De ISKA

De Iska ging dus over React Native, een React port die i.p.v. html elementen renderd in je browser bouwt naar native componenten (TextLabel, TextInput etc.). Deze ISKA was gegeven door iemand die een app had gemaakt in deze omgeving.

Tijdens de presentatie vertelde hij waarom die React Native fijn vond en dit waren allemaal argumenten waarom React fijn is, niet een specifieke voor React Native. Dit vond ik al een beetje gek. Hij had wel verteld dat die een Web achtergrond had en dat dat goed aansloot bij dit.

Hij was ook een voorstander van TypeScript en veel van de voordelen die hij opnoemde voor React Native kwamen ook door TypeScript. Ik denk dat hij niet veel ervaring had met gewoon JavaScript en daardoor niet inzag wat TypeScript allemaal toevoegd.

Tijdens het bouwen ging er veel mis, de bundler startte niet goed, tijdens het hercompileren ging er vanalles fout waardoor de app een rood scherm werd met foutmeldingen. Het voelde allemaal een beetje amateuristisch aan. Dit komt waarschijnlijk omdat die veel van branch switchtde en er dingen gecached werden waardoor er honderd-en-een dingen fout gingen.

Vanuit mijn Smart Mobile achtergrond (2 jaar specialisatie & minor) vond ik het niet zo aantrekkelijk. Ik ben toch echt wel een voorstander voor Native. Dan kan je alles precies voor dat platform maken en het zal altijd sneller zijn omdat er geen vertaalslag of wat dan ook nodig zal zijn. Ook denk ik dat als je Native ontwikkeld je veel meer feel hebt voor het besturingssysteem dat je gebruikt.

## Dag 57, 22-11-2018

### Gesprek met Benny

Vandaag heb ik weer eens een gesprek gehad met Benny. Hij is een week afwezig geweest omdat die een talk had in Moscow. Ik heb besproken wat ik afgelopen 2 sprints heb gedaan, dit was mijn interview opnemen & voorbereiden, React & Bulma courses en de Proof-of-Concept opzetten voor de web app.

Benny kwam met de functionaliteit om Azure Active Directory te integreren. Dit is zodat mensen met hun Info Support account kunnen inloggen en er ook een auto-complete functionaliteit zal komen bij het geven van een bonus in de web app. Dit leek mij een mooie toevoeging en dit hebben we ingeplanned.

### Wat is Azure Active Directory?

[Azure Active Directory](https://azure.microsoft.com/nl-nl/services/active-directory/) is een identiteits- en toegangsbeheersysteem. Hier heeft Info Support al zijn gebruikers in staan. Deze kan via het OAuth 2 protocol aangesproken worden om toegang te geven.

### Integratie met AAD

Oke, nu ik een idee heb wat het is moet ik het werkend krijgen. Ik heb een demo project aangemaakt genaamd `aad-demo`. Spring ondersteund Azure Active Directory en heb dus de dependencies toegevoegd bij het maken van de applicatie met de [Spring Initialzr](https://start.spring.io).

Dependencies:

- Web (`spring-boot-starter-web`)
- Security (`spring-boot-starter-security`, `spring-security-oauth2-client`, `spring-security-oauth2-jose`)
- Azure Active Directory (`azure-active-directory-spring-boot-starter`)

Ik heb het [tutorial](https://azure.microsoft.com/en-us/blog/spring-security-azure-ad/) van Microsoft gevolgd genaamd _"Spring Security Azure AD: Wire up enterprise grade authentication and authorization"_. Na dit tutorial te volgen werkte het nog steeds niet. Ik kan maar niet begrijpen waarom niet. Ik heb de stappen gevolgd en krijg een foutmelding.

Na de comments te lezen op de Github van [Microsoft/azure-spring-boot](https://github.com/Microsoft/azure-spring-boot) kwam ik bij het kopje _"If registered application is not multi-tananted, how to run this sample?"_ op de pagina `azure-spring-boot/azure-spring-boot-samples/azure-active-directory-spring-boot-backend-sample/README.md`. Dit impliciteerd dus dat een applicatie `multi-tananted` kan zijn en dat ze hier dus vanuit gaan. Toen ben ik gaan kijken en zag ik dat dit niet zo was bij mij.

Eenmaal de checkbox aangevinkt en nog eens geprobeerd werkte het nog steeds niet. Als ik met mijn `@infosupport.com` account inlog krijg ik een melding dat een admin toestemming moet geven voor deze applicatie.. Dit werkt dus niet. Toen heb ik een account aangemaakt in de Active Directory die ik had aangemaakt, deze heet bbbapi.

Het account wat ik heb aangemaakt is `marvin@bbbapi.onmicrosoft.com`, dit is dus een lokale gebruiker in mijn AAD. Met deze zou ik in moeten kunnen loggen dan. Ik probeerde het en kreeg alsnog een foutmelding. 401 - Unautherized, hoe kan dit? Hier ga ik morgen verder naar kijken.

![Azure error](https://github.com/zwolsman/g-log/raw/master/img/ss_azure_error.png)

## Dag 58, 23-11-2018

### AAD Integeratie.. continues..

Alright, met de error van gister heb ik eigenlijk geen idee waar het fout gaat. Ik ben gaan zoeken naar examples. Op [de Github pagina](https://github.com/Microsoft/azure-spring-boot) is er ook een mapje `azure-spring-boot-samples`. Hier heb ik een project gevonden in Java en gedownload. Ik heb de gegevens aangepast naar mijn id's en secrets en deze werkt wel.. Hoe kan dit?

Ik heb mijn project nagekeken en kan niet vinden hoe dit komt. Ik krijg nog steeds de 401.

### Debuggen

Nou, nu ik een werkende sample heb ga ik het is debuggen. Ik heb het logging level aangepast in de `application.properties`

```properties
logging.level.root=DEBUG
```

Door het op `DEBUG` te zetten zie je alles. Opzoek naar de 401..

```bash
 [nio-8080-exec-5] o.s.s.authentication.ProviderManager     : Authentication attempt using org.springframework.security.oauth2.client.authentication.OAuth2LoginAuthenticationProvider
 [nio-8080-exec-5] o.s.s.authentication.ProviderManager     : Authentication attempt using org.springframework.security.oauth2.client.oidc.authentication.OidcAuthorizationCodeAuthenticationProvider
 [nio-8080-exec-5] o.s.web.client.RestTemplate              : HTTP POST https://login.microsoftonline.com/common/oauth2/token
 [nio-8080-exec-5] o.s.web.client.RestTemplate              : Accept=[application/json, application/*+json]
 [nio-8080-exec-5] o.s.web.client.RestTemplate              : Writing [{grant_type=[authorization_code], code=[AQABAAIAAAC5una0EUFgTIF8ElaxtWjT5d8358D_pgvdPxKmvF37B81QpWW_tPgsEjJpPMxQUOAtbpjU9GY8g_GndfBx6X5dj9HBiDZkXec2tv5x4yVL1EA0QKoNR9tBxzj5Ux-lAYfR-QZcYC7xtJNakwCjlVkkCXCYFfnqR4SkCi4mCfwXZBDGR1Lq8JoHY6KLdPp955KIGyZshhizlFiNiSR7MqCyqswky3t_C8tbmSus1CR-gqDTbmhC3bSEK6_SrjmToeUs2M_7YbBK_4kzuMVG1s6SjMXmLTETMmUhoqfwRHtDTfw1VqlPaEeNFkBuWqV37xkm6xYqp1F1Tv8nljM-ugiJXW1u8-Wr-Sc3zURbZPkK5FxiH-fEpmy3sEkdFPlxMpY-Oks4Wby6IBAci78gVr4BsZegU-286tAiVvo1Wclt2eFAXMuGLJOuxRLIBh6RV_37FanFEB7cEyaZmrs747WoaFStPMpCkZOCpgGN3aoQyiVZwE5_XPqadB-OaBqA6i3DB6ATF2F20PQ3owDQnlAOfxLBJdTFhGqw4pYL-hYlzKkebg8aTNPZF24o3DVqDyggAA], redirect_uri=[http://localhost:8080/login/oauth2/code/azure]}] as "application/x-www-form-urlencoded;charset=UTF-8"
 [nio-8080-exec-5] s.n.www.protocol.http.HttpURLConnection  : sun.net.www.MessageHeader@4ecbd19c8 pairs: {POST /common/oauth2/token HTTP/1.1: null}{Accept: application/json;charset=UTF-8}{Content-Type: application/x-www-form-urlencoded;charset=UTF-8}{Authorization: Basic M2E5OGY0M2EtYTkxZS00ZDgxLWE2NDgtZmFkNzE5MjFkYjYwOio/dl46e3x7PiQmPjFxK1t8Oyh4fCV9TX02K18vK1BaQg==}{User-Agent: Java/1.8.0_161}{Host: login.microsoftonline.com}{Connection: keep-alive}{Content-Length: 700}
 [nio-8080-exec-5] s.n.www.protocol.http.HttpURLConnection  : sun.net.www.MessageHeader@39c3d44b14 pairs: {null: HTTP/1.1 401 Unauthorized}{Cache-Control: no-cache, no-store}{Pragma: no-cache}{Content-Type: application/json; charset=utf-8}{Expires: -1}{Strict-Transport-Security: max-age=31536000; includeSubDomains}{X-Content-Type-Options: nosniff}{x-ms-request-id: ed73bc36-3dfd-4c2b-813b-4dfc3853f900}{P3P: CP="DSP CUR OTPi IND OTRi ONL FIN"}{Set-Cookie: fpc=AWNB-Te6FzlJrjKpOhGlBE3Z5VjZAQDonH_7iVPWCA; expires=Wed, 26-Dec-2018 10:29:01 GMT; path=/; secure; HttpOnly}{Set-Cookie: x-ms-gateway-slice=006; path=/; secure; HttpOnly}{Set-Cookie: stsservicecookie=ests; path=/; secure; HttpOnly}{Date: Mon, 26 Nov 2018 10:29:00 GMT}{Content-Length: 449}
 [nio-8080-exec-5] o.s.web.client.RestTemplate              : Response 401 UNAUTHORIZED
 [nio-8080-exec-5] .s.o.c.w.OAuth2LoginAuthenticationFilter : Authentication request failed: org.springframework.security.oauth2.core.OAuth2AuthenticationException: [invalid_token_response] An error occurred while attempting to retrieve the OAuth 2.0 Access Token Response: 401 Unauthorized
```

Hier zie je dus de POST naar `common/oauth2/token` met variables. Deze variables zijn dus "niet goed" want hier krijg je dus een 401 terug. Nu kijken hoe het gaat bij de exmaple.

```bash
2018-11-26 13:30:00.874 DEBUG 88481 --- [nio-8080-exec-5] org.apache.tomcat.util.http.Parameters   : Start processing with input [code=AQABAAIAAAC5una0EUFgTIF8ElaxtWjTUxwKP2p1mUo2z3_N3n-Zn9oQRvTsDAIQAX_R8jY7_LMtY2M-0ieqPTc-rRhlhQ1XgumbDz6czkEd0BtRDqGtVtHc1mEtc-PJP_BVxHQkdSrNvRU95BaY4swWODLsk62xZMUPQowq_d3vWEXwqBPmeI6xQEzoMHPoJBFDaV9Tz83JAFljAKjnPwhLTlsCSuYaLIv-ukEydSL4Bd8Y8gD9atezXNaXLa3ccf5GCFjtCWo6-4d5iPLoMR6a2GfF6TenQBhCOPP_GFsn3mx55O7w7Zy_b54kgh4PmsmViUZM8RP-jq7lMymRBTao0Cz_eY4Szo5ZjF-VWdJ0jz2c4Wzgp6mKxde18aIL1GyQRVdAxBCn9o6QZ3NnOwTdSzciy8iEyNlH2FSZE9zgTphyXtEEwPpdYT2fLMBNNTnGQfX7Adf5IdRISj_x1Nfy5g-3BNxl_NtrXCEHq5YSMpPp5183say3pzdiJ9-BRs8tcDeABrykNGtKm-P8ry3snr_3J7fE3T1rrIN_l3M-CbTranvVEG3hPOlT_mu4U-uDZ4wFrdMgAA&state=iSSPsrFv2x2s7m5JJxzPy8P1YBZF_m7657LFxF_x7b0%3d&session_state=eb51eee7-c20f-446b-a56b-1d351073f697]
2018-11-26 13:30:00.876 DEBUG 88481 --- [nio-8080-exec-5] o.s.s.authentication.ProviderManager     : Authentication attempt using org.springframework.security.oauth2.client.authentication.OAuth2LoginAuthenticationProvider
2018-11-26 13:30:00.876 DEBUG 88481 --- [nio-8080-exec-5] o.s.s.authentication.ProviderManager     : Authentication attempt using org.springframework.security.oauth2.client.oidc.authentication.OidcAuthorizationCodeAuthenticationProvider
2018-11-26 13:30:01.250 DEBUG 88481 --- [nio-8080-exec-5] s.n.www.protocol.http.HttpURLConnection  : sun.net.www.MessageHeader@40628e788 pairs: {POST /common/oauth2/token HTTP/1.1: null}{Accept: application/json}{Authorization: Basic M2E5OGY0M2EtYTkxZS00ZDgxLWE2NDgtZmFkNzE5MjFkYjYwOiolM0Z2JTVFJTNBJTdCJTdDJTdCJTNFJTI0JTI2JTNFMXElMkIlNUIlN0MlM0IlMjh4JTdDJTI1JTdETSU3RDYlMkJfJTJGJTJCUFpC}{Content-Type: application/x-www-form-urlencoded; charset=UTF-8}{User-Agent: Java/1.8.0_161}{Host: login.microsoftonline.com}{Connection: keep-alive}{Content-Length: 700}
2018-11-26 13:30:01.435 DEBUG 88481 --- [nio-8080-exec-5] s.n.www.protocol.http.HttpURLConnection  : sun.net.www.MessageHeader@6849622d14 pairs: {null: HTTP/1.1 200 OK}{Cache-Control: no-cache, no-store}{Pragma: no-cache}{Content-Type: application/json; charset=utf-8}{Expires: -1}{Strict-Transport-Security: max-age=31536000; includeSubDomains}{X-Content-Type-Options: nosniff}{x-ms-request-id: 3f104cdc-c555-4d8e-845a-1d8a56711d01}{P3P: CP="DSP CUR OTPi IND OTRi ONL FIN"}{Set-Cookie: fpc=AZgcSgAke_ZNki4cQm5KUWpHj33CAQBbNfPimlPWCA; expires=Wed, 26-Dec-2018 12:30:01 GMT; path=/; secure; HttpOnly}{Set-Cookie: x-ms-gateway-slice=001; path=/; secure; HttpOnly}{Set-Cookie: stsservicecookie=ests; path=/; secure; HttpOnly}{Date: Mon, 26 Nov 2018 12:30:01 GMT}{Content-Length: 2819}
2018-11-26 13:30:01.751 DEBUG 88481 --- [nio-8080-exec-5] s.n.www.protocol.http.HttpURLConnection  : sun.net.www.MessageHeader@d81a7765 pairs: {GET /common/discovery/keys HTTP/1.1: null}{User-Agent: Java/1.
```

Hier zie je eigenlijk 2x dezelfde post, zelfde endpoint. Ik heb geen idee waar het aan kan liggen..

## Dag 59, 26-11-2018

Verder gaande waar ik vrijdag achter ben gebleven is het nog meer debuggen..! Ik heb iets gevonden (denk ik). De 2e versie doet de Basic Authentication token anders. Die doet de secret "url encoden" waardoor je dus een andere token krijgt. De eerste versie doet dit dus niet, die doet gewoon `$clientid:$clientsecret` i.p.v. `urlEncode($clientid):urlEncode($clientsecret)`. Eens kijken of ik dit ergens in kan stellen/op kan lossen.

Ik heb het probleem niet kunnen oplossen, ik heb een repo aangemaakt. Daar mijn code opgezet en hulp gevraagd aan een collega. Die zal er naar kijken, ik heb morgen alleen een andere dag voor de boeg. Ik ben dan niet op kantoor maar ga op klant bezoek!

## Dag 60, 24-11-2018

### VECOZO bedrijfs bezoek

We hebben afgesproken bij Vecozo, dit is in Tilburg. Hier zit een groep van ~20 Info Supporters. We hebben afgesproken met een aantal stagiaires uit Nederland en dan Mathias + Ik. Toen we hier aankwamen werden we begroet door 2 Info Supporters, een uit NL en een uit BE. Dit waren hele aardige jongens die zelf er ongeveer 1 jaartje zaten.

We hebben presentaties gehad over Vecozo, wat het doet. Het is een soort "broker" tussen een zorgverlener en de zorgverzekering. Alle facturen/declaraties gaan via dit systeem. Dit wordt ook door heel Nederland gebruikt, waarschijnlijk heb je er nog nooit van gehoord maar heb je er dus wel gebruik van gemaakt (zonder dat je het wist dus!). Het pand was super mooi en modern.

We hebben ook een blik kunnen zien van een Info Supporter die er al langer werkte. Deze liet zien hoe het er aan toe ging een normale dag, welke tooling ze gebruikte etc. Dit was wel inzichtelijk en vond het wel cool. 

Spijtig genoeg kon ik niet mee lunchen, ik had een afspraak staan waar ik naar toe moest.

### System4 sollicitatie

Om 14:00 uur had ik een sollicitatie bij System4 staan. Dit is een ICT detachering bedrijf in Veghel. Ik ben hier terecht gekomen via iemand van LinkedIn. Ik had zelf geen idee wat ik moest verwachten omdat dit de eerste *echte* sollicitatie was. Het gesprek verliep goed. Het enige minpunt was dat ik niet veel werk ervaring had maar ze zag toch potentie. Zelf was ik niet helemaal weg van het bedrijf.

### Jarpis

Om 16:00 uur had ik nog een sollicitatie staan! Dit keer bij Jarpis. Dit is een klein bedrijfje gevestigd in Oisterwijk, dit ligt tussen Tilburg en Eindhoven in.

Ik had hier ook niet echt een idee wat ik kon verwachten alleen dat het een klein bedrijfje was. Dit is een bedrijf met 2 bazen (rond de 25-30 en 4 parttime medewerkers. De 2 bazen waren super toffe gozers en dit gebouw was echt super nieuw en mooi. Ze hadden het IOT toegepast om automatisch te tracken welke bureau's of kamers gebruikt werden en dit kon je inzien op een super groot scherm in de lunch ruimte. Het gesprek verliep super goed en de technieken die ze daar gebruikte waren ook echt wel in mijn straatje. Hier ben ik wel erg enthousiast over. Ik ben uitgenodigd voor een 2e gesprek en benieuwd hoe die gaat!

Al met al was dit een hele drukke dag met veel indrukken. Ik solliciteer bij andere bedrijven omdat ik eens rond wil kijken hoe het er aan toe gaat binnen de ICT wereld en mezelf te orienteren.

## 25-11-2018

### Bol.com IT Young Professional day

Om 13:00 uur begon de IT dag bij bol.com, wie kent de site niet. We kregen een introductie hoe het bij bol.com is. Het bedrijf bestaat uit 1500(!) medewerkers, dit is echt ongelofelijk groot. Ongeveer 400 hiervan zijn IT medewerkers, verdeeld in ~70 teams. Al deze teams werken helemaal autonoom, dit is wel echt cool. Er draaien +- 300 microservices waar teams dus ook zelf verantwoordelijk zijn (OpEx principe).

Ook wordt er gebruik gemaakt van het YBI YRI YLI principe. Elk team is dus 100% verantwoordelijk voor de service die ze maken en onderhoud ervan. Omdat alles autonoom is, is elk team ook in staat om zelf te deployen naar de live productie. Dit gebeurt ook meerdere keren per dag!

> YBI YRI YLI
> You Build It, You Run It, You Love It

Na de rondleiding hebben we een 1:2 gesprek gehad met mensen van daar en kregen we een inzicht of we uberhaupt wel bij bol.com passen. Ik heb er een goed gevoel bij en denk dat ik ook ga solliciteren. Dit is toch wel een heel ander iets dan Info Support of Jarpis. Ik ben benieuwd hoe dit zal verlopen!

Ik ben net terug in Mechelen en ga zo lekker mijn bed in, het is weer een lange dag geweest.. veel gereden en ben toe aan slaap! Morgen weer verder met de Azure Active Directory en gesprek met Benny.

## 26-11-2018

### Gesprek met Benny

Ik zit nog steeds met het probleem van Azure Active Directory. Ik heb dit nu helemaal uitgelegd aan Benny en laten zien hoe het gaat. We hebben samen 30-45mins vanalles zitten proberen en kunnen nog niet vinden wat het is. Ik ga de vraag op Stackoverflow zetten en dan kijken we morgen naar of iemand er op heeft gereageert.

Ik ga nu mijn portfolio producten bekijken en orderen zodat ik morgen feedback/tips kan krijgen.